# An√°lise Preliminar de Performance - Query "KPIs principais por segmento une mad"

**Data:** 2025-10-21
**Status:** ‚ö†Ô∏è Query com falha (ArrowMemoryError)
**Analista:** Claude Code

---

## üìã Sum√°rio Executivo

**Problema:** Query "KPIs principais por segmento une mad" falha com erro `ArrowMemoryError: realloc of size 8910592 failed`

**Causa Raiz:** `load_data()` carrega 2.2M linhas na mem√≥ria SEM aplicar filtros antes

**Impacto:** Timeout/crash em queries que precisam filtrar grandes datasets

---

## üîç An√°lise Detalhada do Fluxo

### 1. C√≥digo Gerado pelo LLM

```python
# C√≥digo gerado (conforme log de erro 20251021)
df = load_data()  # ‚ùå CARREGA TUDO (2.2M linhas)

une_mad_df = df[df['UNE'] == 'MAD']  # Filtro aplicado TARDE DEMAIS

kpis_por_segmento_mad = une_mad_df.groupby('NOMESEGMENTO').agg(
    Venda_Total=('VENDA_30DD', 'sum'),
    Estoque_Total=('ESTOQUE_UNE', 'sum'),
    Preco_Medio=('LIQUIDO_38', 'mean')
).reset_index()

result = kpis_por_segmento_mad[['NOMESEGMENTO', 'Venda_Total', 'Estoque_Total', 'Preco_Medio']]
```

### 2. Execu√ß√£o de `load_data()` (code_gen_agent.py:119-188)

**Etapas internas (estimativa de tempo):**

| Etapa | Tempo Estimado | Mem√≥ria | Opera√ß√£o |
|-------|----------------|---------|----------|
| 1. `dd.read_parquet()` | ~0.5s | Lazy (m√≠nima) | Cria task graph Dask |
| 2. Convers√£o de tipos (`dd.to_numeric`) | ~0.3s | Lazy (m√≠nima) | Adiciona tarefas ao graph |
| 3. **`.compute()`** | **5-15s** | **‚ùå 500MB-2GB** | **MATERIALIZA 2.2M LINHAS** |
| 4. Retorno para pandas | ~0.1s | C√≥pia em mem√≥ria | DataFrame pandas |
| **TOTAL** | **6-16s** | **‚ùå Alto** | **Bottleneck cr√≠tico** |

---

## üö® Bottlenecks Identificados

### Bottleneck #1: Carregamento Completo do Dataset ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

**Localiza√ß√£o:** `code_gen_agent.py:184-186`

```python
self.logger.info(f"‚ö° load_data(): Convertendo Dask ‚Üí pandas ({ddf.npartitions} parti√ß√µes)")
start_compute = time.time()
df_pandas = ddf.compute()  # ‚ùå PROBLEMA AQUI!
```

**Problema:**
- Carrega **todas as 2.2M linhas** do dataset na mem√≥ria
- Ignora completamente o filtro `UNE == 'MAD'` (que reduziria para ~100k linhas)
- PyArrow tenta alocar mais mem√≥ria e falha

**Dados:**
- Dataset completo: ~1.1M linhas (admmat.parquet) + outros arquivos = **2.2M linhas total**
- Tamanho estimado: **500MB - 2GB** em mem√≥ria (pandas)
- UNE 'MAD' filtrado: ~100k linhas (~50MB)

**Impacto:**
- **Tempo:** +5-15s desnecess√°rios
- **Mem√≥ria:** +500MB-2GB desnecess√°rios
- **Risco:** ArrowMemoryError / MemoryError / Timeout

---

### Bottleneck #2: Filtro Aplicado Tarde Demais ‚ö†Ô∏è

**Localiza√ß√£o:** C√≥digo gerado pelo LLM

```python
df = load_data()  # J√° carregou tudo
une_mad_df = df[df['UNE'] == 'MAD']  # Filtro em mem√≥ria (tarde)
```

**Problema:**
- Filtro aplicado DEPOIS de `.compute()`
- Pandas precisa varrer 2.2M linhas em mem√≥ria
- Desperdi√ßa ~95% dos dados carregados

**Solu√ß√£o Ideal (Predicate Pushdown):**
```python
# Filtrar ANTES de compute (no Dask)
ddf = dd.read_parquet(file)
ddf_filtered = ddf[ddf['UNE'] == 'MAD']  # Lazy filter
df = ddf_filtered.compute()  # Carrega apenas ~100k linhas
```

---

### Bottleneck #3: Ignorar PolarsDaskAdapter H√≠brido ‚ö†Ô∏è

**Problema:**
- `load_data()` reimplementa leitura Dask do zero
- **N√ÉO usa** `PolarsDaskAdapter` (que j√° tem predicate pushdown!)
- Perde todos os benef√≠cios da arquitetura h√≠brida

**C√≥digo Atual (code_gen_agent.py:144):**
```python
ddf = dd.read_parquet(parquet_pattern, engine='pyarrow')  # Ignora adapter!
```

**Deveria ser:**
```python
# Usar adapter com filtros
result_list = self.data_adapter.execute_query({'UNE': 'MAD'})
df = pd.DataFrame(result_list)  # Apenas 100k linhas
```

---

## üìä Breakdown de Tempo Estimado (Sem Profiling Real)

### Cen√°rio ATUAL (C√≥digo Problem√°tico):

| Fase | Tempo | Mem√≥ria | Status |
|------|-------|---------|--------|
| 1. LLM gera c√≥digo | ~2-5s | M√≠nima | ‚úÖ OK |
| 2. `load_data()` - read_parquet (lazy) | ~0.5s | M√≠nima | ‚úÖ OK |
| 3. `load_data()` - convers√£o tipos (lazy) | ~0.3s | M√≠nima | ‚úÖ OK |
| 4. **`load_data()` - `.compute()`** | **5-15s** | **500MB-2GB** | ‚ùå BOTTLENECK |
| 5. Filtro `UNE == 'MAD'` em pandas | ~0.5s | J√° em mem√≥ria | ‚ö†Ô∏è Tarde |
| 6. GroupBy + agrega√ß√µes | ~0.2s | M√≠nima | ‚úÖ OK |
| **TOTAL** | **8-21s** | **Alto** | ‚ùå Falha (OOM) |

---

### Cen√°rio IDEAL (Com Filtros no Adapter):

| Fase | Tempo | Mem√≥ria | Status |
|------|-------|---------|--------|
| 1. LLM gera c√≥digo | ~2-5s | M√≠nima | ‚úÖ OK |
| 2. `adapter.execute_query({'UNE': 'MAD'})` - Polars scan | ~0.1s | Lazy | ‚úÖ OK |
| 3. Polars filter (lazy) | ~0.01s | Lazy | ‚úÖ OK |
| 4. Polars collect (apenas MAD) | ~0.2-0.5s | ~50MB | ‚úÖ OK |
| 5. Convers√£o para pandas | ~0.01s | J√° pequeno | ‚úÖ OK |
| 6. GroupBy + agrega√ß√µes | ~0.02s | M√≠nima | ‚úÖ OK |
| **TOTAL** | **2.5-5.5s** | **Baixo** | ‚úÖ Sucesso |

**Ganho:** 3-4x mais r√°pido + 90% menos mem√≥ria!

---

## üéØ Compara√ß√£o: Atual vs Ideal

| M√©trica | Atual (Problema) | Ideal (Solu√ß√£o) | Melhoria |
|---------|------------------|-----------------|----------|
| **Tempo total** | 8-21s (ou falha) | 2.5-5.5s | **3-4x mais r√°pido** |
| **Mem√≥ria pico** | 500MB-2GB | ~50MB | **90% redu√ß√£o** |
| **Linhas carregadas** | 2.2M linhas | ~100k linhas | **95% redu√ß√£o** |
| **Taxa de sucesso** | ‚ùå 0% (OOM) | ‚úÖ 100% | **Resolve bug** |
| **Usa arquitetura h√≠brida** | ‚ùå N√£o | ‚úÖ Sim | **Alinhamento** |

---

## üîß Planos de Corre√ß√£o Recomendados

### **Plano A: Filtros Opcionais em `load_data()` (RECOMENDADO)** ‚≠ê

**Tempo de implementa√ß√£o:** 30 minutos
**Complexidade:** Baixa
**Risco:** Baixo

**Modifica√ß√£o:**
```python
# code_gen_agent.py - load_data()
def load_data(filters: Dict[str, Any] = None):
    if self.data_adapter and filters:
        # Usar adapter com filtros (Polars/Dask)
        result_list = self.data_adapter.execute_query(filters)
        return pd.DataFrame(result_list)
    else:
        # Sem filtros - carregar amostra (10k linhas)
        self.logger.warning("load_data() sem filtros - limitando a 10k linhas")
        # ... implementa√ß√£o
```

**Atualizar prompt LLM:**
```python
"""
‚úÖ CORRETO - Passar filtros para load_data():
df = load_data(filters={'UNE': 'MAD'})

‚ùå ERRADO - Carregar tudo:
df = load_data()  # Timeout!
"""
```

**Vantagens:**
- ‚úÖ Usa PolarsDaskAdapter (arquitetura h√≠brida)
- ‚úÖ Corre√ß√£o m√≠nima (~50 linhas)
- ‚úÖ N√£o quebra c√≥digo existente
- ‚úÖ LLM aprende a usar filtros

**Desvantagens:**
- ‚ö†Ô∏è Depende de LLM gerar c√≥digo com filtros

---

### **Plano B: Polars LazyFrame (Ideal a Longo Prazo)**

**Tempo:** 1-2 horas
**Complexidade:** M√©dia
**Risco:** M√©dio

**Modifica√ß√£o:**
```python
def load_data():
    import polars as pl
    lf = pl.scan_parquet(file_path)  # LazyFrame
    # ... convers√µes de tipos (lazy)
    return lf  # N√ÉO computado!
```

**C√≥digo gerado precisa ser:**
```python
lf = load_data()  # Polars LazyFrame
lf_mad = lf.filter(pl.col('UNE') == 'MAD')  # Lazy
df = lf_mad.collect()  # Agora computa (apenas MAD)
```

**Vantagens:**
- ‚úÖ Performance m√°xima (Polars puro)
- ‚úÖ Imposs√≠vel carregar tudo (lazy obriga filtros)

**Desvantagens:**
- ‚ùå LLM precisa aprender sintaxe Polars
- ‚ùå Taxa de erro inicial pode ser alta

---

### **Plano C: Auto-Filtro Inteligente**

**Tempo:** 2-3 horas
**Complexidade:** Alta
**Risco:** M√©dio-Alto

**Ideia:** Extrair filtros da query do usu√°rio automaticamente (regex)

**Vantagens:**
- ‚úÖ Transparente para LLM

**Desvantagens:**
- ‚ö†Ô∏è Regex pode falhar
- ‚ö†Ô∏è Mais complexo

---

## üìà Impacto Esperado do Plano A

### Queries Afetadas:

| Tipo de Query | Antes | Depois | Ganho |
|---------------|-------|--------|-------|
| **KPIs por UNE espec√≠fica** | Falha (OOM) | 2-3s | ‚úÖ Resolve |
| **Ranking segmento espec√≠fico** | 8-15s | 2-4s | **2-4x** |
| **An√°lise produto espec√≠fico** | 5-10s | 0.5-1s | **10x** |
| **Query sem filtros** | 8-15s | 10k linhas (limitado) | ‚úÖ Seguro |

### Estimativa de Melhoria:

- **70-80% das queries** usam filtros (UNE, segmento, produto)
- Ganho m√©dio: **3-5x mais r√°pido**
- Redu√ß√£o de RAM: **80-90%**
- **100% das queries OOM resolvidas**

---

## ‚úÖ Conclus√µes

### Bottleneck Principal:
**`load_data()` em `code_gen_agent.py:184` carrega 2.2M linhas sem filtros**

### Solu√ß√£o Recomendada:
**Plano A** - Adicionar suporte a filtros opcionais em `load_data()` + atualizar prompt

### Pr√≥ximos Passos:
1. ‚úÖ Aguardar profiling real terminar (validar estimativas)
2. Implementar Plano A (~30 min)
3. Testar com query problem√°tica
4. Validar ganho de performance

---

**Documento gerado em:** 2025-10-21 19:05
**Status:** Aguardando profiling real para valida√ß√£o
**Pr√≥xima atualiza√ß√£o:** Ap√≥s execu√ß√£o do profiling
