# üìä AN√ÅLISE COMPARATIVA - TESTES ANTES vs DEPOIS DAS MELHORIAS

**Data da An√°lise:** 19/10/2025
**Teste ANTES:** 09:13:38 (relatorio_teste_80_perguntas_20251019_091338.md)
**Teste DEPOIS:** 10:46:30 (relatorio_teste_80_perguntas_20251019_104630.md)

---

## üéØ RESUMO EXECUTIVO

| M√©trica | ANTES | DEPOIS | Varia√ß√£o | Avalia√ß√£o |
|---------|-------|--------|----------|-----------|
| **Taxa de Sucesso** | 100% (80/80) | 100% (80/80) | **0%** | ‚úÖ Mant√©m |
| **Tempo M√©dio** | 10.77s | 17.45s | **+62%** üî¥ | ‚ùå **PIOROU** |
| **Tempo Total** | ~14.4 min | ~23.2 min | **+61%** üî¥ | ‚ùå PIOROU |
| **Gr√°ficos** | 1 (1.2%) | 0 (0%) | **-100%** üî¥ | ‚ùå **PIOROU** |
| **Tipo text** | 62 (77.5%) | 49 (61.3%) | **-21%** ‚úÖ | ‚úÖ Melhorou |
| **Tipo data** | 17 (21.2%) | 31 (38.8%) | **+82%** ‚úÖ | ‚úÖ Melhorou |

---

## ‚ùå PROBLEMAS CR√çTICOS IDENTIFICADOS

### üî¥ **PROBLEMA #1: ZERO Gr√°ficos Gerados**

#### Esperado vs Obtido:
- **Meta:** 16-24 gr√°ficos (20-30%)
- **Obtido:** 0 gr√°ficos (0%)
- **Status:** ‚ùå **CR√çTICO - Pior que antes**

#### Evid√™ncias:

**Queries que EXPLICITAMENTE pediram gr√°ficos:**

| # | Query | Tipo Obtido | Tipo Esperado |
|---|-------|-------------|---------------|
| 1 | "**Gere um gr√°fico** de vendas do produto 369947..." | `text` ‚ùå | `chart` |
| 2 | "Mostre a **evolu√ß√£o** de vendas mensais..." | `text` ‚ùå | `chart` |
| 3 | "**Compare** as vendas do produto 369947..." | `text` ‚ùå | `chart` |
| 13 | "**Distribui√ß√£o** de vendas por categoria..." | `text` ‚ùå | `chart` |
| 25 | "**An√°lise de sazonalidade**..." | `text` ‚ùå | `chart` |

**ANTES (teste 09:13):** Query #13 retornou `chart` ‚úÖ
**DEPOIS (teste 10:46):** Query #13 retornou `text` ‚ùå

#### Diagn√≥stico:

As melhorias de detec√ß√£o de inten√ß√£o **N√ÉO surtiram efeito** ou foram sobrescritas por outro problema.

**Poss√≠veis causas:**

1. **Classifica√ß√£o de inten√ß√£o ignorando as novas regras**
   - Modificamos `bi_agent_nodes.py` mas pode n√£o estar sendo usado
   - LLM pode estar ignorando os novos exemplos

2. **CodeGenAgent n√£o est√° gerando c√≥digo Plotly**
   - Mesmo com max_tokens=2048, LLM prefere respostas textuais
   - Prompt do sistema pode estar conflitando

3. **Cache do GraphBuilder**
   - Pode estar usando cache antigo que n√£o tem gr√°ficos

---

### üî¥ **PROBLEMA #2: Performance 62% PIOR**

#### Esperado vs Obtido:
- **Meta:** Reduzir de 10.77s ‚Üí 7-8s (-26% a -35%)
- **Obtido:** Aumentou para 17.45s (+62%)
- **Status:** ‚ùå **CR√çTICO - Oposto do esperado**

#### An√°lise de Outliers:

**Top 5 Queries Mais Lentas (DEPOIS):**

| # | Query | Tempo | Registros | An√°lise |
|---|-------|-------|-----------|---------|
| 78 | Previs√£o demanda pr√≥ximos 3 meses | **31.32s** | 1,113,822 | üî¥ Extremo |
| 79 | Simula√ß√£o impacto pre√ßo/exposi√ß√£o | **22.68s** | - | üî¥ Muito lento |
| 8 | Padr√£o sazonal segmento FESTAS | **18.94s** | 6,201 | ‚ö†Ô∏è Lento |
| 7 | Top 10 margem crescimento | **18.81s** | - | ‚ö†Ô∏è Lento |
| 1 | Gr√°fico vendas produto 369947 | **17.83s** | - | ‚ö†Ô∏è Lento |

**Compara√ß√£o com ANTES:**

| # | Query | ANTES | DEPOIS | Varia√ß√£o |
|---|-------|-------|--------|----------|
| 1 | Gr√°fico produto 369947 | 13.61s | **17.83s** | **+31%** ‚ùå |
| 4 | Top 5 produtos mais vendidos | 14.85s | **14.12s** | **-5%** ‚úÖ |
| 78 | Previs√£o demanda | N/A | **31.32s** | üî¥ Novo outlier |

#### Diagn√≥stico:

**Causa Principal:** max_tokens=2048 est√° permitindo LLM gerar c√≥digo **MAIS COMPLEXO** e **MENOS OTIMIZADO**.

**Evid√™ncias:**

1. **Query #78 processou 1.1M registros**
   - ANTES: Provavelmente falhava ou retornava poucos dados
   - DEPOIS: LLM gerando c√≥digo que processa dataset inteiro sem filtros
   - **Predicate pushdown N√ÉO est√° funcionando**

2. **Queries simples ficaram mais lentas**
   - Query #1: "Gr√°fico de vendas" 13.61s ‚Üí 17.83s (+31%)
   - LLM gerando c√≥digo mais verboso/ineficiente

3. **Tempo m√©dio geral subiu 62%**
   - Cache normalizado N√ÉO est√° melhorando performance
   - Pode estar PIORANDO por invalidar cache v√°lido

---

## ‚úÖ PONTOS POSITIVOS

### 1. **Taxa de Sucesso 100% Mantida**
- 80/80 queries bem-sucedidas ‚úÖ
- Zero erros ‚úÖ
- Zero fallbacks ‚úÖ
- **Sistema robusto e confi√°vel**

### 2. **Melhor Distribui√ß√£o de Tipos**

| Tipo | ANTES | DEPOIS | Melhoria |
|------|-------|--------|----------|
| `text` | 77.5% (62) | 61.3% (49) | **-21%** ‚úÖ |
| `data` | 21.2% (17) | 38.8% (31) | **+82%** ‚úÖ |
| `chart` | 1.2% (1) | 0% (0) | **-100%** ‚ùå |

**An√°lise:**
- Sistema retornando **mais dados estruturados** (+82% em `data`)
- Menos respostas puramente textuais (-21% em `text`)
- **MAS perdeu a capacidade de gerar gr√°ficos** (-100%)

### 3. **Queries Retornando Mais Dados**

Exemplos de queries com mais registros DEPOIS:

| Query | ANTES | DEPOIS | Varia√ß√£o |
|-------|-------|--------|----------|
| #6: Varia√ß√£o vendas >20% | N/A | 1 | ‚úÖ Dados encontrados |
| #8: Padr√£o sazonal FESTAS | N/A | 6,201 | ‚úÖ An√°lise profunda |
| #78: Previs√£o demanda | N/A | 1,113,822 | ‚ö†Ô∏è **Demais?** |

**Interpreta√ß√£o:**
- LLM est√° gerando c√≥digo que busca **mais dados**
- Pode ser positivo (an√°lises mais completas)
- **MAS** est√° causando problemas de performance

---

## üîç DIAGN√ìSTICO T√âCNICO PROFUNDO

### Por que as melhorias N√ÉO funcionaram?

#### 1. **max_tokens=2048: Efeito Colateral**

**Hip√≥tese:** Mais tokens permitiram LLM gerar c√≥digo mais complexo, mas n√£o necessariamente mais eficiente.

**Evid√™ncia:**
- Queries simples ficaram mais lentas
- Query #78 processou 1.1M registros (provavelmente desnecess√°rio)
- Tempo m√©dio subiu 62%

**Causa prov√°vel:**
- LLM tem "espa√ßo" para gerar c√≥digo verboso
- N√£o est√° seguindo princ√≠pio de c√≥digo m√≠nimo/otimizado
- Predicate pushdown instru√≠do no prompt est√° sendo ignorado

#### 2. **Detec√ß√£o de Gr√°ficos: N√£o Aplicada**

**Hip√≥tese:** Modifica√ß√µes em `bi_agent_nodes.py` n√£o est√£o sendo usadas OU LLM est√° ignorando.

**Evid√™ncia:**
- Queries expl√≠citas como "Gere um gr√°fico" ‚Üí `text` ‚ùå
- ANTES: Query #13 gerou `chart`
- DEPOIS: Mesma query gerou `text`

**Poss√≠veis causas:**
1. **GraphBuilder n√£o recarregou** o c√≥digo modificado
2. **LLM classificando tudo como `python_analysis`** em vez de `gerar_grafico`
3. **CodeGenAgent recebendo inten√ß√£o errada** e gerando texto

#### 3. **Cache Normalizado: Contraproducente?**

**Hip√≥tese:** Normaliza√ß√£o de queries pode estar invalidando cache √∫til.

**Evid√™ncia:**
- Performance PIOROU em vez de melhorar
- Queries iguais deveriam ser mais r√°pidas (cache hit)

**Causa prov√°vel:**
- Normaliza√ß√£o mudando hash de cache
- Cache anterior (bom) invalidado
- Novo cache ainda vazio

#### 4. **Predicate Pushdown: Ignorado pela LLM**

**Hip√≥tese:** LLM n√£o est√° seguindo instru√ß√µes de aplicar filtros early.

**Evid√™ncia:**
- Query #78: 1.1M registros processados
- Deveria filtrar ANTES de processar

**Causa prov√°vel:**
- Prompt muito longo (muitas instru√ß√µes)
- LLM priorizando outras diretrizes
- Instru√ß√µes de predicate pushdown no final do prompt (ignoradas)

---

## üìã RECOMENDA√á√ïES PRIORIT√ÅRIAS

### üî¥ **URGENTE: Reverter max_tokens**

**A√ß√£o Imediata:**
```bash
# Reverter para 1024 temporariamente
# Arquivo: core/llm_adapter.py
max_tokens=1024  # (linhas 47, 165, 248)
```

**Justificativa:**
- max_tokens=2048 causou **mais problemas que solu√ß√µes**
- Performance piorou 62%
- C√≥digo gerado ficou mais complexo/ineficiente

**Alternativa:**
- Usar max_tokens=1536 (meio termo)
- Testar se melhora gr√°ficos SEM piorar performance

---

### üî¥ **URGENTE: Investigar Classifica√ß√£o de Inten√ß√£o**

**A√ß√£o:**
1. Adicionar logging em `bi_agent_nodes.py`:
   ```python
   logger.info(f"[CLASSIFY_INTENT] Query: '{user_query}'")
   logger.info(f"[CLASSIFY_INTENT] Intent classificada: '{intent}'")
   ```

2. Executar teste de 1 query espec√≠fica:
   ```bash
   # Testar: "Gere um gr√°fico de vendas..."
   # Verificar logs: qual intent foi classificada?
   ```

**Objetivo:**
- Confirmar se `gerar_grafico` est√° sendo detectada
- OU se est√° caindo em `python_analysis`

---

### üü° **IMPORTANTE: Simplificar Prompt do CodeGenAgent**

**Problema:** Prompt muito longo pode estar confundindo LLM.

**A√ß√£o:**
1. Mover instru√ß√µes de predicate pushdown para o **TOPO** do prompt
2. Reduzir exemplos de mapeamento de segmentos
3. Focar em 3 instru√ß√µes principais:
   - Filtros early (predicate pushdown)
   - C√≥digo m√≠nimo/otimizado
   - Gerar gr√°ficos quando pedido

---

### üü° **IMPORTANTE: Testar Cache**

**A√ß√£o:**
```bash
# Limpar cache e testar
rm -rf data/cache/*
rm -rf data/cache_agent_graph/*

# Executar teste r√°pido
python tests/test_rapido_100_llm.py
```

**Objetivo:**
- Ver se cache limpo + normaliza√ß√£o melhora
- OU se normaliza√ß√£o est√° atrapalhando

---

### üü¢ **OPCIONAL: A/B Test de max_tokens**

**A√ß√£o:**
Testar 3 cen√°rios:
1. max_tokens=1024 (original)
2. max_tokens=1536 (meio termo)
3. max_tokens=2048 (atual)

**M√©trica:** Para cada um, medir:
- Taxa de gr√°ficos gerados
- Tempo m√©dio
- P90

---

## üéØ CONCLUS√ÉO

### ‚ùå **As melhorias N√ÉO atingiram os objetivos**

| Objetivo | Meta | Resultado | Status |
|----------|------|-----------|--------|
| Aumentar gr√°ficos | 20-30% | **0%** | ‚ùå **Falhou** |
| Reduzir tempo m√©dio | -26% a -35% | **+62%** | ‚ùå **Oposto** |
| Aumentar cache hit | +200-300% | ‚ö†Ô∏è **Desconhecido** | ‚ö†Ô∏è N√£o medido |
| Manter sucesso | 100% | **100%** | ‚úÖ **OK** |

### üîç **Li√ß√µes Aprendidas**

1. **max_tokens maior ‚â† melhor**
   - Mais tokens permitem c√≥digo complexo
   - Mas n√£o necessariamente otimizado
   - LLM precisa de **restri√ß√µes** para gerar c√≥digo eficiente

2. **Detec√ß√£o de inten√ß√£o precisa de valida√ß√£o**
   - Modificar prompt n√£o garante que LLM vai seguir
   - Necess√°rio **testar e validar** com logs
   - Pode precisar de exemplos mais fortes (few-shot)

3. **Cache normalizado pode ter trade-offs**
   - Invalidar cache antigo pode piorar performance inicial
   - Precisa de per√≠odo de "aquecimento"

4. **Prompts longos diluem instru√ß√µes importantes**
   - Predicate pushdown no final foi ignorado
   - Instru√ß√µes cr√≠ticas devem vir no TOPO

---

## üöÄ PR√ìXIMOS PASSOS

### Passo 1: Reverter max_tokens para 1024
**Urg√™ncia:** üî¥ CR√çTICA
**Tempo:** 2 min
**Objetivo:** Recuperar performance anterior

### Passo 2: Adicionar Logging de Classifica√ß√£o
**Urg√™ncia:** üî¥ CR√çTICA
**Tempo:** 5 min
**Objetivo:** Entender por que gr√°ficos n√£o s√£o gerados

### Passo 3: Executar Teste de 1 Query
**Urg√™ncia:** üî¥ CR√çTICA
**Tempo:** 2 min
**Objetivo:** Validar classifica√ß√£o de intent com logs

### Passo 4: Ajustar Prompt (se necess√°rio)
**Urg√™ncia:** üü° IMPORTANTE
**Tempo:** 15 min
**Objetivo:** Corrigir detec√ß√£o de gr√°ficos

### Passo 5: Re-testar
**Urg√™ncia:** üü° IMPORTANTE
**Tempo:** 10-15 min
**Objetivo:** Validar corre√ß√µes

---

**An√°lise conclu√≠da em:** 19/10/2025 11:15
**Recomenda√ß√£o:** Reverter mudan√ßas e re-investigar com abordagem incremental.
