# Teste de 80 Perguntas de NegÃ³cio - DirectQueryEngine

## ðŸ“‹ VisÃ£o Geral

Este teste avalia a capacidade do **DirectQueryEngine** de processar 80 perguntas de negÃ³cio organizadas em 10 categorias, **sem usar tokens da LLM**.

## ðŸŽ¯ Objetivo

Validar que o sistema consegue responder perguntas de negÃ³cio complexas usando apenas:
- PadrÃµes prÃ©-definidos
- Cache inteligente
- Consultas diretas ao Parquet
- **Zero consumo de tokens LLM**

## ðŸ“ Arquivos

- `test_80_perguntas_completo.py` - Script principal de teste
- `run_test_80_perguntas.py` - Script auxiliar para executar o teste
- `README_TESTE_80_PERGUNTAS.md` - Este arquivo

## ðŸš€ Como Executar

### OpÃ§Ã£o 1: Script Auxiliar (Recomendado)

```bash
cd C:\Users\AndrÃ©\Documents\Agent_Solution_BI
python tests/run_test_80_perguntas.py
```

### OpÃ§Ã£o 2: Diretamente

```bash
cd C:\Users\AndrÃ©\Documents\Agent_Solution_BI
python tests/test_80_perguntas_completo.py
```

## ðŸ“Š Categorias de Perguntas

O teste cobre 10 categorias principais:

1. **ðŸŽ¯ Vendas por Produto** (8 perguntas)
   - GrÃ¡ficos de vendas
   - EvoluÃ§Ã£o temporal
   - Comparativos entre UNEs
   - Top performers

2. **ðŸª AnÃ¡lises por Segmento** (8 perguntas)
   - Rankings por segmento
   - Comparativos
   - DistribuiÃ§Ã£o ABC
   - Sazonalidade

3. **ðŸ¬ AnÃ¡lises por UNE/Loja** (8 perguntas)
   - Performance por loja
   - Potencial de crescimento
   - Diversidade de produtos
   - EficiÃªncia de vendas

4. **ðŸ“ˆ AnÃ¡lises Temporais** (8 perguntas)
   - Sazonalidade
   - TendÃªncias
   - PrevisÃµes
   - Alertas de declÃ­nio

5. **ðŸ’° Performance e ABC** (8 perguntas)
   - ClassificaÃ§Ã£o ABC
   - MigraÃ§Ã£o entre classes
   - FrequÃªncia de vendas
   - ConsistÃªncia

6. **ðŸ“¦ Estoque e LogÃ­stica** (8 perguntas)
   - Ponto de pedido
   - RotaÃ§Ã£o de estoque
   - Excesso/falta
   - EficiÃªncia logÃ­stica

7. **ðŸ­ AnÃ¡lises por Fabricante** (8 perguntas)
   - Rankings
   - Diversidade
   - ConcentraÃ§Ã£o
   - Oportunidades

8. **ðŸŽ¨ Categoria/Grupo** (8 perguntas)
   - Performance por categoria
   - Cross-selling
   - Gap analysis
   - ExpansÃ£o de linha

9. **ðŸ“Š Dashboards Executivos** (8 perguntas)
   - KPIs consolidados
   - Scorecards
   - Alertas
   - Indicadores de saÃºde

10. **ðŸ” AnÃ¡lises EspecÃ­ficas** (8 perguntas)
    - CanibalizaÃ§Ã£o
    - Impacto de promoÃ§Ãµes
    - PrevisÃ£o de demanda
    - SimulaÃ§Ãµes

## ðŸ“ˆ MÃ©tricas Avaliadas

Para cada pergunta, o teste registra:

- âœ… **SUCCESS**: Processado com sucesso pelo DirectQueryEngine
- âš ï¸ **FALLBACK**: Necessita processamento pela LLM (objetivo: minimizar)
- âŒ **ERROR**: Erro durante processamento
- â“ **UNKNOWN**: Tipo de resultado desconhecido

## ðŸ“„ RelatÃ³rio Gerado

O teste gera um arquivo JSON detalhado:

```
tests/relatorio_teste_80_perguntas_YYYYMMDD_HHMMSS.json
```

### Estrutura do RelatÃ³rio

```json
{
  "metadata": {
    "timestamp": "2025-10-19T...",
    "total_perguntas": 80,
    "total_categorias": 10
  },
  "estatisticas": {
    "SUCCESS": 65,
    "FALLBACK": 10,
    "ERROR": 5,
    "UNKNOWN": 0
  },
  "resultados": [
    {
      "id": 1,
      "categoria": "ðŸŽ¯ Vendas por Produto",
      "pergunta": "Gere um grÃ¡fico...",
      "status": "SUCCESS",
      "mensagem": "Processado como chart",
      "tipo_resultado": "chart",
      "tempo_processamento": 0.45,
      "timestamp": "2025-10-19T..."
    }
  ]
}
```

## ðŸ” InterpretaÃ§Ã£o dos Resultados

### Meta de Sucesso
- **Ã“timo**: SUCCESS > 70% (56+ perguntas)
- **Bom**: SUCCESS > 60% (48+ perguntas)
- **AceitÃ¡vel**: SUCCESS > 50% (40+ perguntas)
- **Precisa melhorias**: SUCCESS < 50%

### AnÃ¡lise de Fallback
- Perguntas que caem em FALLBACK indicam padrÃµes que ainda nÃ£o foram implementados
- Use o relatÃ³rio para identificar novos padrÃµes a adicionar no DirectQueryEngine

### AnÃ¡lise de Erros
- Erros indicam problemas de implementaÃ§Ã£o ou dados
- Revise o log de cada erro para correÃ§Ã£o

## ðŸ› ï¸ PrÃ©-requisitos

### DependÃªncias Python
```bash
pip install pandas dask pyarrow
```

### Arquivos de Dados
O teste procura automaticamente por:
1. `data/parquet/admmat_extended.parquet` (preferencial)
2. `data/parquet/admmat.parquet` (fallback)

## ðŸ› Troubleshooting

### Erro: "Parquet file not found"
```bash
# Verifique se o arquivo existe
ls data/parquet/
```

### Erro: "Module not found"
```bash
# Instale dependÃªncias
pip install -r requirements.txt
```

### Problemas de Encoding (Windows)
O script tem tratamento automÃ¡tico para problemas de encoding com emojis.
Se ainda houver problemas, execute com:
```bash
python -X utf8 tests/run_test_80_perguntas.py
```

### LentidÃ£o na ExecuÃ§Ã£o
- Normal: 80 perguntas levam ~2-5 minutos
- Se levar muito mais, verifique o tamanho do arquivo parquet
- Considere usar `admmat.parquet` em vez de `admmat_extended.parquet`

## ðŸ“ Logs

Durante a execuÃ§Ã£o, vocÃª verÃ¡:

```
================================================================================
TESTE COMPLETO DAS 80 PERGUNTAS DE NEGÃ“CIO
================================================================================
InÃ­cio: 2025-10-19 10:30:00

Inicializando DirectQueryEngine...
   Carregando dados de: C:\...\admmat_extended.parquet
[OK] Engine inicializada

================================================================================
[CATEGORIA] ðŸŽ¯ Vendas por Produto
================================================================================

[1/80] Testando: Gere um grÃ¡fico de vendas do produto 369947 na UNE SCR...
[OK] SUCCESS: Processado como chart (0.45s)

[2/80] Testando: Mostre a evoluÃ§Ã£o de vendas mensais do produto 369947...
[OK] SUCCESS: Processado como chart (0.38s)

...
```

## ðŸŽ¯ PrÃ³ximos Passos

ApÃ³s executar o teste:

1. **Revise o relatÃ³rio JSON** gerado
2. **Analise perguntas FALLBACK** - adicione novos padrÃµes
3. **Corrija erros** identificados
4. **Otimize performance** de queries lentas
5. **Execute novamente** para validar melhorias

## ðŸ“ž Suporte

Em caso de dÃºvidas ou problemas:
1. Verifique os logs detalhados
2. Consulte o relatÃ³rio JSON
3. Revise a documentaÃ§Ã£o do DirectQueryEngine
4. Abra uma issue no projeto

---

**Ãšltima atualizaÃ§Ã£o**: 2025-10-19
**VersÃ£o**: 1.0
