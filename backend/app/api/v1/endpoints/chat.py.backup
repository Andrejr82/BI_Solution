"""
Chat Endpoints
BI Chat with AI assistant
"""

from typing import Annotated
from fastapi import APIRouter, Depends, HTTPException
from fastapi.responses import ORJSONResponse
from pydantic import BaseModel
from pathlib import Path

from app.api.dependencies import get_current_active_user
from app.infrastructure.database.models import User

# Project root (6 n√≠veis acima deste arquivo: chat.py -> endpoints -> v1 -> api -> app -> backend -> ROOT)
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent.parent.parent.parent

router = APIRouter(prefix="/chat", tags=["Chat"])


class ChatRequest(BaseModel):
    query: str


class ChatResponse(BaseModel):
    response: str


@router.post("", response_class=ORJSONResponse)
async def send_chat_message(
    request: ChatRequest,
    current_user: Annotated[User, Depends(get_current_active_user)],
) -> dict:
    """
    Send a message to the BI Chat assistant
    
    Processes natural language queries using Agent System (with fallback to direct Parquet queries)
    """
    import sys
    import polars as pl
    from pathlib import Path
    import logging
    import asyncio
    
    logger = logging.getLogger(__name__)
    query = request.query
    
    print(f"==> CHAT REQUEST: {query} <==", file=sys.stderr, flush=True)

    # ‚úÖ AGENTE HABILITADO - Otimizado para performance
    use_agent = True

    # Tentar usar sistema de agentes primeiro COM TIMEOUT
    if use_agent:
        try:
            from app.core.query_processor import QueryProcessor

            # Inicializar QueryProcessor (singleton)
            if not hasattr(send_chat_message, '_query_processor'):
                print("==> Inicializando QueryProcessor... <==", file=sys.stderr, flush=True)
                send_chat_message._query_processor = QueryProcessor()
                print("==> QueryProcessor inicializado! <==", file=sys.stderr, flush=True)

            print("==> Processando query com agente... <==", file=sys.stderr, flush=True)

            # ‚úÖ TIMEOUT DE 10 SEGUNDOS (reduzido de 30s)
            result = await asyncio.wait_for(
                asyncio.to_thread(send_chat_message._query_processor.process_query, query),
                timeout=10.0
            )

            print(f"==> Agente retornou: {type(result)} <==", file=sys.stderr, flush=True)

            # Extrair resposta do resultado
            if isinstance(result, dict):
                response_text = result.get("output", "")
                if response_text:
                    print(f"==> Resposta v√°lida: {response_text[:100]}... <==", file=sys.stderr, flush=True)
                    return ChatResponse(response=response_text)

                # Se n√£o houver resposta v√°lida, fazer fallback
                print("==> Agente n√£o retornou resposta v√°lida, usando fallback <==", file=sys.stderr, flush=True)
        except asyncio.TimeoutError:
            print("==> TIMEOUT: Agente demorou mais de 30s, usando fallback <==", file=sys.stderr, flush=True)
        except Exception as e:
            print(f"==> ERRO no agente: {e}, usando fallback <==", file=sys.stderr, flush=True)
            logger.warning(f"Sistema de agentes n√£o dispon√≠vel ({e}), usando fallback para Parquet")
    
    # FALLBACK: Consultas diretas ao Parquet (c√≥digo anterior)
    try:
        # Caminho h√≠brido Docker/Dev
        docker_path = Path("/app/data/parquet/admmat.parquet")
        dev_path = PROJECT_ROOT / "data" / "parquet" / "admmat.parquet"

        parquet_path = docker_path if docker_path.exists() else dev_path

        # OTIMIZA√á√ÉO: Usar scan_parquet (lazy) ao inv√©s de read_parquet (eager)
        # Carrega apenas dados necess√°rios, muito mais r√°pido
        print(f"==> Carregando dados do Parquet (lazy scan)... <==", file=sys.stderr, flush=True)
        lf = pl.scan_parquet(parquet_path)

        query_lower = query.lower()
        
        # Processar diferentes tipos de perguntas
        if "vendas" in query_lower or "sales" in query_lower or "total" in query_lower:
            # OTIMIZA√á√ÉO: Usar count() no lazy frame (muito mais r√°pido que len(df))
            total = lf.select(pl.count()).collect().item()
            response = f"üìä **An√°lise de Vendas**\n\nCom base nos dados reais, temos um total de **{total:,} registros** de vendas no sistema.\n\nEste n√∫mero representa todas as transa√ß√µes registradas no banco de dados."
            
        elif "produtos" in query_lower or "products" in query_lower:
            # Verificar colunas dispon√≠veis
            schema_cols = lf.collect_schema().names()
            if "PRODUTO" in schema_cols:
                # OTIMIZA√á√ÉO: Opera√ß√µes no lazy frame antes de collect
                unique_products = lf.select(pl.col("PRODUTO").n_unique()).collect().item()
                top_products = (
                    lf.group_by("PRODUTO")
                    .agg(pl.count().alias("count"))
                    .sort("count", descending=True)
                    .head(5)
                    .collect()
                )

                response = f"üì¶ **An√°lise de Produtos**\n\nTemos **{unique_products:,} produtos √∫nicos** no cat√°logo.\n\n**Top 5 Produtos Mais Vendidos:**\n"
                for row in top_products.iter_rows():
                    response += f"- {row[0]}: {row[1]:,} vendas\n"
            else:
                response = "üì¶ Informa√ß√£o de produtos n√£o dispon√≠vel no momento."
                
        elif "colunas" in query_lower or "campos" in query_lower or "dados" in query_lower:
            # OTIMIZA√á√ÉO: Pegar schema sem carregar dados
            schema_cols = lf.collect_schema().names()
            total_count = lf.select(pl.count()).collect().item()

            cols = schema_cols[:20]
            response = f"üìã **Estrutura dos Dados**\n\nO dataset possui **{len(schema_cols)} colunas** e **{total_count:,} registros**.\n\n**Principais colunas:**\n"
            for col in cols:
                response += f"- {col}\n"
            if len(schema_cols) > 20:
                response += f"\n... e mais {len(schema_cols) - 20} colunas."
                
        elif "estat√≠sticas" in query_lower or "resumo" in query_lower or "overview" in query_lower:
            # OTIMIZA√á√ÉO: Tudo no lazy frame
            schema_cols = lf.collect_schema().names()
            total_count = lf.select(pl.count()).collect().item()

            response = f"üìà **Resumo Estat√≠stico**\n\n"
            response += f"- **Total de registros:** {total_count:,}\n"
            response += f"- **Total de colunas:** {len(schema_cols)}\n"
            if "PRODUTO" in schema_cols:
                unique_prods = lf.select(pl.col('PRODUTO').n_unique()).collect().item()
                response += f"- **Produtos √∫nicos:** {unique_prods:,}\n"
            response += f"\nüí° Fa√ßa perguntas espec√≠ficas sobre vendas, produtos ou qualquer coluna do dataset!"
            
        else:
            # Resposta gen√©rica com informa√ß√µes √∫teis
            # OTIMIZA√á√ÉO: Usar lazy frame
            schema_cols = lf.collect_schema().names()
            total_count = lf.select(pl.count()).collect().item()

            response = f"ü§ñ **Assistente BI**\n\nRecebi sua pergunta: '{query}'\n\n"
            response += f"Tenho acesso a **{total_count:,} registros** com **{len(schema_cols)} colunas** de dados.\n\n"
            response += "**Perguntas que posso responder:**\n"
            response += "- Quantas vendas tivemos?\n"
            response += "- Quais s√£o os produtos mais vendidos?\n"
            response += "- Mostre as colunas dispon√≠veis\n"
            response += "- Fa√ßa um resumo estat√≠stico\n"

        return {"response": response}
        
    except Exception as e:
        # √öltimo fallback em caso de erro
        print(f"==> ERRO no fallback: {e} <==", file=sys.stderr, flush=True)
        return {
            "response": f"‚ùå Erro ao processar consulta: {str(e)}\n\nPor favor, tente reformular sua pergunta."
        }

