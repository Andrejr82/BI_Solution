import json
import logging
import asyncio
import numpy as np
import pandas as pd
from decimal import Decimal
from datetime import datetime, date
from typing import Any, Dict, List, Optional, Callable, Awaitable

logger = logging.getLogger(__name__)

# Safe Import for LangChain dependencies
LANGCHAIN_AVAILABLE = False
try:
    from langchain_core.language_models import BaseChatModel
    from langchain_core.tools import BaseTool
    LANGCHAIN_AVAILABLE = True
except (ImportError, OSError):
    logger.warning("LangChain dependencies missing. CaculinhaBIAgent will run in degraded mode.")
    BaseChatModel = object # Dummy for type hinting
    BaseTool = object # Dummy for type hinting

from app.core.tools.une_tools import (
    calcular_abastecimento_une,
    calcular_mc_produto,
    calcular_preco_final_une,
    validar_transferencia_produto,
    sugerir_transferencias_automaticas,
    encontrar_rupturas_criticas,
    consultar_dados_gerais,
)
from app.core.tools.flexible_query_tool import consultar_dados_flexivel

# Import NEW universal chart tool - Context7 2025 Best Practice
from app.core.tools.universal_chart_generator import gerar_grafico_universal_v2

# Import legacy chart tools for compatibility
from app.core.tools.chart_tools import (
    gerar_ranking_produtos_mais_vendidos,
    gerar_dashboard_executivo,
    listar_graficos_disponiveis,
    gerar_visualizacao_customizada
)

# Import NEW semantic search tool - RAG Implementation 2025
from app.core.tools.semantic_search_tool import buscar_produtos_inteligente

# Import RAG Hybrid Retriever - Query Example Retrieval 2025
from app.core.rag.hybrid_retriever import HybridRetriever

# Optional: Import CodeGenAgent just for type hinting if needed,
# but we won't use it for logic anymore.
from app.core.utils.field_mapper import FieldMapper

# Import TypeConverter para serializa√ß√£o segura
from app.core.utils.serializers import TypeConverter, safe_json_dumps

# Import Tool Scoping - Security 2025
from app.core.utils.tool_scoping import ToolPermissionManager, get_scoped_tools

# Alias para manter compatibilidade com c√≥digo existente
safe_json_serialize = safe_json_dumps

# System instruction - Analista de BI Focado em Ferramentas (Vers√£o Simplificada 2025)
SYSTEM_PROMPT = """Voc√™ √© um Analista de Business Intelligence com acesso direto ao Data Lake da empresa.

## SUA MISS√ÉO
Responder perguntas de neg√≥cio usando FERRAMENTAS dispon√≠veis para obter dados reais e gerar visualiza√ß√µes.

## DADOS DISPON√çVEIS (Schema do Data Lake)
**Colunas Principais:**
- `PRODUTO` (c√≥digo), `NOME` (descri√ß√£o)
- `UNE` (loja), `NOMESEGMENTO`, `NOMECATEGORIA`, `NOMEFABRICANTE`
- `VENDA_30DD` (vendas √∫ltimos 30 dias)
- `ESTOQUE_UNE` (estoque loja), `ESTOQUE_CD` (estoque centro distribui√ß√£o)
- `PRECO_VENDA`, `PRECO_CUSTO`

## COMO FUNCIONA O SISTEMA

Voc√™ possui acesso a **ferramentas especializadas** que executam opera√ß√µes no Data Lake.
**REGRA CR√çTICA:** Voc√™ DEVE chamar ferramentas para obter dados. NUNCA invente n√∫meros ou an√°lises sem tool result.

**Principais Ferramentas Dispon√≠veis:**
- **Gr√°ficos:** `gerar_grafico_universal_v2` (use para QUALQUER gr√°fico), `gerar_ranking_produtos_mais_vendidos`, `gerar_dashboard_executivo`
- **Consultas:** `consultar_dados_flexivel` (consultas gen√©ricas), `buscar_produtos_inteligente` (busca sem√¢ntica)
- **An√°lises:** `encontrar_rupturas_criticas`, `sugerir_transferencias_automaticas`, `calcular_abastecimento_une`

## VALIDA√á√ÉO OBRIGAT√ìRIA DE DADOS
**Antes de enviar qualquer resposta com n√∫meros/m√©tricas/an√°lises:**
1. Verifique se chamou pelo menos UMA ferramenta
2. Verifique se a ferramenta retornou dados v√°lidos (n√£o vazio, n√£o erro)
3. Use APENAS os n√∫meros retornados pela ferramenta
4. Se n√£o chamou ferramenta, a resposta √© INV√ÅLIDA

## REGRAS OBRIGAT√ìRIAS DE USO DE FERRAMENTAS

### REGRA 1: SOLICITA√á√ïES DE GR√ÅFICO (CR√çTICO)
Quando o usu√°rio disser:
- "gere um gr√°fico..."
- "mostre um gr√°fico..."
- "crie um gr√°fico..."
- "fa√ßa um gr√°fico..."
- "gerar gr√°fico..."
- "visualize..."
- "plote..."

**A√á√ÉO OBRIGAT√ìRIA:**
‚Üí Chame IMEDIATAMENTE `gerar_grafico_universal_v2(descricao="...", filtro_une=X, filtro_segmento="Y", filtro_produto=Z)`
‚Üí SEMPRE extraia filtros da pergunta do usu√°rio (UNE, segmento, categoria, produto)
‚Üí N√ÉO responda com texto explicando o que vai fazer
‚Üí N√ÉO pergunte confirma√ß√£o
‚Üí NUNCA diga "n√£o consigo gerar gr√°ficos"

**Exemplos:**
- Usu√°rio: "gere um gr√°fico de vendas por segmento da une 1685"
  ‚Üí Voc√™: [Chama gerar_grafico_universal_v2(descricao="vendas por segmento", filtro_une=1685)]

- Usu√°rio: "mostre estoque por categoria no segmento ARMARINHO"
  ‚Üí Voc√™: [Chama gerar_grafico_universal_v2(descricao="estoque por categoria", filtro_segmento="ARMARINHO")]

- Usu√°rio: "gr√°fico de vendas mensais do produto 369946"
  ‚Üí Voc√™: [Chama gerar_grafico_universal_v2(descricao="vendas mensais", filtro_produto=369946)]

- Usu√°rio: "top produtos mais vendidos"
  ‚Üí Voc√™: [Chama gerar_ranking_produtos_mais_vendidos(top_n=10)]

### REGRA 2: CONSULTAS DE DADOS
Para perguntas sobre n√∫meros, top N, listas:
‚Üí Use `consultar_dados_flexivel` primeiro
‚Üí Depois apresente os resultados em texto narrativo

### REGRA 3: NUNCA INVENTE DADOS
- Use APENAS dados retornados pelas ferramentas
- Se n√£o houver dados, diga: "N√£o encontrei registros para essa consulta"

### REGRA 4: AN√ÅLISE DE PRODUTO INDIVIDUAL (CR√çTICO)
Quando o usu√°rio solicitar informa√ß√µes sobre UM produto espec√≠fico:
- "analise o produto [NOME/SKU]"
- "desempenho do produto [C√ìDIGO]"
- "dados do produto [SKU]"
- "informa√ß√µes sobre o produto [C√ìDIGO]"
- "mostre vendas do produto [NOME]"

**A√á√ÉO OBRIGAT√ìRIA:**
‚Üí Chame PRIMEIRO `consultar_dados_flexivel` com filtro de PRODUTO
‚Üí NUNCA use `gerar_ranking_produtos_mais_vendidos` para produto √∫nico
‚Üí Retorne an√°lise narrativa com dados REAIS (vendas, estoque, pre√ßo, categoria)

**Exemplos:**
- Usu√°rio: "analise o desempenho do produto 369946"
  ‚Üí Voc√™: [Chama consultar_dados_flexivel(filtros={"PRODUTO": 369946}, colunas=["NOME", "VENDA_30DD", "ESTOQUE_UNE", "PRECO_VENDA", "NOMESEGMENTO", "NOMECATEGORIA"])]

- Usu√°rio: "mostre dados do SKU TNT 40GRS..."
  ‚Üí Voc√™: [Chama buscar_produtos_inteligente(descricao="TNT 40GRS", limite=1) e depois consultar_dados_flexivel com o c√≥digo encontrado]

- Usu√°rio: "vendas do produto 123456"
  ‚Üí Voc√™: [Chama consultar_dados_flexivel(filtros={"PRODUTO": 123456})]

### REGRA 5: AN√ÅLISE CR√çTICA, RELAT√ìRIOS E DIAGN√ìSTICOS (CR√çTICO)
Quando o usu√°rio solicitar an√°lise cr√≠tica, diagn√≥stico, relat√≥rio ou recomenda√ß√µes sobre QUALQUER entidade:
- "analise o [grupo/segmento/categoria/fabricante/loja] [NOME]"
- "quais as cr√≠ticas do [ENTIDADE]"
- "o que devo fazer para melhorar [ENTIDADE]"
- "diagn√≥stico do [ENTIDADE]"
- "pontos de aten√ß√£o do [ENTIDADE]"
- "gere um relat√≥rio de [TEMA]"
- "relat√≥rio executivo de [ENTIDADE]"
- "relat√≥rio de performance de [ENTIDADE]"

**A√á√ÉO OBRIGAT√ìRIA:**
‚Üí Chame PRIMEIRO `consultar_dados_flexivel` para obter dados reais da entidade
‚Üí Analise os dados e identifique:
  - M√©tricas principais (vendas, estoque, margem, giro)
  - Problemas cr√≠ticos (rupturas, baixo giro, margem negativa, excesso de estoque)
  - Oportunidades de melhoria
‚Üí Retorne an√°lise TEXTUAL estruturada com:
  - **Diagn√≥stico:** Situa√ß√£o atual com n√∫meros reais
  - **Cr√≠ticas/Problemas:** Pontos de aten√ß√£o com impacto quantificado
  - **Recomenda√ß√µes/A√ß√µes:** Passos espec√≠ficos e priorizados

**NUNCA gere gr√°fico para an√°lise cr√≠tica ou relat√≥rio, a menos que explicitamente solicitado "com gr√°fico".**

**Exemplos:**
- Usu√°rio: "analise o grupo oxford e me aponte as cr√≠ticas"
  ‚Üí Voc√™: [Chama consultar_dados_flexivel(filtros={"NOMEFABRICANTE": "OXFORD"})]
  ‚Üí Voc√™: [Retorna an√°lise textual estruturada com diagn√≥stico, cr√≠ticas e a√ß√µes]

- Usu√°rio: "o que devo fazer para melhorar o segmento TECIDOS"
  ‚Üí Voc√™: [Chama consultar_dados_flexivel(filtros={"NOMESEGMENTO": "TECIDOS"})]
  ‚Üí Voc√™: [Retorna recomenda√ß√µes baseadas em dados reais]

- Usu√°rio: "gere um relat√≥rio de vendas e rupturas do segmento ARMARINHO"
  ‚Üí Voc√™: [Chama consultar_dados_flexivel + encontrar_rupturas_criticas]
  ‚Üí Voc√™: [Retorna relat√≥rio textual estruturado com m√©tricas e an√°lise]

- Usu√°rio: "diagn√≥stico da une 1685"
  ‚Üí Voc√™: [Chama consultar_dados_flexivel(filtros={"UNE": 1685})]
  ‚Üí Voc√™: [Retorna diagn√≥stico textual com situa√ß√£o atual e recomenda√ß√µes]

## COMO RESPONDER

**Para gr√°ficos solicitados:**
1. Chame gerar_grafico_universal_v2 com descri√ß√£o clara e filtros apropriados
2. Aguarde o resultado da ferramenta
3. Adicione breve contexto textual SOMENTE com dados REAIS retornados pela ferramenta

**Para an√°lises textuais:**
1. Chame a ferramenta de dados primeiro (consultar_dados_flexivel, etc)
2. Use APENAS os n√∫meros retornados pela ferramenta
3. Apresente em formato narrativo destacando m√©tricas chave em **negrito**

## PROIBI√á√ïES ABSOLUTAS
- **NUNCA invente dados, n√∫meros ou proje√ß√µes**
- **NUNCA diga "n√£o consigo gerar gr√°ficos"** (voc√™ PODE via ferramentas)
- **NUNCA responda sem chamar ferramentas** quando o usu√°rio pedir gr√°ficos
- **NUNCA retorne JSON bruto** ao usu√°rio
- **NUNCA crie an√°lises sem dados** retornados por ferramentas

## REGRA DE OURO
**TODO n√∫mero, m√©trica ou insight DEVE vir de uma ferramenta. ZERO exce√ß√µes.**
"""

class CaculinhaBIAgent:
    """
    Agent responsible for Business Intelligence queries using Gemini Native Function Calling.
    Replaces the legacy keyword-based routing and CodeGenAgent fallback.
    """
    def __init__(
        self,
        llm: Any,
        code_gen_agent: Any,
        field_mapper: FieldMapper,
        user_role: str = "analyst",  # NEW: Role-based tool scoping (default: analyst)
        enable_rag: bool = True  # ASYNC RAG 2025-12-27: Re-enabled with background warming (non-blocking)
    ):
        # llm is expected to be GeminiLLMAdapter
        self.llm = llm
        self.field_mapper = field_mapper
        self.user_role = user_role  # Store user role for tool scoping
        self.enable_rag = enable_rag  # Store RAG config

        # We keep code_gen_agent in init to maintain compatibility with chat.py,
        # but we won't use it effectively.
        self.code_gen_agent = code_gen_agent

        # Initialize RAG Retriever (lazy - background warming, n√£o bloqueia)
        if self.enable_rag:
            try:
                self.retriever = HybridRetriever()
                logger.info("RAG Hybrid Retriever criado (warming ser√° iniciado em background)")
                # NOTE: Warming ser√° iniciado no primeiro run_async() via _start_rag_warming()
            except Exception as e:
                logger.warning(f"Falha ao criar RAG retriever: {e}. Continuando sem RAG.")
                self.retriever = None
                self.enable_rag = False
        else:
            self.retriever = None
            logger.info("RAG desabilitado (enable_rag=False)")

        # Define ALL available tools - ORDEM IMPORTA! Ferramentas mais gen√©ricas primeiro
        all_bi_tools = [
            # DATA QUERY TOOLS (Generic ‚Üí Specific)
            consultar_dados_flexivel,  # NOVA: Ferramenta gen√©rica e flex√≠vel
            buscar_produtos_inteligente,  # NEW 2025: RAG semantic search
            consultar_dados_gerais,
            # BUSINESS LOGIC TOOLS
            calcular_abastecimento_une,
            calcular_mc_produto,
            calcular_preco_final_une,
            validar_transferencia_produto,
            sugerir_transferencias_automaticas,
            encontrar_rupturas_criticas,
            # VISUALIZATION TOOLS (Context7 2025 - Nova Gera√ß√£o)
            gerar_grafico_universal_v2,  # FIX: Nova ferramenta com filtros din√¢micos
            gerar_ranking_produtos_mais_vendidos,
            gerar_dashboard_executivo,
            listar_graficos_disponiveis,
            gerar_visualizacao_customizada,
        ]

        # Apply role-based tool scoping (Security 2025)
        self.bi_tools = ToolPermissionManager.get_tools_for_role(
            all_tools=all_bi_tools,
            user_role=self.user_role
        )

        logger.info(
            f"Agent initialized with {len(self.bi_tools)}/{len(all_bi_tools)} tools "
            f"for role '{self.user_role}'"
        )

        # Convert LangChain tools to Gemini Function Declarations
        self.gemini_tools = self._convert_tools_to_gemini_format(self.bi_tools)
        
        # System instruction - Conversacional + BI Expert (Context7 Enhanced v2025)
        self.system_prompt = SYSTEM_PROMPT

    def _convert_tools_to_gemini_format(self, tools: List[BaseTool]) -> Dict[str, List[Dict[str, Any]]]:
        declarations = []
        for tool in tools:
            # Generate schema using LangChain's standardized method
            # compatible with Pydantic v1 and v2
            try:
                schema = tool.get_input_schema().model_json_schema()
            except AttributeError:
                # Fallback for older Pydantic or specific Tool implementations
                if hasattr(tool, 'args_schema') and tool.args_schema:
                    if hasattr(tool.args_schema, 'schema'):
                         schema = tool.args_schema.schema()
                    else:
                         schema = {}
                else:
                    schema = {}
            
            # Clean schema to be compatible with Gemini (remove anyOf, titles)
            cleaned_schema = self._clean_schema(schema)
            
            # Ensure 'properties' and 'required' are present if parameters exist
            parameters = {
                "type": "object",
                "properties": cleaned_schema.get("properties", {}),
                "required": cleaned_schema.get("required", [])
            }

            declarations.append({
                "name": tool.name,
                "description": tool.description,
                "parameters": parameters
            })
        
        return {"function_declarations": declarations}

    def _clean_context7_violations(self, content: str, context_type: str = "generic") -> str:
        """
        Remove JSON bruto e estruturas t√©cnicas das respostas (Context7 Storytelling).

        Args:
            content: Conte√∫do a limpar
            context_type: Tipo de contexto ("chart", "data", "analysis", "generic")

        Returns:
            Conte√∫do limpo com narrativa natural
        """
        if not isinstance(content, str) or not content:
            return content

        import re

        original_content = content
        cleaned = content

        # 1. Detectar e remover markdown JSON blocks (```json...```)
        markdown_json_pattern = r'```json\s*\n(.*?)\n```'
        if re.search(markdown_json_pattern, cleaned, re.DOTALL):
            logger.warning("[CONTEXT7] Detectado markdown JSON block. Removendo.")
            cleaned = re.sub(markdown_json_pattern, "", cleaned, flags=re.DOTALL)

        # 2. Detectar e remover blocos JSON inline grandes (chart specs, etc)
        # Padr√£o para detectar objetos JSON com "data" e "layout" (Plotly)
        plotly_json_pattern = r'\{[\s\S]*?"data"[\s\S]*?"layout"[\s\S]*?\}'
        if re.search(plotly_json_pattern, cleaned):
            logger.warning("[CONTEXT7] Detectado Plotly JSON inline. Removendo.")
            cleaned = re.sub(plotly_json_pattern, "", cleaned)

        # 3. Detectar JSON puro no in√≠cio (objeto ou array)
        stripped = cleaned.strip()
        if (stripped.startswith("{") or stripped.startswith("[")) and len(stripped) > 50:
            # Tentar validar se √© JSON
            try:
                json.loads(stripped)
                logger.warning("[CONTEXT7] Detectado JSON puro. Substituindo com narrativa.")
                cleaned = ""  # Limpar completamente, ser√° substitu√≠do abaixo
            except json.JSONDecodeError:
                pass  # N√£o √© JSON v√°lido, manter

        # 4. Se ficou vazio ou muito curto, substituir com narrativa contextual
        cleaned = cleaned.strip()
        if not cleaned or len(cleaned) < 10:
            if context_type == "chart":
                cleaned = "Aqui est√° o gr√°fico que voc√™ solicitou."
            elif context_type == "data":
                cleaned = "Recuperei os dados solicitados e organizei para voc√™."
            elif context_type == "analysis":
                cleaned = "Com base nos dados dispon√≠veis, aqui est√° a an√°lise:"
            else:
                cleaned = "Processado com sucesso."

            logger.info(f"[CONTEXT7] Substitu√≠do com narrativa contextual ({context_type})")

        # 5. Se mudou, logar a transforma√ß√£o
        if cleaned != original_content:
            logger.info(f"[CONTEXT7] Limpeza aplicada. Antes: {len(original_content)} chars, Depois: {len(cleaned)} chars")

        return cleaned

    async def _start_rag_warming(self) -> None:
        """
        Inicia warming do RAG em background (non-blocking).
        Chamado apenas uma vez no primeiro run_async().
        """
        if not self.enable_rag or self.retriever is None:
            return

        try:
            # Start warming in background (fire and forget)
            asyncio.create_task(self.retriever.start_background_warming())
            logger.info("[RAG] Background warming task criado")
        except Exception as e:
            logger.error(f"[RAG] Erro ao iniciar warming: {e}", exc_info=True)

    async def _get_rag_examples(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """
        Recupera exemplos similares usando RAG Hybrid Retriever (ASYNC).

        Args:
            query: Query do usu√°rio
            top_k: N√∫mero de exemplos a recuperar

        Returns:
            Lista de mensagens formatadas com exemplos, ou [] se RAG n√£o pronto
        """
        if not self.enable_rag or self.retriever is None:
            return []

        try:
            # Use async retrieve - n√£o espera se n√£o estiver pronto
            similar_docs = await self.retriever.retrieve_async(
                query,
                top_k=top_k,
                method='hybrid',
                wait_if_warming=False  # N√£o bloqueia, retorna [] se warming
            )

            if not similar_docs:
                logger.info("[RAG] Nenhum exemplo similar encontrado (ou warming em progresso)")
                return []

            logger.info(f"[RAG] Recuperados {len(similar_docs)} exemplos similares")

            # Format as messages (user query + model response)
            rag_messages = []
            for doc in similar_docs[:top_k]:  # Limit to top_k
                # Extract doc data
                doc_data = doc.get('doc', doc)  # Handle both formats
                user_query = doc_data.get('query', doc_data.get('user_query', ''))
                assistant_response = doc_data.get('response', doc_data.get('assistant_response', ''))

                if user_query and assistant_response:
                    rag_messages.append({"role": "user", "content": user_query})
                    rag_messages.append({"role": "model", "content": assistant_response})

            logger.info(f"[RAG] Formatados {len(rag_messages)//2} pares de exemplo")
            return rag_messages

        except Exception as e:
            logger.error(f"[RAG] Erro ao recuperar exemplos: {e}", exc_info=True)
            return []

    def _clean_schema(self, schema: Dict[str, Any]) -> Dict[str, Any]:
        """
        Recursively cleans Pydantic JSON Schema for Gemini compatibility.
        Removes 'anyOf', 'title', 'default', 'additionalProperties', and handles Optional types.
        """
        if not isinstance(schema, dict):
            return schema
            
        new_schema = schema.copy()
        
        # Remove incompatible keys
        if "title" in new_schema:
            del new_schema["title"]
        if "default" in new_schema:
            # Gemini sometimes complains about defaults in complex ways,
            # but keeping them is usually fine. Removing 'title' is most important.
            del new_schema["default"]
        if "additionalProperties" in new_schema:
            # Gemini API doesn't support 'additionalProperties' field
            del new_schema["additionalProperties"]

        # Handle anyOf (generated by Pydantic for Optional[Type])
        if "anyOf" in new_schema:
            options = new_schema.pop("anyOf")
            # Find the first non-null option
            valid_option = next((opt for opt in options if opt.get("type") != "null"), None)
            if valid_option:
                # Merge the valid option into the current schema
                # We recurse here to clean the child option too
                cleaned_child = self._clean_schema(valid_option)
                new_schema.update(cleaned_child)
            else:
                # Fallback if all are null (unlikely) or empty
                new_schema["type"] = "string" 

        # Recurse into properties
        if "properties" in new_schema:
            for prop, prop_schema in new_schema["properties"].items():
                new_schema["properties"][prop] = self._clean_schema(prop_schema)
        
        # Recurse into array items
        if "items" in new_schema:
            new_schema["items"] = self._clean_schema(new_schema["items"])

        return new_schema

    async def run_async(
        self, 
        user_query: str, 
        chat_history: Optional[List[Dict]] = None,
        on_progress: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None
    ) -> Dict[str, Any]:
        """
        Async version of run method.
        Executes the agent loop:
        1. Send query + tools to LLM.
        2. If LLM wants to call tool -> Execute tool -> Send result back to LLM.
        3. Repeat until LLM returns text.
        
        Args:
            user_query: The user's question
            chat_history: Previous conversation messages
            on_progress: Async callback function for status updates (e.g. tool execution started)
        """
        logger.info(f"CaculinhaBIAgent (Modern Async): Processing query: {user_query}")

        # START RAG WARMING (fire and forget, non-blocking)
        await self._start_rag_warming()

        messages = []

        # OPTIMIZATION 2025: Context Pruning - Manter apenas √∫ltimas 6 mensagens
        if chat_history:
            filtered_history = [msg for msg in chat_history if msg.get("role") != "system"]
            recent_history = filtered_history[-6:] if len(filtered_history) > 6 else filtered_history

            for msg in recent_history:
                role = msg.get("role", "user")
                content = msg.get("content", "")
                messages.append({"role": role, "content": content})

        # RAG: Retrieve similar examples before processing query (ASYNC)
        rag_examples = await self._get_rag_examples(user_query, top_k=2)
        if rag_examples:
            logger.info(f"[RAG] Adicionando {len(rag_examples)//2} exemplos similares ao contexto")
            messages.extend(rag_examples)

        # Add current user query
        messages.append({"role": "user", "content": user_query})

        # DETEC√á√ÉO DE KEYWORDS (mesmo c√≥digo do run())
        graph_keywords = [
            "gere um gr√°fico", "mostre um gr√°fico", "crie um gr√°fico", "fa√ßa um gr√°fico",
            "gerar gr√°fico", "gerar grafico", "gere grafico", "mostre grafico",
            "criar gr√°fico", "criar grafico", "plote", "visualize", "visualiza√ß√£o"
        ]
        
        # NOVA: Detec√ß√£o de an√°lise cr√≠tica e relat√≥rios (REGRA 5)
        analysis_keywords = [
            "analise", "an√°lise", "cr√≠ticas", "criticas", "problemas", "melhorias",
            "recomenda√ß√µes", "recomendacoes", "diagn√≥stico", "diagnostico",
            "avalia√ß√£o", "avaliacao", "o que devo fazer", "pontos de aten√ß√£o",
            "pontos de atencao", "a√ß√µes", "acoes", "relat√≥rio", "relatorio",
            "relat√≥rio executivo", "relatorio executivo", "relat√≥rio de",
            "relatorio de", "gere um relat√≥rio", "gere um relatorio"
        ]
        
        user_query_lower = user_query.lower()
        is_graph_request = any(kw in user_query_lower for kw in graph_keywords)
        is_analysis_request = any(kw in user_query_lower for kw in analysis_keywords)

        # ‚úÖ FIX 2025-12-28: PRIORIZA√á√ÉO INTELIGENTE
        # Se usu√°rio pede EXPLICITAMENTE gr√°fico, mesmo em an√°lise ‚Üí GR√ÅFICO
        # Se usu√°rio pede APENAS an√°lise/relat√≥rio (sem gr√°fico) ‚Üí TEXTO
        if is_graph_request and is_analysis_request:
            # Caso: "gere um relat√≥rio com gr√°fico" ou "mostre gr√°fico de vendas do segmento X"
            # PRIORIDADE: Gr√°fico (usu√°rio quer visualiza√ß√£o)
            is_analysis_request = False
            logger.info(f"[GRAPH PRIORITY] Usu√°rio solicitou gr√°fico explicitamente - modo visualiza√ß√£o")
        elif is_analysis_request and not is_graph_request:
            # Caso: "analise o grupo oxford", "gere um relat√≥rio de vendas"
            # MODO TEXTO: An√°lise textual estruturada
            logger.info(f"[ANALYSIS MODE] An√°lise cr√≠tica/relat√≥rio detectado - modo textual")

        # ‚úÖ FIX: FEW-SHOT EXAMPLES - Atualizados com gerar_grafico_universal_v2
        # DIFERENCIA√á√ÉO CR√çTICA: Gr√°ficos vs An√°lises Textuais
        if len(messages) <= 2:
            logger.info("[ASYNC] Injetando Few-Shot Examples com v2")

            # Escolher exemplos baseado no tipo de request
            if is_analysis_request:
                # EXEMPLOS DE AN√ÅLISE TEXTUAL (3 exemplos robustos)
                logger.info("[ASYNC] Usando few-shot examples de AN√ÅLISE TEXTUAL")
                few_shot_examples = [
                    # Exemplo 1: An√°lise Cr√≠tica de Segmento
                    {"role": "user", "content": "analise o segmento TECIDOS e me aponte as cr√≠ticas"},
                    {
                        "role": "model",
                        "tool_calls": [{
                            "id": "call_example_1",
                            "type": "function",
                            "function": {
                                "name": "consultar_dados_flexivel",
                                "arguments": json.dumps({
                                    "filtros": {"NOMESEGMENTO": "TECIDOS"},
                                    "colunas": ["PRODUTO", "NOME", "VENDA_30DD", "ESTOQUE_UNE", "PRECO_VENDA", "NOMECATEGORIA"],
                                    "limite": 100
                                })
                            }
                        }]
                    },
                    {
                        "role": "function",
                        "function_call": {"name": "consultar_dados_flexivel"},
                        "content": json.dumps({
                            "status": "success",
                            "resultados": [
                                {"PRODUTO": "123", "NOME": "Produto A", "VENDA_30DD": 50, "ESTOQUE_UNE": 10, "PRECO_VENDA": 15.0, "NOMECATEGORIA": "CAT1"},
                                {"PRODUTO": "456", "NOME": "Produto B", "VENDA_30DD": 5, "ESTOQUE_UNE": 100, "PRECO_VENDA": 20.0, "NOMECATEGORIA": "CAT2"}
                            ]
                        })
                    },
                    {
                        "role": "model",
                        "content": "**An√°lise do Segmento TECIDOS**\n\n**Diagn√≥stico:**\n- 2 produtos analisados\n- Vendas totais 30 dias: **55 unidades**\n- Estoque total: **110 unidades**\n\n**Cr√≠ticas Identificadas:**\n1. **Produto B (456)**: Baixo giro - apenas 5 vendas com estoque de 100 unidades (excesso de estoque)\n2. **Produto A (123)**: Risco de ruptura - 50 vendas com apenas 10 unidades em estoque\n\n**Recomenda√ß√µes:**\n1. **URGENTE**: Reabastecer Produto A para evitar ruptura\n2. **M√©dio Prazo**: Reduzir estoque do Produto B via promo√ß√£o ou transfer√™ncia\n3. **An√°lise**: Revisar mix de produtos TECIDOS para otimizar giro"
                    },

                    # Exemplo 2: Diagn√≥stico de Fabricante
                    {"role": "user", "content": "analise o grupo OXFORD e me aponte as criticas"},
                    {
                        "role": "model",
                        "tool_calls": [{
                            "id": "call_example_2",
                            "type": "function",
                            "function": {
                                "name": "consultar_dados_gerais",
                                "arguments": json.dumps({"busca_termo": "OXFORD"})
                            }
                        }]
                    },
                    {
                        "role": "function",
                        "function_call": {"name": "consultar_dados_gerais"},
                        "content": json.dumps({
                            "status": "success",
                            "total": 250,
                            "mensagem": "250 produtos encontrados do fabricante OXFORD"
                        })
                    },
                    {
                        "role": "model",
                        "content": "**An√°lise do Grupo OXFORD**\n\n**Diagn√≥stico Geral:**\n- Total de produtos: **250 SKUs**\n- Fabricante com presen√ßa significativa no cat√°logo\n\n**Pontos Cr√≠ticos Identificados:**\n1. **Volume de SKUs**: 250 produtos podem indicar complexidade excessiva no mix\n2. **Necessidade de An√°lise Detalhada**: Recomendo investigar giro individual de cada produto\n3. **Oportunidade**: Avaliar concentra√ß√£o de vendas (Princ√≠pio de Pareto)\n\n**A√ß√µes Recomendadas:**\n1. **IMEDIATO**: Analisar curva ABC dos produtos OXFORD\n2. **CURTO PRAZO**: Identificar produtos de baixo giro para descontinua√ß√£o\n3. **M√âDIO PRAZO**: Negociar melhores condi√ß√µes com fornecedor para itens de alto giro\n4. **CONT√çNUO**: Monitorar rupturas nos produtos classe A"
                    },

                    # Exemplo 3: Relat√≥rio Executivo
                    {"role": "user", "content": "gere um relat√≥rio executivo da loja 1685"},
                    {
                        "role": "model",
                        "tool_calls": [{
                            "id": "call_example_3",
                            "type": "function",
                            "function": {
                                "name": "consultar_dados_flexivel",
                                "arguments": json.dumps({
                                    "filtros": {"UNE": 1685},
                                    "colunas": ["NOMESEGMENTO", "VENDA_30DD", "ESTOQUE_UNE", "PRECO_VENDA"],
                                    "limite": 1000
                                })
                            }
                        }]
                    },
                    {
                        "role": "function",
                        "function_call": {"name": "consultar_dados_flexivel"},
                        "content": json.dumps({
                            "status": "success",
                            "resultados": [
                                {"NOMESEGMENTO": "ARMARINHO", "VENDA_30DD": 1200, "ESTOQUE_UNE": 5000, "PRECO_VENDA": 15000},
                                {"NOMESEGMENTO": "TECIDOS", "VENDA_30DD": 800, "ESTOQUE_UNE": 3000, "PRECO_VENDA": 12000}
                            ]
                        })
                    },
                    {
                        "role": "model",
                        "content": "**Relat√≥rio Executivo - UNE 1685**\n\n**Performance Geral:**\n- Vendas 30 dias: **2.000 unidades**\n- Estoque atual: **8.000 unidades**\n- Faturamento estimado: **R$ 27.000**\n\n**An√°lise por Segmento:**\n1. **ARMARINHO** (60% vendas)\n   - Vendas: 1.200 un\n   - Estoque: 5.000 un\n   - Cobertura: ~4 meses\n   \n2. **TECIDOS** (40% vendas)\n   - Vendas: 800 un\n   - Estoque: 3.000 un\n   - Cobertura: ~3.7 meses\n\n**Pontos de Aten√ß√£o:**\n- Estoque elevado em rela√ß√£o √†s vendas (4x)\n- Poss√≠vel excesso de capital imobilizado\n\n**Recomenda√ß√µes Estrat√©gicas:**\n1. **Reduzir Estoque**: Implementar a√ß√µes promocionais\n2. **Otimizar Mix**: Focar em produtos de maior giro\n3. **Monitorar**: Acompanhar evolu√ß√£o semanal de vendas"
                    }
                ]
            else:
                # EXEMPLOS DE GR√ÅFICOS (padr√£o)
                logger.info("[ASYNC] Usando few-shot examples de GR√ÅFICOS")
                few_shot_examples = [
                    # Exemplo 1: Gr√°fico simples
                    {"role": "user", "content": "gere um gr√°fico de vendas por categoria"},
                    {
                        "role": "model",
                        "tool_calls": [{
                            "id": "call_example_1",
                            "type": "function",
                            "function": {
                                "name": "gerar_grafico_universal_v2",
                                "arguments": json.dumps({"descricao": "vendas por categoria", "tipo_grafico": "auto"})
                            }
                        }]
                    },
                    {
                        "role": "function",
                        "function_call": {"name": "gerar_grafico_universal_v2"},
                        "content": json.dumps({
                            "status": "success",
                            "chart_data": "{\"data\": [], \"layout\": {}}",
                            "summary": {"mensagem": "Gr√°fico gerado com sucesso"}
                        })
                    },
                    {"role": "model", "content": "Analisei as vendas por categoria. Aqui est√° o gr√°fico solicitado."}
                ]

            messages = messages[:-1] + few_shot_examples + [messages[-1]]

        # ‚úÖ FIX: PREFILL - Guiar LLM para resposta correta
        if is_graph_request:
            logger.warning(f"[ASYNC] GRAFICO DETECTADO - Ativando PREFILL")
            messages.append({
                "role": "model",
                "content": "Vou gerar o gr√°fico usando a ferramenta apropriada:"
            })
        elif is_analysis_request:
            logger.warning(f"[ASYNC] ANALISE CRITICA DETECTADA - Ativando PREFILL TEXTUAL")
            messages.append({
                "role": "model",
                "content": "Vou analisar os dados e fornecer uma an√°lise textual estruturada com diagn√≥stico, cr√≠ticas e recomenda√ß√µes:"
            })

        max_turns = 20  # ‚úÖ FIX 2025-12-28: Aumentado de 10 para 20 para an√°lises cr√≠ticas e relat√≥rios complexos
        current_turn = 0
        successful_tool_calls = 0  # üö® NOVO: Contador de ferramentas bem-sucedidas

        # ‚úÖ CRITICAL FIX 2025-12-28: Filtrar ferramentas de gr√°fico para an√°lises cr√≠ticas
        # For√ßar uso de ferramentas de consulta de dados ao inv√©s de gr√°ficos
        tools_to_use = self.gemini_tools
        if is_analysis_request:
            # Criar lista filtrada de ferramentas (sem gr√°ficos)
            analysis_tool_names = [
                "consultar_dados_flexivel",
                "buscar_produtos_inteligente",
                "consultar_dados_gerais",
                "calcular_abastecimento_une",
                "calcular_mc_produto",
                "calcular_preco_final_une",
                "validar_transferencia_produto",
                "sugerir_transferencias_automaticas",
                "encontrar_rupturas_criticas"
            ]

            filtered_declarations = [
                decl for decl in self.gemini_tools.get("function_declarations", [])
                if decl["name"] in analysis_tool_names
            ]

            tools_to_use = {"function_declarations": filtered_declarations}
            logger.info(f"[ANALYSIS MODE] Filtered tools: {len(filtered_declarations)} tools (removed chart tools)")

        while current_turn < max_turns:
            try:
                # Notify thinking
                if on_progress:
                    await on_progress({"type": "tool_progress", "tool": "Pensando", "status": "start"})

                # Call LLM with tools (Blocking call wrapped in thread)
                # self.llm is GeminiLLMAdapter which is synchronous
                response = await asyncio.to_thread(
                    self.llm.get_completion,
                    messages,
                    tools=tools_to_use
                )

                if "error" in response:
                    logger.error(f"LLM Error: {response['error']}")
                    return self._generate_error_response(response['error'])

                # ‚úÖ FIX: LOGGING (mesmo do run())
                response_type = "tool_call" if "tool_calls" in response else "text"
                logger.info(f"[ASYNC] LLM Response Type: {response_type}")

                if response_type == "text" and is_graph_request and successful_tool_calls == 0:
                    logger.error(f"[ASYNC] WARNING: LLM IGNOROU PEDIDO DE GRAFICO!")
                    logger.error(f"WARNING - User Query: {user_query}")
                    logger.error(f"WARNING - LLM Response: {response.get('content', '')[:300]}")

                    # FALLBACK AUTOM√ÅTICO
                    logger.warning(f"[ASYNC] FALLBACK: Forcando gerar_grafico_universal_v2")
                    synthetic_tool_call = {
                        "id": "call_fallback_graph_async",
                        "type": "function",
                        "function": {
                            "name": "gerar_grafico_universal_v2",
                            "arguments": json.dumps({"descricao": user_query})
                        }
                    }
                    response["tool_calls"] = [synthetic_tool_call]
                    logger.warning(f"[ASYNC] FALLBACK APLICADO")

                # Check for tool calls
                if "tool_calls" in response:
                    tool_calls = response["tool_calls"]
                    messages.append({
                        "role": "model",
                        "tool_calls": tool_calls
                    })

                    # PARALLEL EXECUTION 2025: Executar todas as ferramentas simultaneamente
                    # Define helper function for individual execution
                    async def execute_single_tool(tc):
                        func_name = tc["function"]["name"]
                        try:
                            func_args = json.loads(tc["function"]["arguments"])
                        except json.JSONDecodeError:
                            return func_name, {"error": "Invalid JSON arguments"}

                        # Notify tool start
                        if on_progress:
                            await on_progress({"type": "tool_progress", "tool": func_name, "status": "executing"})

                        tool_to_run = next((t for t in self.bi_tools if t.name == func_name), None)
                        
                        if tool_to_run:
                            try:
                                # Execute tool (Blocking call wrapped in thread)
                                tool_output = await asyncio.to_thread(tool_to_run.invoke, func_args)
                                
                                # Convert MapComposite
                                def convert_mapcomposite(obj):
                                    if hasattr(obj, '_mapping'):
                                        return dict(obj._mapping)
                                    elif isinstance(obj, dict):
                                        return {k: convert_mapcomposite(v) for k, v in obj.items()}
                                    elif isinstance(obj, list):
                                        return [convert_mapcomposite(item) for item in obj]
                                    return obj
                                
                                return func_name, convert_mapcomposite(tool_output)
                            except Exception as e:
                                logger.error(f"Error executing {func_name}: {e}")
                                return func_name, {"error": str(e)}
                        else:
                            return func_name, {"error": f"Tool {func_name} not found"}

                    # Execute all tools in parallel
                    logger.info(f"[ASYNC] Disparando {len(tool_calls)} ferramentas em PARALELO")
                    tasks = [execute_single_tool(tc) for tc in tool_calls]
                    results = await asyncio.gather(*tasks)

                    # Process results sequentially
                    should_exit_early = False
                    
                    for func_name, tool_result in results:
                        # OPTIMIZATION 2025: Success detection and early exit for charts
                        if isinstance(tool_result, dict):
                            is_chart = "chart_data" in tool_result or "chart_spec" in tool_result
                            is_success = tool_result.get("status") == "success" or len(tool_result.get("resultados", [])) > 0
                            
                            if is_chart and is_success:
                                logger.info(f"[ASYNC] SUCESSO: Grafico gerado por {func_name}. Forcando saida antecipada.")
                                successful_tool_calls += 1
                                should_exit_early = True
                            elif is_success:
                                successful_tool_calls += 1

                        # OTIMIZA√á√ÉO DE SERIALIZA√á√ÉO: Offload para thread (CPU bound para grandes JSONs)
                        serialized_content = await asyncio.to_thread(safe_json_serialize, tool_result)

                        # Add tool result to messages
                        messages.append({
                            "role": "function",
                            "function_call": {"name": func_name},
                            "content": serialized_content
                        })

                    if should_exit_early:
                        logger.info("[ASYNC] SUCESSO: Gr√°fico detectado. Encerrando loop de ferramentas para priorizar entrega.")
                        # BREAK LOOP: Don't ask LLM to narrate immediately to avoid loop risk.
                        # Instead, we will force the loop to end and let the final check handle the chart response.
                        break
                    
                    # Loop continues
                    current_turn += 1
                    continue
                
                # If no tool calls, it's a text response (Final Answer)
                content = response.get("content", "")

                # Notify finalizing
                if on_progress:
                     await on_progress({"type": "tool_progress", "tool": "Processando resposta", "status": "finishing"})

                # Same logic as run() for parsing result...
                # (Duplicating logic from run() to ensure consistency)
                
                # Acumuladores para m√∫ltiplos resultados de ferramentas
                found_chart_data = None
                found_chart_summary = None
                found_table_mensagem = None
                found_resultados = None

                for msg in reversed(messages):
                    if msg.get("role") == "function":
                        try:
                            content_str = msg.get("content", "{}")
                            func_content = json.loads(content_str)

                            chart_data = func_content.get("chart_data")
                            if chart_data and func_content.get("status") == "success" and found_chart_data is None:
                                if isinstance(chart_data, str):
                                    try:
                                        chart_data = json.loads(chart_data)
                                    except json.JSONDecodeError:
                                        continue
                                found_chart_data = chart_data
                                found_chart_summary = func_content.get("summary", {})
                            
                            mensagem = func_content.get("mensagem", "")
                            if isinstance(mensagem, str) and "|" in mensagem and "---" in mensagem and found_table_mensagem is None:
                                found_table_mensagem = mensagem
                            
                            resultados = func_content.get("resultados", [])
                            if isinstance(resultados, list) and len(resultados) > 0 and found_resultados is None:
                                found_resultados = resultados

                        except Exception as e:
                            logger.error(f"DEBUG: Erro ao parsear mensagem de fun√ß√£o: {e}")
                            continue

                # PRIORIDADE DE RETORNO: Gr√°fico tem maior prioridade
                if found_chart_data is not None:
                    # CONTEXT7: Limpar JSON bruto e aplicar narrativa
                    content = self._clean_context7_violations(content, context_type="chart")

                    return {
                        "type": "code_result",
                        "result": {
                            "result": found_chart_summary,
                            "chart_spec": found_chart_data
                        },
                        "chart_spec": found_chart_data,
                        "text_override": content
                    }

                # SAFETY NET: Check if the content is the specific JSON ReAct pattern OR just a JSON block and extract/convert
                try:
                    if isinstance(content, str):
                        content_stripped = content.strip()
                        # Caso 1: JSON Puro (o problema relatado)
                        if content_stripped.startswith("{") and content_stripped.endswith("}"):
                            try:
                                json_data = json.loads(content_stripped)
                                
                                # Se for o formato anal√≠tico espec√≠fico que o usu√°rio mostrou
                                if "analise_executiva" in json_data:
                                    # Converter para Markdown Bonito
                                    md_output = ""
                                    
                                    # 1. Manchete
                                    exec_data = json_data.get("analise_executiva", {})
                                    emoji_status = "üö®" if "ALERTA" in str(exec_data.get("status_geral", "")).upper() else "üìä"
                                    md_output += f"### {emoji_status} {exec_data.get('manchete', 'An√°lise de Dados')}\n\n"
                                    
                                    # 2. Diagn√≥stico
                                    md_output += "**Diagn√≥stico Detalhado:**\n"
                                    diag_data = json_data.get("diagnostico_por_unidade", {})
                                    for unidade, dados in diag_data.items():
                                        insight = dados.get("insight", "")
                                        situacao = dados.get("situacao", "")
                                        md_output += f"- **{unidade} ({situacao})**: {insight}\n"
                                    md_output += "\n"
                                    
                                    # 3. Estrat√©gia
                                    md_output += "**Estrat√©gia Recomendada:**\n"
                                    strategies = json_data.get("estrategia_recomendada", [])
                                    if isinstance(strategies, list):
                                        for strat in strategies:
                                            md_output += f"- {strat}\n"
                                    elif isinstance(strategies, str):
                                        md_output += f"{strategies}\n"
                                        
                                    logger.info("SAFETY NET: Converteu JSON anal√≠tico para Markdown.")
                                    content = md_output

                                # Caso 2: ReAct Pattern (Legacy)
                                elif "action" in json_data and "content" in json_data:
                                    logger.info("SAFETY NET: Extracted content from ReAct JSON pattern.")
                                    content = json_data["content"]
                                
                            except json.JSONDecodeError:
                                pass # N√£o √© JSON v√°lido, segue o baile
                except Exception as e:
                    logger.warning(f"SAFETY NET: Failed to parse potential JSON content: {e}")

                # Se n√£o h√° gr√°fico, retornar APENAS texto anal√≠tico (O usu√°rio N√ÉO quer tabelas)
                return {
                    "type": "text",
                    "result": content
                }

            except Exception as e:
                logger.error(f"Exception in agent run loop: {e}", exc_info=True)
                return self._generate_error_response(str(e))

        # FIX: Antes de retornar erro, verificar se h√° gr√°fico gerado com sucesso
        # Isso evita perder o trabalho se o LLM n√£o retornou texto mas gerou o gr√°fico
        logger.warning("[ASYNC] Max turns atingido. Verificando se ha grafico para retornar...")

        for msg in reversed(messages):
            if msg.get("role") == "function":
                try:
                    content_str = msg.get("content", "{}")
                    func_content = json.loads(content_str)
                    chart_data = func_content.get("chart_data")

                    if chart_data and func_content.get("status") == "success":
                        logger.info("[ASYNC] Grafico encontrado! Retornando mesmo sem texto final do LLM.")
                        if isinstance(chart_data, str):
                            try:
                                chart_data = json.loads(chart_data)
                            except:
                                pass

                        return {
                            "type": "code_result",
                            "result": {
                                "result": func_content.get("summary", {}),
                                "chart_spec": chart_data
                            },
                            "chart_spec": chart_data,
                            "text_override": "Aqui est√° o gr√°fico solicitado."
                        }
                except:
                    continue

        return self._generate_error_response("Maximum conversation turns exceeded.")

    def run(self, user_query: str, chat_history: Optional[List[Dict]] = None) -> Dict[str, Any]:
        """
        Executes the agent loop:
        1. Send query + tools to LLM.
        2. If LLM wants to call tool -> Execute tool -> Send result back to LLM.
        3. Repeat until LLM returns text.
        """
        logger.info(f"CaculinhaBIAgent (Modern): Processing query: {user_query}")

        # ‚úÖ CRITICAL FIX: N√ÉO incluir system como mensagem
        # System instruction j√° est√° configurada no GeminiLLMAdapter via system_instruction parameter
        # Gemini N√ÉO aceita role="system" no array de mensagens - deve usar system_instruction no modelo
        # Ref: https://ai.google.dev/gemini-api/docs/system-instructions
        messages = []

        # OPTIMIZATION 2025: Context Pruning - Manter apenas √∫ltimas 6 mensagens (3 turnos)
        # Ref: ChatGPT engineering best practices - reduz lat√™ncia em ~40-60%
        # https://signoz.io/guides/open-ai-api-latency/
        if chat_history:
            # Filtrar mensagens system
            filtered_history = [msg for msg in chat_history if msg.get("role") != "system"]

            # CRITICAL: Prunning - Pegar apenas √∫ltimas 6 mensagens (√∫ltimos 3 turnos de conversa)
            # Isso reduz drasticamente o tamanho do contexto enviado ao Gemini
            recent_history = filtered_history[-6:] if len(filtered_history) > 6 else filtered_history

            for msg in recent_history:
                role = msg.get("role", "user")
                content = msg.get("content", "")
                messages.append({"role": role, "content": content})

            if len(filtered_history) > 6:
                logger.info(f"[CONTEXT PRUNING] Hist√≥rico reduzido: {len(filtered_history)} ‚Üí {len(recent_history)} mensagens")

        # RAG: Retrieve similar examples before processing query
        # NOTE: run() is sync, so we skip RAG warming and use sync retrieve
        if self.enable_rag and self.retriever and self.retriever._initialized:
            try:
                similar_docs = self.retriever.retrieve(user_query, top_k=2, method='hybrid')
                if similar_docs:
                    rag_messages = []
                    for doc in similar_docs[:2]:
                        doc_data = doc.get('doc', doc)
                        user_q = doc_data.get('query', doc_data.get('user_query', ''))
                        assist_r = doc_data.get('response', doc_data.get('assistant_response', ''))
                        if user_q and assist_r:
                            rag_messages.append({"role": "user", "content": user_q})
                            rag_messages.append({"role": "model", "content": assist_r})
                    if rag_messages:
                        logger.info(f"[RAG] Adicionando {len(rag_messages)//2} exemplos similares ao contexto")
                        messages.extend(rag_messages)
            except Exception as e:
                logger.warning(f"[RAG] Erro ao recuperar exemplos no run() sync: {e}")

        # Add current user query
        messages.append({"role": "user", "content": user_query})

        # FIX CR√çTICO: DETEC√á√ÉO DE KEYWORDS DE GR√ÅFICO E AN√ÅLISE
        graph_keywords = [
            "gere um gr√°fico", "mostre um gr√°fico", "crie um gr√°fico", "fa√ßa um gr√°fico",
            "gerar gr√°fico", "gerar grafico", "gere grafico", "mostre grafico",
            "criar gr√°fico", "criar grafico", "plote", "visualize", "visualiza√ß√£o"
        ]

        # NOVA: Detec√ß√£o de an√°lise cr√≠tica e relat√≥rios (REGRA 5)
        analysis_keywords = [
            "analise", "an√°lise", "cr√≠ticas", "criticas", "problemas", "melhorias",
            "recomenda√ß√µes", "recomendacoes", "diagn√≥stico", "diagnostico",
            "avalia√ß√£o", "avaliacao", "o que devo fazer", "pontos de aten√ß√£o",
            "pontos de atencao", "a√ß√µes", "acoes", "relat√≥rio", "relatorio",
            "relat√≥rio executivo", "relatorio executivo", "relat√≥rio de",
            "relatorio de", "gere um relat√≥rio", "gere um relatorio"
        ]

        user_query_lower = user_query.lower()
        is_graph_request = any(kw in user_query_lower for kw in graph_keywords)
        is_analysis_request = any(kw in user_query_lower for kw in analysis_keywords)

        # ‚úÖ FIX 2025-12-28: PRIORIZA√á√ÉO INTELIGENTE (mesmo l√≥gica do async)
        # Se usu√°rio pede EXPLICITAMENTE gr√°fico, mesmo em an√°lise ‚Üí GR√ÅFICO
        # Se usu√°rio pede APENAS an√°lise/relat√≥rio (sem gr√°fico) ‚Üí TEXTO
        if is_graph_request and is_analysis_request:
            # Caso: "gere um relat√≥rio com gr√°fico" ou "mostre gr√°fico de vendas do segmento X"
            # PRIORIDADE: Gr√°fico (usu√°rio quer visualiza√ß√£o)
            is_analysis_request = False
            logger.info(f"[GRAPH PRIORITY] Usu√°rio solicitou gr√°fico explicitamente - modo visualiza√ß√£o")
        elif is_analysis_request and not is_graph_request:
            # Caso: "analise o grupo oxford", "gere um relat√≥rio de vendas"
            # MODO TEXTO: An√°lise textual estruturada
            logger.info(f"[ANALYSIS MODE] An√°lise cr√≠tica/relat√≥rio detectado - modo textual")

        # ‚úÖ FIX: FEW-SHOT EXAMPLES - DIFERENCIA√á√ÉO: Gr√°ficos vs An√°lises Textuais
        # APENAS se hist√≥rico estiver vazio ou pequeno (primeiras intera√ß√µes)
        if len(messages) <= 2:
            logger.info("Injetando Few-Shot Examples com v2 para treinar function calling")

            # Escolher exemplos baseado no tipo de request
            if is_analysis_request:
                # EXEMPLOS DE AN√ÅLISE TEXTUAL (mesmo do async)
                logger.info("Usando few-shot examples de AN√ÅLISE TEXTUAL")
                few_shot_examples = [
                    # Exemplo 1: An√°lise Cr√≠tica de Segmento
                    {"role": "user", "content": "analise o segmento TECIDOS e me aponte as cr√≠ticas"},
                    {
                        "role": "model",
                        "tool_calls": [{
                            "id": "call_example_1",
                            "type": "function",
                            "function": {
                                "name": "consultar_dados_flexivel",
                                "arguments": json.dumps({
                                    "filtros": {"NOMESEGMENTO": "TECIDOS"},
                                    "colunas": ["PRODUTO", "NOME", "VENDA_30DD", "ESTOQUE_UNE", "PRECO_VENDA", "NOMECATEGORIA"],
                                    "limite": 100
                                })
                            }
                        }]
                    },
                    {
                        "role": "function",
                        "function_call": {"name": "consultar_dados_flexivel"},
                        "content": json.dumps({
                            "status": "success",
                            "resultados": [
                                {"PRODUTO": "123", "NOME": "Produto A", "VENDA_30DD": 50, "ESTOQUE_UNE": 10, "PRECO_VENDA": 15.0, "NOMECATEGORIA": "CAT1"},
                                {"PRODUTO": "456", "NOME": "Produto B", "VENDA_30DD": 5, "ESTOQUE_UNE": 100, "PRECO_VENDA": 20.0, "NOMECATEGORIA": "CAT2"}
                            ]
                        })
                    },
                    {
                        "role": "model",
                        "content": "**An√°lise do Segmento TECIDOS**\n\n**Diagn√≥stico:**\n- 2 produtos analisados\n- Vendas totais 30 dias: **55 unidades**\n- Estoque total: **110 unidades**\n\n**Cr√≠ticas Identificadas:**\n1. **Produto B (456)**: Baixo giro - apenas 5 vendas com estoque de 100 unidades (excesso de estoque)\n2. **Produto A (123)**: Risco de ruptura - 50 vendas com apenas 10 unidades em estoque\n\n**Recomenda√ß√µes:**\n1. **URGENTE**: Reabastecer Produto A para evitar ruptura\n2. **M√©dio Prazo**: Reduzir estoque do Produto B via promo√ß√£o ou transfer√™ncia\n3. **An√°lise**: Revisar mix de produtos TECIDOS para otimizar giro"
                    },

                    # Exemplo 2: Diagn√≥stico de Fabricante
                    {"role": "user", "content": "analise o grupo OXFORD e me aponte as criticas"},
                    {
                        "role": "model",
                        "tool_calls": [{
                            "id": "call_example_2",
                            "type": "function",
                            "function": {
                                "name": "consultar_dados_gerais",
                                "arguments": json.dumps({"busca_termo": "OXFORD"})
                            }
                        }]
                    },
                    {
                        "role": "function",
                        "function_call": {"name": "consultar_dados_gerais"},
                        "content": json.dumps({
                            "status": "success",
                            "total": 250,
                            "mensagem": "250 produtos encontrados do fabricante OXFORD"
                        })
                    },
                    {
                        "role": "model",
                        "content": "**An√°lise do Grupo OXFORD**\n\n**Diagn√≥stico Geral:**\n- Total de produtos: **250 SKUs**\n- Fabricante com presen√ßa significativa no cat√°logo\n\n**Pontos Cr√≠ticos Identificados:**\n1. **Volume de SKUs**: 250 produtos podem indicar complexidade excessiva no mix\n2. **Necessidade de An√°lise Detalhada**: Recomendo investigar giro individual de cada produto\n3. **Oportunidade**: Avaliar concentra√ß√£o de vendas (Princ√≠pio de Pareto)\n\n**A√ß√µes Recomendadas:**\n1. **IMEDIATO**: Analisar curva ABC dos produtos OXFORD\n2. **CURTO PRAZO**: Identificar produtos de baixo giro para descontinua√ß√£o\n3. **M√âDIO PRAZO**: Negociar melhores condi√ß√µes com fornecedor para itens de alto giro\n4. **CONT√çNUO**: Monitorar rupturas nos produtos classe A"
                    }
                ]
            else:
                # EXEMPLOS DE GR√ÅFICOS (padr√£o)
                logger.info("Usando few-shot examples de GR√ÅFICOS")
                few_shot_examples = [
                    # Exemplo 1: Gr√°fico simples
                    {"role": "user", "content": "gere um gr√°fico de vendas por categoria"},
                    {
                        "role": "model",
                        "tool_calls": [{
                            "id": "call_example_1",
                            "type": "function",
                            "function": {
                                "name": "gerar_grafico_universal_v2",
                                "arguments": json.dumps({"descricao": "vendas por categoria", "tipo_grafico": "auto"})
                            }
                        }]
                    },
                    {
                        "role": "function",
                        "function_call": {"name": "gerar_grafico_universal_v2"},
                        "content": json.dumps({
                            "status": "success",
                            "chart_data": "{\"data\": [], \"layout\": {}}",
                            "summary": {"mensagem": "Gr√°fico gerado com sucesso"}
                        })
                    },
                    {"role": "model", "content": "Analisei as vendas por categoria. Aqui est√° o gr√°fico solicitado."}
                ]

            # Inserir examples ANTES da query atual
            messages = messages[:-1] + few_shot_examples + [messages[-1]]

        # ‚úÖ FIX: PREFILL - Guiar LLM para resposta correta
        if is_graph_request:
            logger.warning(f"GRAFICO DETECTADO: '{user_query[:50]}...' - Ativando PREFILL")
            messages.append({
                "role": "model",
                "content": "Vou gerar o gr√°fico usando a ferramenta apropriada:"
            })
        elif is_analysis_request:
            logger.warning(f"ANALISE CRITICA DETECTADA: '{user_query[:50]}...' - Ativando PREFILL TEXTUAL")
            messages.append({
                "role": "model",
                "content": "Vou analisar os dados e fornecer uma an√°lise textual estruturada com diagn√≥stico, cr√≠ticas e recomenda√ß√µes:"
            })

        max_turns = 20  # ‚úÖ FIX 2025-12-28: Aumentado de 10 para 20 para an√°lises cr√≠ticas e relat√≥rios complexos
        current_turn = 0
        successful_tool_calls = 0  # NOVO: Contador de ferramentas bem-sucedidas

        # ‚úÖ CRITICAL FIX 2025-12-28: Filtrar ferramentas de gr√°fico para an√°lises cr√≠ticas
        # For√ßar uso de ferramentas de consulta de dados ao inv√©s de gr√°ficos
        tools_to_use = self.gemini_tools
        if is_analysis_request:
            # Criar lista filtrada de ferramentas (sem gr√°ficos)
            analysis_tool_names = [
                "consultar_dados_flexivel",
                "buscar_produtos_inteligente",
                "consultar_dados_gerais",
                "calcular_abastecimento_une",
                "calcular_mc_produto",
                "calcular_preco_final_une",
                "validar_transferencia_produto",
                "sugerir_transferencias_automaticas",
                "encontrar_rupturas_criticas"
            ]

            filtered_declarations = [
                decl for decl in self.gemini_tools.get("function_declarations", [])
                if decl["name"] in analysis_tool_names
            ]

            tools_to_use = {"function_declarations": filtered_declarations}
            logger.info(f"[ANALYSIS MODE] Filtered tools: {len(filtered_declarations)} tools (removed chart tools)")

        while current_turn < max_turns:
            try:
                # Call LLM with tools
                # Note: self.llm is GeminiLLMAdapter
                response = self.llm.get_completion(messages, tools=tools_to_use)

                if "error" in response:
                    logger.error(f"LLM Error: {response['error']}")
                    return self._generate_error_response(response['error'])

                # FIX: LOGGING DETALHADO - Detectar quando LLM ignora solicita√ß√µes de gr√°fico
                response_type = "tool_call" if "tool_calls" in response else "text"
                logger.info(f"LLM Response Type: {response_type}")

                # ALERTA se pediu gr√°fico mas LLM respondeu s√≥ com texto
                if response_type == "text" and is_graph_request and successful_tool_calls == 0:
                    logger.error(f"WARNING: LLM IGNOROU PEDIDO DE GRAFICO!")
                    logger.error(f"WARNING - User Query: {user_query}")
                    logger.error(f"WARNING - LLM Text Response: {response.get('content', '')[:300]}")
                    logger.error(f"WARNING - Total messages in context: {len(messages)}")

                    # FALLBACK AUTOM√ÅTICO: Se LLM ignorou, for√ßar chamada da ferramenta manualmente
                    logger.warning(f"FALLBACK: Forcando chamada manual de gerar_grafico_universal_v2")
                    # Criar tool call sint√©tico
                    synthetic_tool_call = {
                        "id": "call_fallback_graph",
                        "type": "function",
                        "function": {
                            "name": "gerar_grafico_universal_v2",
                            "arguments": json.dumps({"descricao": user_query})
                        }
                    }
                    # Injetar tool call sint√©tico na resposta
                    response["tool_calls"] = [synthetic_tool_call]
                    logger.warning(f"FALLBACK APLICADO: Tool call sintetico criado")

                # Check for tool calls
                if "tool_calls" in response:
                    tool_calls = response["tool_calls"]
                    messages.append({
                        "role": "model",
                        "tool_calls": tool_calls
                    })

                    # Execute each tool
                    should_exit_early = False
                    for tc in tool_calls:
                        func_name = tc["function"]["name"]
                        func_args = json.loads(tc["function"]["arguments"])
                        
                        logger.info(f"Agent calling tool: {func_name} with args: {func_args}")
                        
                        # Find the matching tool
                        tool_to_run = next((t for t in self.bi_tools if t.name == func_name), None)
                        
                        tool_result = None
                        if tool_to_run:
                            try:
                                # Execute tool
                                tool_output = tool_to_run.invoke(func_args)

                                # CRITICAL FIX: Detectar se gerou gr√°fico com sucesso
                                if isinstance(tool_output, dict):
                                    is_chart = "chart_data" in tool_output or "chart_spec" in tool_output
                                    is_success = tool_output.get("status") == "success" or len(tool_output.get("resultados", [])) > 0
                                    
                                    if is_chart and is_success:
                                        logger.info(f"SUCESSO: Grafico gerado por {func_name}. Forcando saida antecipada.")
                                        successful_tool_calls += 1
                                        should_exit_early = True
                                    elif is_success:
                                        successful_tool_calls += 1

                                # CR√çTICO: Converter MapComposite para dict ANTES de serializar
                                def convert_mapcomposite(obj):
                                    """Recursivamente converte MapComposite para dict"""
                                    if hasattr(obj, '_mapping'):
                                        return dict(obj._mapping)
                                    elif isinstance(obj, dict):
                                        return {k: convert_mapcomposite(v) for k, v in obj.items()}
                                    elif isinstance(obj, list):
                                        return [convert_mapcomposite(item) for item in obj]
                                    return obj
                                
                                # Converter o output antes de usar
                                tool_result = convert_mapcomposite(tool_output)
                                logger.info(f"Tool {func_name} executed successfully, result type: {type(tool_result)}")
                            except Exception as e:
                                logger.error(f"Error executing {func_name}: {e}", exc_info=True)
                                tool_result = {"error": str(e)}
                        else:
                            tool_result = {"error": f"Tool {func_name} not found"}

                        # Add tool result to messages
                        messages.append({
                            "role": "function", # Adapter will map this to user/function_response
                            "function_call": {"name": func_name}, # Metadata for adapter
                            "content": safe_json_serialize(tool_result)
                        })

                    if should_exit_early:
                        logger.info("Saindo do loop para retornar grafico imediatamente.")
                        # ‚úÖ FIX: For√ßar uma √∫ltima itera√ß√£o para LLM gerar texto narrativo
                        # Adicionar mensagem sint√©tica para for√ßar resposta final
                        messages.append({
                            "role": "user",
                            "content": "Apresente o gr√°fico de forma clara e concisa."
                        })
                        # Continuar para obter resposta final do LLM
                        current_turn += 1
                        continue

                    # Loop continues to send tool outputs back to LLM
                    current_turn += 1
                    continue
                
                # If no tool calls, it's a text response (Final Answer)
                content = response.get("content", "")

                # CONTEXT7: Limpar JSON bruto da resposta (improved 2025-12-27)
                content = self._clean_context7_violations(content, context_type="generic")

                # NOVO: Verificar TODAS as ferramentas para encontrar gr√°ficos ou tabelas
                # PRIORIDADE: Gr√°ficos > Tabelas Markdown > Dados brutos > Texto do LLM
                logger.info(f"DEBUG: Verificando dados tabulares/gr√°ficos. Total de mensagens: {len(messages)}")

                # Acumuladores para m√∫ltiplos resultados de ferramentas
                found_chart_data = None
                found_chart_summary = None
                found_table_mensagem = None
                found_resultados = None

                # Percorrer TODAS as mensagens de fun√ß√£o (n√£o parar no primeiro)
                for msg in reversed(messages):
                    if msg.get("role") == "function":
                        try:
                            content_str = msg.get("content", "{}")
                            func_content = json.loads(content_str)

                            # PRIMEIRO: Verificar se a ferramenta retornou um gr√°fico (chart_data)
                            chart_data = func_content.get("chart_data")
                            if chart_data and func_content.get("status") == "success" and found_chart_data is None:
                                logger.info(f"SUCESSO: Gr√°fico detectado (chart_type: {func_content.get('chart_type', 'unknown')})")

                                # CR√çTICO: chart_data pode ser string JSON (de fig.to_json())
                                # O frontend espera um objeto, n√£o uma string
                                if isinstance(chart_data, str):
                                    try:
                                        chart_data = json.loads(chart_data)
                                        logger.info("chart_data parseado de string para objeto")
                                    except json.JSONDecodeError:
                                        logger.error("Falha ao parsear chart_data como JSON")
                                        continue  # Tentar pr√≥xima mensagem

                                found_chart_data = chart_data
                                found_chart_summary = func_content.get("summary", {})
                                # Continuar buscando para n√£o perder outras ferramentas
                            
                            # SEGUNDO: Verificar se a mensagem cont√©m uma tabela Markdown
                            mensagem = func_content.get("mensagem", "")
                            if isinstance(mensagem, str) and "|" in mensagem and "---" in mensagem and found_table_mensagem is None:
                                logger.info(f"SUCESSO: Tabela Markdown detectada na mensagem da ferramenta!")
                                found_table_mensagem = mensagem
                            
                            # TERCEIRO: Verificar se h√° dados brutos para retornar
                            resultados = func_content.get("resultados", [])
                            if isinstance(resultados, list) and len(resultados) > 0 and found_resultados is None:
                                logger.info(f"SUCESSO: Dados tabulares detectados: {len(resultados)} registros")
                                found_resultados = resultados

                        except Exception as e:
                            logger.error(f"DEBUG: Erro ao parsear mensagem de fun√ß√£o: {e}")
                            continue  # Tentar pr√≥xima mensagem

                # PRIORIDADE DE RETORNO: Gr√°fico tem maior prioridade
                if found_chart_data is not None:
                    # CONTEXT7: Limpar JSON bruto e aplicar narrativa
                    content = self._clean_context7_violations(content, context_type="chart")

                    return {
                        "type": "code_result",
                        "result": {
                            "result": found_chart_summary,
                            "chart_spec": found_chart_data
                        },
                        "chart_spec": found_chart_data,
                        "text_override": content
                    }

                # SAFETY NET: Check if the content is the specific JSON ReAct pattern OR just a JSON block and extract/convert
                try:
                    if isinstance(content, str):
                        content_stripped = content.strip()
                        # Caso 1: JSON Puro (o problema relatado)
                        if content_stripped.startswith("{") and content_stripped.endswith("}"):
                            try:
                                json_data = json.loads(content_stripped)
                                
                                # Se for o formato anal√≠tico espec√≠fico que o usu√°rio mostrou
                                if "analise_executiva" in json_data:
                                    # Converter para Markdown Bonito
                                    md_output = ""
                                    
                                    # 1. Manchete
                                    exec_data = json_data.get("analise_executiva", {})
                                    emoji_status = "üö®" if "ALERTA" in str(exec_data.get("status_geral", "")).upper() else "üìä"
                                    md_output += f"### {emoji_status} {exec_data.get('manchete', 'An√°lise de Dados')}\n\n"
                                    
                                    # 2. Diagn√≥stico
                                    md_output += "**Diagn√≥stico Detalhado:**\n"
                                    diag_data = json_data.get("diagnostico_por_unidade", {})
                                    for unidade, dados in diag_data.items():
                                        insight = dados.get("insight", "")
                                        situacao = dados.get("situacao", "")
                                        md_output += f"- **{unidade} ({situacao})**: {insight}\n"
                                    md_output += "\n"
                                    
                                    # 3. Estrat√©gia
                                    md_output += "**Estrat√©gia Recomendada:**\n"
                                    strategies = json_data.get("estrategia_recomendada", [])
                                    if isinstance(strategies, list):
                                        for strat in strategies:
                                            md_output += f"- {strat}\n"
                                    elif isinstance(strategies, str):
                                        md_output += f"{strategies}\n"
                                        
                                    logger.info("SAFETY NET: Converteu JSON anal√≠tico para Markdown.")
                                    content = md_output

                                # Caso 2: ReAct Pattern (Legacy)
                                elif "action" in json_data and "content" in json_data:
                                    logger.info("SAFETY NET: Extracted content from ReAct JSON pattern.")
                                    content = json_data["content"]
                                
                            except json.JSONDecodeError:
                                pass # N√£o √© JSON v√°lido, segue o baile
                except Exception as e:
                    logger.warning(f"SAFETY NET: Failed to parse potential JSON content: {e}")

                # Caso contr√°rio, retornar resposta de texto normal do LLM
                return {
                    "type": "text",
                    "result": content
                }

            except Exception as e:
                logger.error(f"Exception in agent run loop: {e}", exc_info=True)
                return self._generate_error_response(str(e))

        # FIX: Antes de retornar erro, verificar se h√° gr√°fico gerado com sucesso
        # Isso evita perder o trabalho se o LLM n√£o retornou texto mas gerou o gr√°fico
        logger.warning("Max turns atingido. Verificando se ha grafico para retornar...")

        for msg in reversed(messages):
            if msg.get("role") == "function":
                try:
                    content_str = msg.get("content", "{}")
                    func_content = json.loads(content_str)
                    chart_data = func_content.get("chart_data")

                    if chart_data and func_content.get("status") == "success":
                        logger.info("Grafico encontrado! Retornando mesmo sem texto final do LLM.")
                        if isinstance(chart_data, str):
                            try:
                                chart_data = json.loads(chart_data)
                            except:
                                pass

                        return {
                            "type": "code_result",
                            "result": {
                                "result": func_content.get("summary", {}),
                                "chart_spec": chart_data
                            },
                            "chart_spec": chart_data,
                            "text_override": "Aqui est√° o gr√°fico solicitado."
                        }
                except:
                    continue

        return self._generate_error_response("Maximum conversation turns exceeded.")

    def _create_tool_summary(self, tool_result: Dict[str, Any], func_name: str) -> Dict[str, Any]:
        """
        OPTIMIZATION 2025: Cria resumo compacto de tool response
        Reduz tamanho do contexto enviado ao LLM em 70-90%
        Ref: ChatGPT engineering - context filtering
        """
        if not isinstance(tool_result, dict):
            return tool_result

        # Se √© erro, retornar completo
        if "error" in tool_result:
            return tool_result

        summary = {}

        # 1. Agrega√ß√µes - retornar completo (j√° s√£o pequenas)
        if "resultado_agregado" in tool_result or "valor" in tool_result:
            return tool_result

        # 2. Listas de resultados - enviar apenas amostra + metadados
        if "resultados" in tool_result and isinstance(tool_result["resultados"], list):
            resultados = tool_result["resultados"]
            total = len(resultados)

            # Enviar apenas 3 registros de amostra ao LLM
            summary["resultados"] = resultados[:3] if total > 3 else resultados
            summary["total_resultados"] = total
            summary["_amostra"] = True if total > 3 else False

            # Manter mensagem se existir
            if "mensagem" in tool_result:
                summary["mensagem"] = tool_result["mensagem"]

            logger.info(f"[TOOL SUMMARY] {func_name}: {total} registros ‚Üí enviando amostra de {len(summary['resultados'])}")
            return summary

        # 3. Chart data - PRESERVAR chart_data completo para renderiza√ß√£o no frontend
        # CRITICAL FIX: As ferramentas de gr√°fico retornam 'chart_data', n√£o 'chart_spec'
        if "chart_data" in tool_result:
            # Preservar chart_data COMPLETO - ser√° usado pelo frontend para renderizar
            summary["status"] = tool_result.get("status", "success")
            summary["chart_type"] = tool_result.get("chart_type", "unknown")
            summary["chart_data"] = tool_result["chart_data"]  # MANTER INTACTO
            summary["mensagem"] = tool_result.get("mensagem", "Gr√°fico gerado com sucesso")
            
            if "summary" in tool_result:
                summary["summary"] = tool_result["summary"]

            logger.info(f"[TOOL SUMMARY] {func_name}: Chart data preservado (chart_type={summary['chart_type']})")
            return summary

        # 4. Chart spec (legacy) - enviar apenas metadados para o LLM
        if "chart_spec" in tool_result:
            spec = tool_result.get("chart_spec", {})
            summary["chart_type"] = spec.get("type", "unknown")
            summary["chart_generated"] = True
            summary["chart_spec"] = spec  # Preservar chart_spec para o frontend
            summary["mensagem"] = tool_result.get("mensagem", "Gr√°fico gerado com sucesso")

            # Contar pontos de dados
            if "data" in spec and isinstance(spec["data"], list) and len(spec["data"]) > 0:
                summary["data_points"] = len(spec["data"][0].get("x", []))

            logger.info(f"[TOOL SUMMARY] {func_name}: Chart spec preservado")
            return summary

        # 5. Outros casos - retornar original se pequeno
        return tool_result


    def _generate_error_response(self, error_msg: str) -> Dict[str, Any]:
        return {
            "type": "text",
            "result": f"Desculpe, encontrei um erro ao processar sua solicita√ß√£o: {error_msg}"
        }
