# üõ°Ô∏è PROMPT ROBUSTO - SQL SERVER + PARQUET H√çBRIDO

**Prop√≥sito:** Garantir que futuras altera√ß√µes no sistema n√£o quebrem a integra√ß√£o SQL Server + Parquet
**Data:** 04/10/2025
**Autor:** Claude Code

---

## ‚ö†Ô∏è REGRAS CR√çTICAS - NUNCA QUEBRAR

### **1. HybridDataAdapter √© OBRIGAT√ìRIO**

‚ùå **NUNCA FA√áA:**
```python
# ERRADO: Criar ParquetAdapter diretamente
adapter = ParquetAdapter('data/parquet/admmat.parquet')
```

‚úÖ **SEMPRE FA√áA:**
```python
# CORRETO: Usar HybridDataAdapter
from core.connectivity.hybrid_adapter import HybridDataAdapter
adapter = HybridDataAdapter()  # Tenta SQL Server, fallback Parquet autom√°tico
```

---

### **2. Compatibilidade de Interface**

O `HybridDataAdapter` DEVE implementar os mesmos m√©todos que `ParquetAdapter`:

```python
class HybridDataAdapter:
    def connect(self):
        """Conecta ao adapter ativo."""
        pass

    def disconnect(self):
        """Desconecta adapter ativo."""
        pass

    def execute_query(self, query_filters: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Executa query com fallback autom√°tico."""
        pass

    def get_schema(self) -> str:
        """Retorna schema da fonte ativa."""
        pass

    def get_status(self) -> Dict[str, Any]:
        """Status do adapter (debugging)."""
        pass

    # Propriedades para compatibilidade com DirectQueryEngine
    @property
    def _dataframe(self):
        """Retorna DataFrame do parquet_adapter."""
        pass

    def _load_dataframe(self):
        """Carrega DataFrame (delega para parquet_adapter)."""
        pass
```

**SE ADICIONAR NOVOS M√âTODOS EM `ParquetAdapter`, ADICIONE TAMB√âM EM `HybridDataAdapter`!**

---

### **3. Mapeamento de Colunas SQL Server ‚Üî Parquet**

**Tabela SQL Server: `ADMMATAO` (colunas MAI√öSCULAS)**
**Parquet: `admmat.parquet` (colunas min√∫sculas)**

**Mapeamento cr√≠tico:**
```python
column_mapping = {
    # SQL Server ‚Üí Parquet
    'UNE': 'une',
    'PRODUTO': 'codigo',
    'NOME': 'nome_produto',
    'UNE_NOME': 'une_nome',
    'NOMESEGMENTO': 'nomesegmento',
    'LIQUIDO_38': 'preco_38_percent',
    'MES_01': 'mes_01',
    'MES_02': 'mes_02',
    # ... (95 colunas no total)
    'ESTOQUE_UNE': 'estoque_atual',
    'VENDA_30DD': 'venda_30_d',
}
```

**SE ADICIONAR/REMOVER COLUNAS:**
1. Atualizar `export_sqlserver_to_parquet.py` (linha ~120)
2. Atualizar `HybridDataAdapter._build_sql_query()` (linha ~220)
3. Exportar novo Parquet: `python scripts/export_sqlserver_to_parquet.py`

---

### **4. Configura√ß√£o .env OBRIGAT√ìRIA**

**Vari√°veis cr√≠ticas:**
```env
# Flag principal
USE_SQL_SERVER=true  # ou false

# Conex√£o SQL Server (obrigat√≥rias se USE_SQL_SERVER=true)
MSSQL_SERVER=FAMILIA\SQLJR,1433
MSSQL_DATABASE=Projeto_Caculinha
MSSQL_USER=AgenteVirtual
MSSQL_PASSWORD=Cacula@2020
DB_DRIVER=ODBC Driver 17 for SQL Server
DB_TRUST_SERVER_CERTIFICATE=yes

# Seguran√ßa
SQL_SERVER_TIMEOUT=10            # Timeout em segundos
FALLBACK_TO_PARQUET=true         # NUNCA false em produ√ß√£o!
```

**NUNCA comite `.env` com credenciais!**
**SEMPRE use `.env.example` como template.**

---

### **5. Parquet SEMPRE Dispon√≠vel**

O sistema DEVE funcionar mesmo se SQL Server falhar.

**Teste obrigat√≥rio antes de qualquer deploy:**
```bash
# 1. SQL Server desligado ‚Üí app funciona?
USE_SQL_SERVER=false
streamlit run streamlit_app.py

# 2. SQL Server ligado ‚Üí app funciona?
USE_SQL_SERVER=true
streamlit run streamlit_app.py

# 3. SQL Server cai durante execu√ß√£o ‚Üí fallback funciona?
python scripts/test_hybrid_connection.py
```

---

## üìù CHECKLIST DE ALTERA√á√ïES SEGURAS

Antes de modificar qualquer arquivo relacionado:

### **A. Modificar `HybridDataAdapter`:**
- [ ] Testar com SQL Server ON: `USE_SQL_SERVER=true`
- [ ] Testar com SQL Server OFF: `USE_SQL_SERVER=false`
- [ ] Executar: `python scripts/test_hybrid_connection.py`
- [ ] Verificar fallback autom√°tico funciona
- [ ] N√£o quebrou compatibilidade com `DirectQueryEngine`

### **B. Modificar `streamlit_app.py`:**
- [ ] HybridDataAdapter continua sendo usado (linha ~186)
- [ ] Backend retorna `parquet_adapter` (que √© HybridDataAdapter)
- [ ] Status mostrado no sidebar (admin only)
- [ ] Fallback transparente em `query_backend()`

### **C. Adicionar/Remover Colunas:**
- [ ] Atualizar mapeamento em `export_sqlserver_to_parquet.py`
- [ ] Atualizar mapeamento em `HybridDataAdapter._build_sql_query()`
- [ ] Exportar novo Parquet: `python scripts/export_sqlserver_to_parquet.py`
- [ ] Validar Parquet: `python -c "import pandas as pd; df = pd.read_parquet('data/parquet/admmat.parquet'); print(df.columns)"`
- [ ] Testar consultas antigas ainda funcionam

### **D. Modificar Configura√ß√µes SQL Server:**
- [ ] Atualizar `.env`
- [ ] Testar conex√£o: `python scripts/test_hybrid_connection.py`
- [ ] Se mudar estrutura de tabela, exportar novo Parquet
- [ ] Validar em ambiente de teste ANTES de produ√ß√£o

---

## üö® ERROS COMUNS E COMO EVITAR

### **Erro 1: ImportError: cannot import name 'HybridDataAdapter'**

**Causa:** C√≥digo importando ParquetAdapter ao inv√©s de HybridDataAdapter

**Solu√ß√£o:**
```python
# ANTES (errado)
from core.connectivity.parquet_adapter import ParquetAdapter
adapter = ParquetAdapter(...)

# DEPOIS (correto)
from core.connectivity.hybrid_adapter import HybridDataAdapter
adapter = HybridDataAdapter()
```

---

### **Erro 2: KeyError: 'parquet_adapter' not found**

**Causa:** Backend n√£o retornou `parquet_adapter` (HybridDataAdapter)

**Solu√ß√£o:**
```python
# streamlit_app.py linha ~265
return {
    "llm_adapter": llm_adapter,
    "parquet_adapter": data_adapter,  # ‚Üê DEVE ser HybridDataAdapter!
    "code_gen_agent": code_gen_agent,
    "agent_graph": agent_graph,
    "query_history": query_history
}
```

---

### **Erro 3: SQL Server conecta mas retorna dados vazios**

**Causa:** Query SQL malformada ou colunas mapeadas incorretamente

**Debug:**
```python
# HybridDataAdapter._build_sql_query()
# Adicionar log:
logger.info(f"SQL Query: {sql_query}")

# Testar query diretamente:
python -c "
import pyodbc
conn = pyodbc.connect('...')
cursor = conn.cursor()
cursor.execute('SELECT TOP 10 * FROM ADMMATAO WHERE UNE = 261')
print(cursor.fetchall())
"
```

---

### **Erro 4: Fallback n√£o funciona**

**Causa:** `FALLBACK_TO_PARQUET=false` ou Parquet corrompido

**Solu√ß√£o:**
```bash
# 1. Verificar .env
grep FALLBACK_TO_PARQUET .env
# Deve ser: FALLBACK_TO_PARQUET=true

# 2. Validar Parquet
python -c "import pandas as pd; df = pd.read_parquet('data/parquet/admmat.parquet'); print(len(df))"

# 3. Restaurar backup se necess√°rio
copy data\parquet\admmat_backup_*.parquet data\parquet\admmat.parquet
```

---

## üîß MANUTEN√á√ÉO PERI√ìDICA

### **Semanal:**
- [ ] Executar: `python scripts/export_sqlserver_to_parquet.py`
- [ ] Validar Parquet atualizado com dados SQL Server
- [ ] Testar diagn√≥stico: `python scripts/test_hybrid_connection.py`

### **Mensal:**
- [ ] Revisar logs de fallback (quantas vezes SQL Server caiu?)
- [ ] Otimizar queries lentas
- [ ] Limpar backups antigos de Parquet (`admmat_backup_*.parquet`)

### **Antes de cada Apresenta√ß√£o:**
- [ ] Executar diagn√≥stico completo
- [ ] Validar SQL Server conecta
- [ ] Testar 10 perguntas aleat√≥rias das 80
- [ ] Preparar Plano B (rollback .env)

---

## üìã TEMPLATE DE PULL REQUEST

Ao submeter altera√ß√µes relacionadas ao HybridDataAdapter:

```markdown
## Descri√ß√£o
[Descrever mudan√ßa]

## Checklist Obrigat√≥rio
- [ ] Testado com `USE_SQL_SERVER=true`
- [ ] Testado com `USE_SQL_SERVER=false`
- [ ] Executado `python scripts/test_hybrid_connection.py` (sucesso)
- [ ] Fallback autom√°tico validado
- [ ] Compatibilidade com DirectQueryEngine OK
- [ ] Nenhuma credencial commitada

## Testes Realizados
```bash
# Comandos executados:
python scripts/test_hybrid_connection.py
streamlit run streamlit_app.py
# ... adicionar outros testes
```

## Rollback Plan
[Como desfazer se quebrar?]
```

---

## üéØ PROMPT PARA FUTURAS IMPLEMENTA√á√ïES

**Use este prompt ao pedir altera√ß√µes ao sistema:**

```
Preciso [DESCRI√á√ÉO DA MUDAN√áA].

IMPORTANTE: Este sistema usa HybridDataAdapter (SQL Server + Parquet fallback).

REGRAS CR√çTICAS:
1. NUNCA quebrar compatibilidade com HybridDataAdapter
2. SEMPRE manter Parquet como fallback funcional
3. SEMPRE atualizar mapeamento de colunas se necess√°rio
4. SEMPRE testar com SQL Server ON e OFF
5. SEMPRE executar python scripts/test_hybrid_connection.py ap√≥s mudan√ßas

Arquivos cr√≠ticos:
- core/connectivity/hybrid_adapter.py (n√£o quebrar interface)
- streamlit_app.py (linha ~186: usa HybridDataAdapter)
- scripts/export_sqlserver_to_parquet.py (mapeamento de colunas)
- scripts/test_hybrid_connection.py (valida√ß√£o)

Documenta√ß√£o:
- docs/GUIA_MIGRACAO_SQLSERVER_COMPLETO.md
- docs/PROMPT_ROBUSTO_SQLSERVER_PARQUET.md (este arquivo)

Por favor, implemente a mudan√ßa seguindo essas regras e forne√ßa:
1. C√≥digo modificado
2. Testes executados
3. Plano de rollback se quebrar
```

---

## ‚úÖ VALIDA√á√ÉO FINAL

Antes de considerar qualquer altera√ß√£o completa:

```bash
# 1. Diagn√≥stico completo
python scripts/test_hybrid_connection.py

# 2. Exportar Parquet atualizado
python scripts/export_sqlserver_to_parquet.py

# 3. Iniciar aplica√ß√£o
streamlit run streamlit_app.py

# 4. Testar 10 perguntas
# - Produto mais vendido
# - Top 10 produtos UNE 261
# - Ranking de vendas por UNE
# - Vendas totais de cada UNE
# - Top 10 produtos segmento TECIDOS
# - Evolu√ß√£o vendas √∫ltimos 12 meses
# - Produtos sem movimento
# - An√°lise ABC
# - Compara√ß√£o de segmentos
# - Estoque alto

# 5. Validar status no sidebar (admin)
# Deve mostrar:
# - Fonte de dados (SQL Server ou Parquet)
# - Status de conex√£o
# - N√∫mero de produtos e UNEs
```

**SUCESSO:** Todas as 10 perguntas respondem em <2s sem erros.

---

## üéâ CONCLUS√ÉO

Este documento garante que:
- ‚úÖ Futuras altera√ß√µes n√£o quebrem o sistema
- ‚úÖ SQL Server + Parquet continuam funcionando em harmonia
- ‚úÖ Fallback autom√°tico sempre dispon√≠vel
- ‚úÖ Zero downtime em produ√ß√£o
- ‚úÖ F√°cil manuten√ß√£o e debug

**Mantenha este documento atualizado ao fazer altera√ß√µes!**
