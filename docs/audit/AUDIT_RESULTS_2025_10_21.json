{
  "logging_config": {
    "chave": "logging_config",
    "arquivo": "C:\\Users\\André\\Documents\\Agent_Solution_BI\\core\\config\\logging_config.py",
    "existe": true,
    "tamanho_bytes": 11180,
    "linhas": 329,
    "conteudo_preview": "\"\"\"\nMódulo de configuração de logging com structured logging (Context7).\nFornece: setup_logging\n\"\"\"\n\nimport logging\nimport logging.config\nimport os\nimport sys\nimport json\nfrom datetime import datetime\nfrom pathlib import Path\n\n# Tentar importar structlog\ntry:\n    import structlog\n    STRUCTLOG_AVAILABLE = True\nexcept ImportError:\n    STRUCTLOG_AVAILABLE = False\n    structlog = None\n\n\ndef setup_logging(debug_mode: bool = False):\n    \"\"\"\n    Configura logging estruturado usando structlog + stdlib.\n\n    Features:\n    - JSON output para produção\n    - Console colorido para desenvolvimento\n    - Thread/processo tracking\n    - Contexto automático (func_name, lineno)\n    - Rotação de arquivos\n    - Performance otimizada\n\n    Args:\n        debug_mode: Ativa nível DEBUG (default: False = INFO)\n    \"\"\"\n    # Caminhos\n    project_root = Path(__file__).parent.parent.parent\n    logs_dir = project_root / \"logs\"",
    "verificacoes": {
      "tem_setup_logging": true,
      "tem_filehandler": true,
      "tem_logging_import": true,
      "tem_rotatinghandler": true,
      "tem_logs_dir": true,
      "tem_get_logger": true,
      "tem_plan_a_logging": false
    },
    "problemas": [],
    "oportunidades": []
  },
  "streamlit_app": {
    "chave": "streamlit_app",
    "arquivo": "C:\\Users\\André\\Documents\\Agent_Solution_BI\\streamlit_app.py",
    "existe": true,
    "tamanho_bytes": 82128,
    "linhas": 1794,
    "conteudo_preview": "'''\nInterface de Usuário (Frontend) para o Agent_BI.\nVersão integrada que não depende de API externa.\nCache clear trigger: 2025-09-21 20:52 - ValidationError fix applied\n'''\nfrom dotenv import load_dotenv\n\n# Forçar o recarregamento das variáveis de ambiente do arquivo .env\n# Isso é crucial em desenvolvimento para evitar problemas de cache.\nload_dotenv(override=True)\nimport streamlit as st\nimport uuid\nimport pandas as pd\nimport logging\nimport sys\nimport time\nimport re\nfrom datetime import datetime\n\n# ============================================================================\n# CONFIGURAÇÃO DE LOGGING ESTRUTURADO\n# Usa sistema centralizado de logs (logs/app_activity/, logs/errors/, etc.)\n# ============================================================================\nfrom core.config.logging_config import setup_logging\n\n# Inicializar sistema de logs estruturado\nsetup_logging()\n\n# Configurar logger específico do Streamlit\nlogger = logging.getLogger(\"streamlit_app\")\nlogger.setLevel(logging.INFO)  # INFO para rastrear atividades\n\n# Silenciar logs verbosos de bibliotecas externas\nlogging.getLogger(\"faiss\").setLevel(logging.ERROR)\nlogging.getLogger(\"sentence_transformers\").setLevel(logging.ERROR)\nlogging.getLogger(\"httpx\").setLevel(logging.ERROR)\n\n# Log de inicialização\nlogger.info(\"=\" * 80)\nlogger.info(\"[STARTUP] Streamlit App Iniciado\")",
    "verificacoes": {
      "tem_import_logging": true,
      "chama_setup_logging": true,
      "tem_logging_call": true,
      "primeira_30_linhas": "'''\nInterface de Usuário (Frontend) para o Agent_BI.\nVersão integrada que não depende de API externa.\nCache clear trigger: 2025-09-21 20:52 - ValidationError fix applied\n'''\nfrom dotenv import load_dotenv\n\n# Forçar o recarregamento das variáveis de ambiente do arquivo .env\n# Isso é crucial em desenvolvimento para evitar problemas de cache.\nload_dotenv(override=True)\nimport streamlit as st\nimport uuid\nimport pandas as pd\nimport logging\nimport sys\nimport time\nimport re\nfrom datetime import datetime\n\n# ============================================================================\n# CONFIGURAÇÃO DE LOGGING ESTRUTURADO\n# Usa sistema centralizado de logs (logs/app_activity/, logs/errors/, etc.)\n# ============================================================================\nfrom core.config.logging_config import setup_logging\n\n# Inicializar sistema de logs estruturado\nsetup_logging()\n\n# Configurar logger específico do Streamlit\nlogger = logging.getLogger(\"streamlit_app\")"
    },
    "problemas": [],
    "oportunidades": []
  },
  "direct_query_engine": {
    "chave": "direct_query_engine",
    "arquivo": "C:\\Users\\André\\Documents\\Agent_Solution_BI\\core\\business_intelligence\\direct_query_engine.py",
    "existe": false,
    "tamanho_bytes": 0,
    "linhas": 0,
    "conteudo_preview": "",
    "verificacoes": {},
    "problemas": [
      "ARQUIVO NAO EXISTE: C:\\Users\\André\\Documents\\Agent_Solution_BI\\core\\business_intelligence\\direct_query_engine.py"
    ],
    "oportunidades": []
  },
  "parquet_adapter": {
    "chave": "parquet_adapter",
    "arquivo": "C:\\Users\\André\\Documents\\Agent_Solution_BI\\core\\connectivity\\parquet_adapter.py",
    "existe": true,
    "tamanho_bytes": 2874,
    "linhas": 71,
    "conteudo_preview": "\"\"\"\nMódulo para core/connectivity/parquet_adapter.py. Define a classe principal 'ParquetAdapter'. Fornece funções utilitárias, incluindo 'connect' e outras. Realiza operações de processamento de dados com Dask.\n\nATUALIZADO 2025-10-20: Agora usa PolarsDaskAdapter internamente (arquitetura híbrida).\n\"\"\"\n\n# core/connectivity/parquet_adapter.py\n\nimport logging\nimport re\nfrom typing import Any, Dict, List, Optional\nimport pandas as pd\nimport dask.dataframe as dd  # Mantido para compatibilidade\nimport os\n\nfrom .base import DatabaseAdapter\nfrom .polars_dask_adapter import PolarsDaskAdapter  # NOVO: Adapter híbrido\n\nlogger = logging.getLogger(__name__)\n\nclass ParquetAdapter(DatabaseAdapter):\n    \"\"\"\n    Adapter for Parquet files usando PolarsDaskAdapter (híbrido Polars+Dask).\n\n    Mantém 100% compatibilidade com interface anterior, mas agora usa:\n    - Polars para arquivos < 500MB (8.1x mais rápido)\n    - Dask para arquivos >= 500MB (escalável)\n    - Fallback automático Polars → Dask em caso de erro\n    \"\"\"\n\n    def __init__(self, file_path: str):\n        # Validação básica mantida (compatibilidade)\n        if \"*\" not in file_path and not os.path.exists(file_path):\n            raise FileNotFoundError(f\"Parquet file not found at: {file_path}\")\n        elif \"*\" in file_path:\n            import glob\n            base_dir = os.path.dirname(file_path)\n            if not os.path.exists(base_dir):\n                raise FileNotFoundError(f\"Parquet directory not found at: {base_dir}\")\n            matching_files = glob.glob(file_path)",
    "verificacoes": {
      "tem_logger": true,
      "tem_load_data": false
    },
    "problemas": [],
    "oportunidades": []
  }
}