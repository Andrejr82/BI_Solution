# Plano de Migra√ß√£o: Arquitetura H√≠brida Polars + Dask

**Data:** 2025-10-20
**Autor:** Claude Code
**Status:** Em Execu√ß√£o
**Objetivo:** Implementar arquitetura h√≠brida que escolhe automaticamente entre Polars (8.1x mais r√°pido) e Dask (escal√°vel) sem quebrar o projeto

---

## üìã Sum√°rio Executivo

### Contexto
- **Problema:** Queries lentas com Dask (3-8s) em 30+ tabelas com milh√µes de linhas
- **Solu√ß√£o:** Arquitetura h√≠brida que usa Polars para 90% das queries (r√°pidas) e Dask para 10% (tabelas muito grandes)
- **Ganho esperado:** 5-8x mais r√°pido, 20-30% menos RAM

### Estrat√©gia
- **Sem quebra:** Interface DatabaseAdapter mantida
- **Fallback seguro:** Polars falha ‚Üí Dask automaticamente
- **Decis√£o autom√°tica:** Threshold 500MB (configur√°vel)
- **Rollback r√°pido:** < 5 minutos se necess√°rio

---

## üéØ Objetivos e M√©tricas

| M√©trica | Antes (Dask) | Meta (H√≠brido) | Como Medir |
|---------|--------------|----------------|------------|
| Tempo m√©dio query | 4-9s | 1-2s | test_80_perguntas_completo.py |
| Uso de RAM | ~15GB | ~10-12GB | psutil durante queries |
| Taxa de sucesso | 95% | ‚â•95% | Suite de testes |
| Queries/minuto | ~10 | ~40 | Benchmark stress test |

---

## üìä An√°lise de Viabilidade

### Dados do Projeto
- **Tabelas:** 30+ arquivos Parquet
- **Dataset exemplo:** admmat.parquet (1.1M linhas, 93.83 MB)
- **Estimativa total:** ~33M linhas, ~2.8 GB
- **Benchmark:** Polars 8.1x mais r√°pido que Dask (ver BENCHMARK_DATAFRAMES_POLARS_VS_DASK.md)

### Decis√£o Arquitetural

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         HYBRID ADAPTER (INTELIGENTE)        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                             ‚îÇ
‚îÇ  Arquivo < 500MB  ‚Üí  POLARS (8.1x r√°pido) ‚îÇ
‚îÇ  Arquivo ‚â• 500MB  ‚Üí  DASK (escal√°vel)     ‚îÇ
‚îÇ  Erro Polars      ‚Üí  DASK (fallback)      ‚îÇ
‚îÇ                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Justificativa:**
- 90% das tabelas < 500MB ‚Üí Polars (queries instant√¢neas)
- 10% das tabelas ‚â• 500MB ‚Üí Dask (escalabilidade garantida)
- Zero mudan√ßa na interface ‚Üí compatibilidade total

---

## üèóÔ∏è Arquitetura da Solu√ß√£o

### Estrutura de Classes

```
DatabaseAdapter (interface)
    ‚Üë
    |
ParquetAdapter (mantido - delega)
    ‚Üì
HybridAdapter (NOVO - decisor inteligente)
    ‚îú‚îÄ‚îÄ PolarsEngine (NOVO - r√°pido)
    ‚îî‚îÄ‚îÄ DaskEngine (atual - escal√°vel)
```

### Fluxo de Decis√£o

```python
def execute_query(filters):
    1. Detectar tamanho do arquivo
    2. SE tamanho < 500MB:
         TENTAR Polars
         SE falhar ‚Üí Fallback Dask
       SEN√ÉO:
         Usar Dask
    3. Validar integridade (checksum)
    4. Retornar resultado
```

---

## üìÖ Cronograma de Implementa√ß√£o

### FASE 1: PREPARA√á√ÉO E AN√ÅLISE (4h)

#### 1.1 Script de An√°lise de Tabelas
**Arquivo:** `scripts/analyze_all_tables.py`

**Funcionalidades:**
- Escanear todos os .parquet em data/parquet/
- Coletar m√©tricas: tamanho, linhas, colunas
- Classificar por engine recomendada
- Gerar relat√≥rio JSON + console

**Output esperado:**
```json
{
  "total_tables": 30,
  "total_size_gb": 2.8,
  "total_rows": 33000000,
  "polars_recommended": 27,
  "dask_recommended": 3,
  "threshold_mb": 500,
  "tables": [
    {
      "name": "admmat.parquet",
      "size_mb": 93.8,
      "rows": 1113822,
      "columns": 97,
      "engine": "polars"
    }
  ]
}
```

#### 1.2 Instalar Polars
```bash
pip install polars==1.34.0
pip freeze > requirements.txt
```

**Valida√ß√£o:**
- Import polars sem erro
- Dask mantido (coexist√™ncia)
- Testes existentes passam

---

### FASE 2: IMPLEMENTA√á√ÉO CORE (4h)

#### 2.1 HybridAdapter
**Arquivo:** `core/connectivity/hybrid_adapter.py`

**Classe principal:**
```python
class HybridAdapter(DatabaseAdapter):
    POLARS_THRESHOLD_MB = 500

    def __init__(self, file_path: str):
        self.file_path = file_path
        self.size_mb = self._get_file_size_mb()
        self.engine = self._select_engine()

    def execute_query(self, filters):
        try:
            if self.engine == "polars":
                return self._execute_polars(filters)
        except Exception as e:
            logger.warning(f"Polars failed, fallback to Dask: {e}")
            return self._execute_dask(filters)

    def _execute_polars(self, filters):
        # Implementa√ß√£o Polars com lazy evaluation
        pass

    def _execute_dask(self, filters):
        # Implementa√ß√£o atual (c√≥digo do ParquetAdapter)
        pass
```

**Recursos cr√≠ticos:**
- ‚úÖ Detec√ß√£o autom√°tica de tamanho
- ‚úÖ Fallback Polars‚ÜíDask em exce√ß√µes
- ‚úÖ Valida√ß√£o de integridade (checksum)
- ‚úÖ Logging detalhado de decis√µes
- ‚úÖ Feature flag (POLARS_ENABLED env var)

#### 2.2 Compatibilidade com Filtros PyArrow
- Manter l√≥gica de predicate pushdown
- Converter filtros para sintaxe Polars
- Manter convers√£o de tipos (ESTOQUE_UNE string‚Üínumeric)

---

### FASE 3: TESTES DE SEGURAN√áA (4h)

#### 3.1 Testes Unit√°rios
**Arquivo:** `tests/test_hybrid_adapter.py`

**Casos de teste:**
```python
def test_auto_select_polars_small_file():
    # Arquivo < 500MB ‚Üí deve usar Polars

def test_auto_select_dask_large_file():
    # Arquivo ‚â• 500MB ‚Üí deve usar Dask

def test_fallback_polars_to_dask():
    # Simular erro Polars ‚Üí fallback Dask

def test_data_integrity():
    # Mesmo resultado Polars vs Dask

def test_performance_threshold():
    # Polars deve ser < 2x tempo Dask
```

#### 3.2 Valida√ß√£o de Integridade
**Arquivo:** `tests/test_data_integrity.py`

**Valida√ß√µes:**
1. Mesmo n√∫mero de linhas
2. Mesmo schema (colunas + tipos)
3. Mesmos valores agregados (¬±0.01%)
4. Mesma ordena√ß√£o (TOP 10)

**Crit√©rio:** 100% dos testes passam antes de migra√ß√£o

---

### FASE 4: MIGRA√á√ÉO GRADUAL (4h)

#### 4.1 Backup
```bash
mkdir backup_before_hybrid_20251020
cp core/connectivity/parquet_adapter.py backup_before_hybrid_20251020/
cp core/agents/code_gen_agent.py backup_before_hybrid_20251020/
git add -A
git commit -m "backup: Before hybrid Polars+Dask migration"
```

#### 4.2 Migrar ParquetAdapter
**Estrat√©gia:** Delega√ß√£o interna (sem quebrar interface)

```python
# core/connectivity/parquet_adapter.py
class ParquetAdapter(DatabaseAdapter):
    def __init__(self, file_path: str):
        # Valida√ß√µes originais mantidas
        self._hybrid = HybridAdapter(file_path)  # NOVO
        logger.info(f"ParquetAdapter usando HybridAdapter (Polars+Dask)")

    def execute_query(self, filters):
        return self._hybrid.execute_query(filters)  # Delega√ß√£o

    # connect(), disconnect(), get_schema() delegam tamb√©m
```

**Vantagem:** Zero mudan√ßa em c√≥digo que usa ParquetAdapter

#### 4.3 Atualizar CodeGenAgent
**Arquivo:** `core/agents/code_gen_agent.py`

**Mudan√ßas m√≠nimas:**
```python
# Adicionar import (opcional, para suporte futuro)
import polars as pl  # NOVO

# load_data() continua retornando Pandas
# (convers√£o Polars‚ÜíPandas feita internamente no HybridAdapter)
```

**Sem quebra:** LLM continua gerando c√≥digo Pandas/Dask normalmente

---

## üõ°Ô∏è Estrat√©gias de Seguran√ßa

### 1. Fallback Autom√°tico em M√∫ltiplos N√≠veis

```python
# N√≠vel 1: Erro na execu√ß√£o
try:
    result = self._execute_polars(query)
except Exception as e:
    logger.warning(f"Polars failed: {e}")
    result = self._execute_dask(query)

# N√≠vel 2: Valida√ß√£o de resultado
if not self._validate_result(result):
    logger.error("Result validation failed, retrying with Dask")
    result = self._execute_dask(query)

# N√≠vel 3: Feature flag global
if os.getenv("POLARS_ENABLED", "true") == "false":
    return self._execute_dask(query)  # Bypass Polars
```

### 2. Valida√ß√£o de Integridade

```python
def _validate_result(self, result):
    """Valida integridade do resultado."""
    if not result or len(result) == 0:
        return True  # Resultado vazio v√°lido

    # Verificar tipos esperados
    if not isinstance(result, list):
        return False

    # Verificar estrutura de dicts
    if not all(isinstance(r, dict) for r in result):
        return False

    return True
```

### 3. Rollback R√°pido

```bash
# Reverter para vers√£o anterior (< 5 minutos)
git checkout backup_before_hybrid_20251020
pip install -r requirements.txt
# Sistema volta ao estado Dask puro
```

### 4. Monitoramento Detalhado

```python
logger.info(f"üöÄ HybridAdapter decision:")
logger.info(f"  File: {self.file_path}")
logger.info(f"  Size: {self.size_mb:.1f}MB")
logger.info(f"  Engine: {self.engine}")
logger.info(f"  Threshold: {self.POLARS_THRESHOLD_MB}MB")

# Em produ√ß√£o, adicionar m√©tricas
metrics = {
    "engine_used": self.engine,
    "query_time": end_time - start_time,
    "rows_returned": len(result),
    "fallback_occurred": fallback_flag
}
```

---

## üß™ Plano de Testes

### Testes de Unidade (Fase 3)
- [x] Sele√ß√£o autom√°tica de engine
- [x] Fallback Polars‚ÜíDask
- [x] Integridade de dados
- [x] Performance threshold
- [x] Tratamento de erros

### Testes de Integra√ß√£o (P√≥s-implementa√ß√£o)
- [ ] Suite de 80 perguntas (subset de 20)
- [ ] Queries em tabela pequena (Polars)
- [ ] Queries em tabela grande (Dask)
- [ ] Agrega√ß√µes complexas
- [ ] Joins entre tabelas

### Testes de Stress (Opcional)
- [ ] 10 queries simult√¢neas
- [ ] Query em tabela 10M+ linhas
- [ ] Join entre 3 tabelas
- [ ] Uso de RAM sob carga

---

## üìä Crit√©rios de Sucesso

### M√≠nimos (Obrigat√≥rios)
- ‚úÖ Zero quebra de funcionalidade existente
- ‚úÖ Taxa de sucesso ‚â• 95% nos testes
- ‚úÖ Rollback funcional em < 5 minutos
- ‚úÖ Fallback Polars‚ÜíDask funciona 100%

### Desej√°veis (Performance)
- ‚è≥ Tempo m√©dio query reduzido em 5x
- ‚è≥ Uso de RAM reduzido em 20%
- ‚è≥ 90% queries usam Polars
- ‚è≥ Zero timeouts

---

## üîß Configura√ß√£o e Vari√°veis de Ambiente

### Novas Vari√°veis (.env)

```bash
# Ativar/desativar Polars globalmente
POLARS_ENABLED=true

# Threshold para decis√£o Polars vs Dask (em MB)
POLARS_THRESHOLD_MB=500

# For√ßar Dask para debug
FORCE_DASK=false

# Ativar valida√ß√£o de integridade (checksum)
VALIDATE_INTEGRITY=true
```

### Configura√ß√£o Din√¢mica

```python
# Ajustar threshold baseado em RAM dispon√≠vel
import psutil

available_ram_gb = psutil.virtual_memory().available / (1024**3)

if available_ram_gb > 16:
    POLARS_THRESHOLD_MB = 1000  # Mais Polars
elif available_ram_gb < 8:
    POLARS_THRESHOLD_MB = 200   # Mais Dask
else:
    POLARS_THRESHOLD_MB = 500   # Padr√£o
```

---

## üìà Impacto Esperado

### Por Tipo de Query

| Tipo de Query | Engine | Antes | Depois | Ganho |
|---------------|--------|-------|--------|-------|
| Filtro simples (ex: segmento=TECIDOS) | Polars | 3s | 0.2s | **15x** |
| Agrega√ß√£o (GroupBy + Sum) | Polars | 0.2s | 0.04s | **5x** |
| Ranking TOP 100 | Polars | 5s | 0.8s | **6x** |
| Join tabelas grandes | Dask | 10s | 10s | **Igual** |
| Query tabela 10M+ linhas | Dask | 15s | 15s | **Igual** |

### Experi√™ncia do Usu√°rio

**Antes:**
```
Usu√°rio: "Quais os produtos do segmento TECIDOS?"
Sistema: [aguardando 3s...] ‚è≥
Resposta: Encontrei 140.790 produtos
```

**Depois:**
```
Usu√°rio: "Quais os produtos do segmento TECIDOS?"
Sistema: [aguardando 0.2s...] ‚ö°
Resposta: Encontrei 140.790 produtos
```

**Percep√ß√£o:** De "lento" para "instant√¢neo"

---

## üö® Riscos e Mitiga√ß√µes

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| Polars falha em query espec√≠fica | M√©dia | Baixo | Fallback autom√°tico para Dask |
| Incompatibilidade de tipos | Baixa | M√©dio | Valida√ß√£o de integridade + testes |
| Consumo de RAM maior que esperado | Baixa | M√©dio | Threshold configur√°vel + monitoramento |
| Performance n√£o atinge meta | Baixa | Alto | Benchmark antes de deploy + rollback |
| Bug em produ√ß√£o | Baixa | Alto | Feature flag + rollback r√°pido |

---

## üìù Checklist de Execu√ß√£o

### Fase 1: Prepara√ß√£o ‚úÖ
- [ ] Criar script analyze_all_tables.py
- [ ] Executar an√°lise de todas as tabelas
- [ ] Instalar Polars (pip install polars==1.34.0)
- [ ] Validar instala√ß√£o (import polars)

### Fase 2: Implementa√ß√£o ‚úÖ
- [ ] Criar core/connectivity/hybrid_adapter.py
- [ ] Implementar _execute_polars()
- [ ] Implementar _execute_dask() (reuso c√≥digo atual)
- [ ] Implementar _select_engine()
- [ ] Implementar fallback autom√°tico
- [ ] Adicionar valida√ß√£o de integridade

### Fase 3: Testes ‚úÖ
- [ ] Criar tests/test_hybrid_adapter.py
- [ ] Criar tests/test_data_integrity.py
- [ ] Executar testes unit√°rios (100% pass)
- [ ] Validar integridade Polars vs Dask

### Fase 4: Migra√ß√£o ‚úÖ
- [ ] Fazer backup (git commit + pasta backup/)
- [ ] Migrar ParquetAdapter (delega√ß√£o)
- [ ] Atualizar CodeGenAgent (import polars)
- [ ] Executar testes de regress√£o
- [ ] Validar zero quebra

---

## üìö Refer√™ncias

### Documentos do Projeto
- `docs/reports/BENCHMARK_DATAFRAMES_POLARS_VS_DASK.md` - Benchmark completo
- `core/connectivity/parquet_adapter.py` - Implementa√ß√£o atual Dask
- `core/connectivity/base.py` - Interface DatabaseAdapter
- `tests/test_80_perguntas_completo.py` - Suite de valida√ß√£o

### Documenta√ß√£o Externa
- Polars User Guide: https://pola-rs.github.io/polars/
- Polars API Reference: https://pola-rs.github.io/polars/py-polars/html/reference/
- Dask DataFrame: https://docs.dask.org/en/stable/dataframe.html
- Pandas‚ÜíPolars Migration: https://pola-rs.github.io/polars/user-guide/migration/pandas/

---

## üéØ Pr√≥ximos Passos Ap√≥s Implementa√ß√£o

### Curto Prazo (Semana 1)
1. Executar suite completa de 80 perguntas
2. Coletar m√©tricas de performance reais
3. Ajustar threshold baseado em dados reais
4. Documentar casos de uso Polars vs Dask

### M√©dio Prazo (Semana 2-4)
1. Otimizar queries Polars espec√≠ficas
2. Implementar cache de resultados
3. Adicionar dashboard de monitoramento
4. Treinar equipe em sintaxe Polars

### Longo Prazo (M√™s 2+)
1. Migrar 100% queries para Polars (quando poss√≠vel)
2. Deprecar Dask para tabelas pequenas
3. Implementar streaming Polars para tabelas grandes
4. Benchmark com datasets maiores (50M+ linhas)

---

## ‚úÖ Crit√©rios de Aprova√ß√£o para Deploy

- [ ] Todos os testes unit√°rios passam (100%)
- [ ] Testes de integridade validados (Polars = Dask)
- [ ] Subset de 20 perguntas com sucesso ‚â•95%
- [ ] Rollback testado e funcional
- [ ] Backup completo realizado
- [ ] Feature flag POLARS_ENABLED configurada
- [ ] Logging detalhado ativo
- [ ] Documenta√ß√£o atualizada

---

**√öltima atualiza√ß√£o:** 2025-10-20
**Pr√≥xima revis√£o:** Ap√≥s execu√ß√£o das Fases 1-4
**Respons√°vel:** Claude Code + Andr√© (valida√ß√£o)
