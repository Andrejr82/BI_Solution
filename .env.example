# ----------------------------------------------------
# Chaves e Modelos de API para os LLMs
# IMPORTANTE: Sistema migrado para Gemini/DeepSeek apenas
# ----------------------------------------------------

# --- Gemini (LLM Principal) ---
# Cole a chave da API do Google AI Studio aqui
GEMINI_API_KEY="sua_chave_gemini_aqui"
# Modelo mais rápido e econômico: gemini-2.5-flash-lite (887 tok/s)
LLM_MODEL_NAME="gemini-2.5-flash"

# --- DeepSeek (Fallback Automático) ---
# Cole a chave da API do DeepSeek aqui
DEEPSEEK_API_KEY="sua_chave_deepseek_aqui"
# Modelo econômico do DeepSeek
DEEPSEEK_MODEL_NAME="deepseek-chat"

# ----------------------------------------------------
# Configurações do SQL Server
# ----------------------------------------------------
DB_SERVER=seu_servidor_sql
DB_NAME=seu_banco_dados
DB_USER=seu_usuario
DB_PASSWORD=sua_senha

# Driver ODBC
DB_DRIVER=ODBC Driver 17 for SQL Server
DB_TRUST_SERVER_CERTIFICATE=yes

# ----------------------------------------------------
# Configurações de Segurança
# ----------------------------------------------------

# DESENVOLVIMENTO APENAS: Ativar bypass de autenticação
# ⚠️ ATENÇÃO: NUNCA defina como "true" em produção!
# Permite login com usuário "admin" e senha "bypass" para testes
ENABLE_DEV_BYPASS=false

# ----------------------------------------------------
# Sistema de Query Inteligente (NOVO - LLM Classifier)
# ----------------------------------------------------

# Ativar o novo sistema de classificação com LLM
# true = Usa IntentClassifier + GenericExecutor (consome tokens Gemini)
# false = Usa sistema antigo de regex patterns (ZERO tokens)
# SEGURO: Se der erro no novo, faz fallback automático para o antigo
USE_LLM_CLASSIFIER=false

# Ativar cache de queries (economiza tokens)
# true = Armazena queries frequentes (reduz 50-80% uso de tokens)
# false = Sempre classifica com LLM
USE_QUERY_CACHE=true

# TTL do cache em horas (0 = sem expiração)
QUERY_CACHE_TTL_HOURS=24
