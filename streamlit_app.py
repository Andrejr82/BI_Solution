'''
Interface de Usu√°rio (Frontend) para o Agent_BI.
Vers√£o integrada que n√£o depende de API externa.
Cache clear trigger: 2025-09-21 20:52 - ValidationError fix applied
'''
from dotenv import load_dotenv

# For√ßar o recarregamento das vari√°veis de ambiente do arquivo .env
# Isso √© crucial em desenvolvimento para evitar problemas de cache.
load_dotenv(override=True)
import streamlit as st
import uuid
import pandas as pd
import logging
import sys
import time
import re
from datetime import datetime

# ============================================================================
# CONFIGURA√á√ÉO DE LOGGING ESTRUTURADO
# Usa sistema centralizado de logs (logs/app_activity/, logs/errors/, etc.)
# ============================================================================
from core.config.logging_config import setup_logging
from core.security import mask_pii, get_pii_summary
from core.llm_service import get_llm_service

# Inicializar sistema de logs estruturado
setup_logging()

# Configurar logger espec√≠fico do Streamlit
logger = logging.getLogger("streamlit_app")
logger.setLevel(logging.INFO)  # INFO para rastrear atividades

# Silenciar logs verbosos de bibliotecas externas
logging.getLogger("faiss").setLevel(logging.ERROR)
logging.getLogger("sentence_transformers").setLevel(logging.ERROR)
logging.getLogger("httpx").setLevel(logging.ERROR)

# Log de inicializa√ß√£o
logger.info("=" * 80)
logger.info("[STARTUP] Streamlit App Iniciado")
logger.info(f"[STARTUP] Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
logger.info("=" * 80)

# ============================================================================
# LIMPEZA AUTOM√ÅTICA DE CACHE
# Executa limpeza inteligente de cache com versionamento autom√°tico
# Configur√°vel via .env ou Streamlit secrets:
#   - CACHE_AUTO_CLEAN (default: True)
#   - CACHE_MAX_AGE_DAYS (default: 7)
#   - CACHE_FORCE_CLEAN (default: False)
# ============================================================================
from core.utils.cache_cleaner import run_cache_cleanup
from core.config.settings import get_settings

# ‚úÖ OTIMIZA√á√ÉO v2.2.3: Cache cleanup DESABILITADO no startup (ganho de 1-2s)
# Executa apenas ap√≥s login bem-sucedido (n√£o cr√≠tico para inicializa√ß√£o)
# Reduz tempo de startup de 8s ‚Üí 6s

# ============================================================================
# ============================================================================
# CSS CUSTOMIZADO - DESIGN MINIMALISTA CLEAN (v3.0)
# Otimizado para performance m√°xima
# Data: 20/11/2025
# ============================================================================

@st.cache_data
def load_optimized_css():
    """Carrega CSS otimizado (cached para performance)"""
    css = """
/* ü§ç DESIGN MINIMALISTA CLEAN - Performance Optimized */
:root {
    --bg-primary: #FFFFFF;
    --bg-secondary: #F8F9FA;
    --bg-card: #FFFFFF;
    --bg-input: #FFFFFF;
    --bg-sidebar: #F8F9FA;
    --border: #E5E7EB;
    --border-focus: #3B82F6;
    --text-primary: #111827;
    --text-secondary: #6B7280;
    --text-tertiary: #9CA3AF;
    --accent: #3B82F6;
    --success: #10B981;
    --error: #EF4444;
}

/* ==================== GLOBAL - FOR√áAR LIGHT THEME ==================== */
/* For√ßar fundo branco em TODOS os containers principais */
.stApp,
[data-testid="stAppViewContainer"],
[data-testid="stApp"],
body,
html,
.main,
#root {
    background: var(--bg-primary) !important;
    background-color: var(--bg-primary) !important;
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif !important;
}

/* Header e Footer tamb√©m brancos */
[data-testid="stHeader"],
header,
footer {
    background: var(--bg-primary) !important;
    background-color: var(--bg-primary) !important;
}

/* Garantir que textos e spinners sejam sempre horizontais */
.stSpinner,
.stSpinner > div,
.stMarkdown,
.stText,
p, h1, h2, h3, h4, h5, h6,
span, div, label, button,
[data-testid="stMarkdownContainer"],
[data-testid="stText"] {
    writing-mode: horizontal-tb !important;
    text-orientation: mixed !important;
}

/* For√ßar spinner horizontal */
.stSpinner > div {
    display: inline-block !important;
    vertical-align: middle !important;
}

/* ==================== SIDEBAR ==================== */
section[data-testid="stSidebar"] {
    background: var(--bg-sidebar) !important;
    border-right: 1px solid var(--border) !important;
}

section[data-testid="stSidebar"] button {
    background: var(--bg-card) !important;
    border: 1px solid var(--border) !important;
    color: var(--text-primary) !important;
    border-radius: 6px !important;
    transition: border-color 150ms ease !important;
}

section[data-testid="stSidebar"] button:hover {
    border-color: var(--accent) !important;
}

/* ==================== CHAT MESSAGES ==================== */
.stChatMessage {
    background: transparent !important;
    border: none !important;
    padding: 16px 0 !important;
    margin: 8px 0 !important;
}

.stChatMessage[data-testid="user"] {
    background: var(--bg-secondary) !important;
    border-radius: 12px !important;
    padding: 16px !important;
    border: 1px solid var(--border) !important;
}

.stChatMessage[data-testid="assistant"] {
    background: var(--bg-card) !important;
    border-radius: 12px !important;
    padding: 16px !important;
    border: 1px solid var(--border) !important;
}

/* ==================== INPUT AREA ==================== */
.stChatInput {
    background: var(--bg-input) !important;
    border: 1px solid var(--border) !important;
    border-radius: 12px !important;
    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.05) !important;
    padding: 12px 16px !important;
    transition: all 150ms ease !important;
}

.stChatInput:focus-within {
    border-color: var(--accent) !important;
    outline: 3px solid rgba(59, 130, 246, 0.1) !important;
    outline-offset: 0px !important;
}

textarea[data-testid="stChatInputTextArea"] {
    background: transparent !important;
    border: none !important;
    color: var(--text-primary) !important;
}

/* ==================== PLOTLY CHARTS ==================== */
.js-plotly-plot {
    background: var(--bg-card) !important;
    border-radius: 12px !important;
    padding: 16px !important;
    border: 1px solid var(--border) !important;
}

/* ==================== DATAFRAMES ==================== */
.stDataFrame {
    background: var(--bg-card) !important;
    border-radius: 8px !important;
    border: 1px solid var(--border) !important;
}

.stDataFrame thead tr {
    background: var(--bg-secondary) !important;
    border-bottom: 2px solid var(--border) !important;
}

.stDataFrame tbody tr {
    border-bottom: 1px solid var(--border) !important;
}

.stDataFrame tbody tr:hover {
    background: var(--bg-secondary) !important;
}

/* ==================== BOT√ïES ==================== */
.stButton button {
    background: var(--accent) !important;
    color: white !important;
    border: none !important;
    border-radius: 8px !important;
    padding: 8px 16px !important;
    font-weight: 500 !important;
    transition: all 150ms ease !important;
}

.stButton button:hover {
    background: #2563EB !important;
    transform: translateY(-1px) !important;
}

/* Bot√µes secund√°rios (feedback, etc) */
button[kind="secondary"],
button[kind="tertiary"] {
    background: var(--bg-secondary) !important;
    color: var(--text-primary) !important;
    border: 1px solid var(--border) !important;
}

button[kind="secondary"]:hover,
button[kind="tertiary"]:hover {
    background: var(--bg-card) !important;
    border-color: var(--accent) !important;
}

/* ==================== EXPANDER ==================== */
.streamlit-expanderHeader {
    background: var(--bg-card) !important;
    border: 1px solid var(--border) !important;
    border-radius: 8px !important;
    color: var(--text-primary) !important;
    padding: 12px 16px !important;
    transition: all 150ms ease !important;
}

.streamlit-expanderHeader:hover {
    background: var(--bg-secondary) !important;
    border-color: var(--accent) !important;
}

.streamlit-expanderContent {
    background: var(--bg-card) !important;
    border: 1px solid var(--border) !important;
    border-top: none !important;
    border-radius: 0 0 8px 8px !important;
    padding: 16px !important;
}

/* ==================== SPINNER (SEM TEXTO) ==================== */
.stSpinner > div {
    border-color: var(--accent) transparent transparent transparent !important;
    width: 20px !important;
    height: 20px !important;
}

/* Remover TODO o texto do spinner */
.stSpinner p,
.stSpinner span,
.stSpinner div[data-testid="stMarkdownContainer"],
.element-container:has(.stSpinner) p,
.element-container:has(.stSpinner) span {
    display: none !important;
    font-size: 0 !important;
    visibility: hidden !important;
}

/* Garantir que apenas o √≠cone apare√ßa */
.stSpinner {
    text-align: center !important;
}

/* ==================== M√âTRICAS ==================== */
div[data-testid="stMetricValue"] {
    font-size: 28px !important;
    font-weight: 600 !important;
    color: var(--text-primary) !important;
}

div[data-testid="stMetricLabel"] {
    font-size: 13px !important;
    color: var(--text-secondary) !important;
    font-weight: 500 !important;
}

/* ==================== INPUTS GERAIS ==================== */
.stTextInput > div > div > input,
.stNumberInput > div > div > input,
.stTextArea > div > div > textarea {
    background: var(--bg-input) !important;
    border: 1px solid var(--border) !important;
    border-radius: 8px !important;
    color: var(--text-primary) !important;
    padding: 8px 12px !important;
    transition: border-color 150ms ease !important;
}

.stTextInput > div > div > input:focus,
.stTextArea > div > div > textarea:focus,
.stNumberInput > div > div > input:focus {
    border-color: var(--accent) !important;
    outline: 3px solid rgba(59, 130, 246, 0.1) !important;
    outline-offset: 0px !important;
}

/* ==================== SCROLLBAR ==================== */
::-webkit-scrollbar {
    width: 8px !important;
    height: 8px !important;
}

::-webkit-scrollbar-track {
    background: var(--bg-secondary) !important;
}

::-webkit-scrollbar-thumb {
    background: var(--border) !important;
    border-radius: 4px !important;
}

::-webkit-scrollbar-thumb:hover {
    background: var(--text-tertiary) !important;
}

/* ==================== OTIMIZA√á√ïES DE PERFORMANCE ==================== */
*:focus-visible {
    outline: 2px solid var(--accent) !important;
    outline-offset: 2px !important;
}
    """
    return f"<style>{css}</style>"

# Carregar CSS com cache (performance boost)
st.markdown(load_optimized_css(), unsafe_allow_html=True)

# ============================================================================
# ‚úÖ OTIMIZA√á√ÉO v2.2: Cache autom√°tico com versionamento
# REMOVIDO: cache.clear_all() no startup (economiza 1-2s + preserva cache v√°lido)
# O sistema de versionamento autom√°tico em agent_graph_cache.py j√° invalida
# o cache quando o c√≥digo muda, sem precisar limpar tudo a cada rein√≠cio.
# ============================================================================

# ============================================================================
# FIM DO CSS CUSTOMIZADO
# ============================================================================

# ‚úÖ FUN√á√ÉO DE NORMALIZA√á√ÉO DE QUERY PARA CACHE (20/10/2025)
def normalize_query_for_cache(query: str) -> str:
    """
    Normaliza query para melhorar taxa de cache hit.
    Remove palavras irrelevantes e padroniza formato.

    Exemplos:
        "gere um gr√°fico de vendas" -> "grafico vendas"
        "mostre o ranking de vendas" -> "ranking vendas"
        "me mostre os produtos" -> "produtos"
    """
    if not query:
        return query

    # Lowercase
    query = query.lower().strip()

    # Remover pontua√ß√£o
    query = re.sub(r'[^\w\s]', ' ', query)

    # Remover artigos e palavras de comando comuns
    stopwords = [
        'o', 'a', 'os', 'as', 'um', 'uma', 'uns', 'umas',
        'de', 'da', 'do', 'das', 'dos', 'no', 'na', 'nos', 'nas',
        'gere', 'mostre', 'me', 'por', 'favor', 'por favor',
        'qual', 'quais', 'liste', 'listar'
    ]

    words = query.split()
    filtered_words = [w for w in words if w not in stopwords and len(w) > 1]

    # Normalizar varia√ß√µes comuns
    normalized = ' '.join(filtered_words)
    normalized = normalized.replace('grafico', 'gr√°fico')  # Padronizar acentua√ß√£o
    normalized = normalized.replace('evolucao', 'evolu√ß√£o')
    normalized = normalized.replace('analise', 'an√°lise')

    return normalized

# Fun√ß√µes de autentica√ß√£o com lazy loading
AUTH_AVAILABLE = None
_auth_module = None

def get_auth_functions():
    """Carrega fun√ß√µes de autentica√ß√£o usando lazy loading"""
    global AUTH_AVAILABLE, _auth_module

    if AUTH_AVAILABLE is None:
        try:
            from core.auth import login as _login, sessao_expirada as _sessao_expirada
            _auth_module = {"login": _login, "sessao_expirada": _sessao_expirada}
            AUTH_AVAILABLE = True
            # Log removido - n√£o vis√≠vel para usu√°rio
        except Exception as e:
            logging.error(f"‚ùå Erro ao carregar autentica√ß√£o: {e}")
            AUTH_AVAILABLE = False
            _auth_module = None

    return _auth_module

def login():
    """Fun√ß√£o de login com lazy loading"""
    auth_funcs = get_auth_functions()
    if auth_funcs:
        return auth_funcs["login"]()
    else:
        # Fallback simples
        st.error("‚ùå Sistema de autentica√ß√£o n√£o dispon√≠vel")
        st.info("üå§Ô∏è Modo cloud - acesso liberado")
        st.session_state.authenticated = True
        st.rerun()

def sessao_expirada():
    """Fun√ß√£o de sess√£o expirada com lazy loading"""
    auth_funcs = get_auth_functions()
    if auth_funcs:
        return auth_funcs["sessao_expirada"]()
    else:
        return False

# ‚ö° LAZY LOADING: Importa√ß√µes do backend s√≥ quando necess√°rio
BACKEND_MODULES = {}
import_errors = []

def get_backend_module(module_name):
    """Carrega m√≥dulos do backend sob demanda (lazy loading)"""
    if module_name in BACKEND_MODULES:
        return BACKEND_MODULES[module_name]

    try:
        if module_name == "GraphBuilder":
            from core.graph.graph_builder import GraphBuilder
            BACKEND_MODULES[module_name] = GraphBuilder
        elif module_name == "ComponentFactory":
            from core.factory.component_factory import ComponentFactory
            BACKEND_MODULES[module_name] = ComponentFactory
        elif module_name == "ParquetAdapter":
            from core.connectivity.parquet_adapter import ParquetAdapter
            BACKEND_MODULES[module_name] = ParquetAdapter
        elif module_name == "CodeGenAgent":
            from core.agents.code_gen_agent import CodeGenAgent
            BACKEND_MODULES[module_name] = CodeGenAgent
        elif module_name == "HumanMessage":
            from langchain_core.messages import HumanMessage
            BACKEND_MODULES[module_name] = HumanMessage
        elif module_name == "QueryHistory":
            from core.utils.query_history import QueryHistory
            BACKEND_MODULES[module_name] = QueryHistory

        return BACKEND_MODULES[module_name]
    except Exception as e:
        import_errors.append(f"{module_name}: {e}")
        logging.error(f"Erro ao carregar {module_name}: {e}")
        return None

# Settings com lazy loading
settings = None

def get_settings():
    """Obt√©m settings de forma lazy e segura"""
    global settings
    if settings is None:
        try:
            from core.config.safe_settings import get_safe_settings
            settings = get_safe_settings()
        except Exception as e:
            logging.error(f"Erro ao carregar settings: {e}")
            settings = None
    return settings

# --- Autentica√ß√£o ---
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated or sessao_expirada():
    st.session_state.authenticated = False
    login()
    st.stop()  # ‚úÖ Parar execu√ß√£o - evita tela de login fantasma
else:
    # --- Configura√ß√£o da P√°gina ---
    st.set_page_config(page_title="Analisador de Dados Ca√ßulinha", page_icon="üìä", layout="wide")
    st.title("üìä Analisador de Dados Ca√ßulinha")

    # --- Inicializa√ß√£o do Backend Integrado ---
    @st.cache_resource(show_spinner=False)
    def initialize_backend():
        """Inicializa os componentes do backend uma √∫nica vez"""
        debug_info = []

        try:
            # ‚ö° Carregar m√≥dulos sob demanda
            GraphBuilder = get_backend_module("GraphBuilder")
            ComponentFactory = get_backend_module("ComponentFactory")
            ParquetAdapter = get_backend_module("ParquetAdapter")
            CodeGenAgent = get_backend_module("CodeGenAgent")
            HumanMessage = get_backend_module("HumanMessage")
            QueryHistory = get_backend_module("QueryHistory")

            # Verificar se m√≥dulos cr√≠ticos foram carregados
            if not all([GraphBuilder, ComponentFactory, ParquetAdapter]):
                with st.sidebar:
                    st.error("‚ùå M√≥dulos cr√≠ticos do backend n√£o dispon√≠veis")
                    if import_errors:
                        st.write("**Erros:**")
                        for error in import_errors:
                            st.code(error)
                return None

            debug_info.append("‚úÖ M√≥dulos carregados com lazy loading")
            # Debug 2: Verificar secrets de LLM (Gemini ou DeepSeek)
            gemini_key = None
            deepseek_key = None
            secrets_status = "‚ùå Falhou"

            try:
                gemini_key = st.secrets.get("GEMINI_API_KEY")
                deepseek_key = st.secrets.get("DEEPSEEK_API_KEY")

                if gemini_key:
                    secrets_status = "‚úÖ Gemini OK"
                    debug_info.append(f"Secrets Gemini: OK ({gemini_key[:10]}...)")
                elif deepseek_key:
                    secrets_status = "‚úÖ DeepSeek OK"
                    debug_info.append(f"Secrets DeepSeek: OK ({deepseek_key[:10]}...)")
                else:
                    debug_info.append(f"Secrets: Nenhuma chave LLM encontrada")
            except Exception as e:
                debug_info.append(f"Secrets erro: {e}")

            # Debug 3: Fallback para settings
            if not gemini_key and not deepseek_key:
                try:
                    current_settings = get_settings()
                    if current_settings:
                        gemini_key = getattr(current_settings, 'GEMINI_API_KEY', None)
                        deepseek_key = getattr(current_settings, 'DEEPSEEK_API_KEY', None)
                    debug_info.append(f"Settings LLM: OK")
                except Exception as e:
                    debug_info.append(f"Settings erro: {e}")

            if not gemini_key and not deepseek_key:
                raise ValueError("Nenhuma chave LLM (GEMINI_API_KEY ou DEEPSEEK_API_KEY) encontrada em secrets nem settings")

            # Debug 4: Inicializar LLM
            debug_info.append("Inicializando LLM...")
            llm_adapter = ComponentFactory.get_llm_adapter("gemini")
            debug_info.append("‚úÖ LLM OK")

            # Debug 5: Inicializar Data Adapter (H√≠brido)
            debug_info.append("Inicializando HybridDataAdapter...")
            import os
            from core.connectivity.hybrid_adapter import HybridDataAdapter

            # Usar HybridAdapter que gerencia SQL Server e Parquet
            data_adapter = HybridDataAdapter()
            adapter_status = data_adapter.get_status()

            debug_info.append(f"‚úÖ HybridAdapter OK - Fonte: {adapter_status['current_source'].upper()}")

            # Validar que temos dados (via Parquet que sempre existe)
            import pandas as pd
            parquet_check = os.path.join(os.getcwd(), "data", "parquet", "admmat.parquet")

            if os.path.exists(parquet_check):
                # ‚ö° OTIMIZA√á√ÉO: N√ÉO chamar get_schema() pois carrega dados!
                # Apenas reportar que o Parquet est√° dispon√≠vel
                debug_info.append(f"‚úÖ Dataset: Parquet dispon√≠vel em {parquet_check}")
            else:
                debug_info.append("‚ö†Ô∏è Parquet n√£o encontrado")

            # Mostrar status da fonte de dados no sidebar APENAS para admins
            user_role = st.session_state.get('role', '')
            if user_role == 'admin':
                with st.sidebar.expander("üì¶ Detalhes da Fonte de Dados (Admin)", expanded=False):
                    fonte_icon = "üóÑÔ∏è" if adapter_status['current_source'] == 'sqlserver' else "üì¶"
                    fonte_nome = "SQL Server" if adapter_status['current_source'] == 'sqlserver' else "Parquet"

                    info_text = f"**{fonte_icon} Fonte de Dados: {fonte_nome}**\n\n"

                    if adapter_status['sql_enabled']:
                        info_text += f"SQL Server: {'‚úÖ Conectado' if adapter_status['sql_available'] else '‚ùå Indispon√≠vel'}\n"

                    info_text += f"Parquet Fallback: {'‚úÖ Ativo' if adapter_status['fallback_enabled'] else '‚ùå Desativado'}\n"

                    # ParquetAdapter usa lazy loading - n√£o exibir informa√ß√µes detalhadas
                    info_text += f"\n**Dataset:** Parquet com lazy loading (Polars/Dask otimizado)"
                    info_text += f"\n**Performance:** Predicate pushdown ativo - filtra antes de carregar"

                    st.info(info_text)

            # Para compatibilidade com c√≥digo legado, criar alias
            parquet_adapter = data_adapter

            # Debug 6: Inicializar CodeGen
            debug_info.append("Inicializando CodeGen...")
            code_gen_agent = CodeGenAgent(llm_adapter=llm_adapter, data_adapter=parquet_adapter)
            debug_info.append("‚úÖ CodeGen OK")

            # Debug 7: Inicializar QueryHistory
            debug_info.append("Inicializando QueryHistory...")
            history_path = os.path.join(os.getcwd(), "data", "query_history")
            query_history = QueryHistory(history_dir=history_path)
            debug_info.append("‚úÖ QueryHistory OK")

            # Debug 8: Construir Grafo
            debug_info.append("Construindo grafo...")
            graph_builder = GraphBuilder(
                llm_adapter=llm_adapter,
                parquet_adapter=parquet_adapter,
                code_gen_agent=code_gen_agent
            )
            agent_graph = graph_builder.build()
            debug_info.append("‚úÖ Grafo OK")

            debug_info.append("üéâ Backend inicializado com sucesso!")

            # Mostrar painel de diagn√≥stico para admins
            user_role = st.session_state.get('role', '')
            if user_role == 'admin':
                with st.sidebar.expander("‚öôÔ∏è Painel de Diagn√≥stico do Backend (Admin)", expanded=False):
                    st.write("**Debug Log:**")
                    for info in debug_info:
                        if "‚úÖ" in info:
                            st.success(info)
                        elif "‚ö†Ô∏è" in info:
                            st.warning(info)
                        elif "‚ùå" in info:
                            st.error(info)
                        else:
                            st.info(info)

            return {
                "llm_adapter": llm_adapter,
                "parquet_adapter": parquet_adapter,
                "code_gen_agent": code_gen_agent,
                "agent_graph": agent_graph,
                "query_history": query_history
            }

        except Exception as e:
            import traceback
            error_traceback = traceback.format_exc()
            debug_info.append(f"‚ùå ERRO: {str(e)}")
            debug_info.append(f"üìç Tipo do erro: {type(e).__name__}")

            # Log do erro completo para debugging
            logging.error(f"Backend initialization failed: {str(e)}")
            logging.error(f"Traceback: {error_traceback}")

            # Mostrar debug completo na sidebar APENAS para admins
            user_role = st.session_state.get('role', '')
            if user_role == 'admin':
                with st.sidebar:
                    st.error("üö® Backend Error (Admin)")
                    st.write("**Debug Log:**")
                    for info in debug_info:
                        if "‚úÖ" in info:
                            st.success(info)
                        elif "‚ùå" in info:
                            st.error(info)
                        else:
                            st.info(info)

                    with st.expander("üêõ Erro Completo (Traceback)"):
                        st.code(error_traceback)
            else:
                with st.sidebar:
                    st.error("‚ùå Sistema temporariamente indispon√≠vel")
                    st.info("üí° Tente recarregar a p√°gina ou entre em contato com o suporte")

            return None

    # ‚úÖ CORRE√á√ÉO CONTEXT7: N√ÉO armazenar objetos n√£o-serializ√°veis no session_state
    # O @st.cache_resource j√° funciona como singleton, ent√£o basta chamar initialize_backend()
    # sempre que precisar - o cache retornar√° a mesma inst√¢ncia automaticamente
    backend_components = initialize_backend()

    # Feedback visual apenas (sem armazenar no session_state)
    if backend_components:
        user_role = st.session_state.get('role', '')
        if user_role == 'admin':
            with st.sidebar:
                st.success("‚úÖ Backend inicializado!")
    else:
        user_role = st.session_state.get('role', '')
        if user_role == 'admin':
            with st.sidebar:
                st.error("‚ùå Backend falhou")

    # --- Logout Button ---
    with st.sidebar:
        st.write(f"Bem-vindo, {st.session_state.get('username', '')}!")
        st.write(f"DEBUG: Role do usu√°rio (sidebar): {st.session_state.get('role', '')}") # LINHA DE DEBUG

    # --- Modo de Consulta: 100% IA ---
    with st.sidebar:
        st.divider()

        # Logo removida do sidebar conforme solicitado (2025-10-26)
        # Logo aparece apenas no chat como avatar do assistente

        st.subheader("‚ú® An√°lise Inteligente com IA")

        st.info("""
            **Converse com a Ca√ßulinha!**
            - Eu sou sua assistente de BI.
            - Fa√ßa perguntas sobre seus dados.
            - Pe√ßa an√°lises e gr√°ficos.
            - Estou aqui para ajudar!
        """)

        st.caption("üí° Alimentado por IA avan√ßada (Gemini 2.5)")

    # --- Painel de Administra√ß√£o ---
    user_role = st.session_state.get('role', '')
    if user_role == 'admin':
        with st.sidebar:
            st.divider()
            with st.expander("‚öôÔ∏è Administra√ß√£o", expanded=False):
                st.subheader("üíæ Gerenciamento de Cache")

                # Estat√≠sticas do cache
                try:
                    from core.business_intelligence.agent_graph_cache import get_agent_graph_cache
                    cache = get_agent_graph_cache()
                    stats = cache.get_stats()

                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Cache Mem√≥ria", stats['memory_entries'])
                    with col2:
                        st.metric("Cache Disco", stats['disk_entries'])

                    st.caption(f"TTL: {stats['ttl_hours']}h")

                    # Bot√£o para limpar cache
                    if st.button("üßπ Limpar Cache"):
                        cache.clear_all()
                        st.success("‚úÖ Cache limpo com sucesso!")
                        st.rerun()

                except Exception as e:
                    st.error(f"Erro ao carregar estat√≠sticas do cache: {e}")

                st.divider()
                # Perguntas R√°pidas (Ocultas - pode ser reativado via checkbox)
                if st.checkbox("‚ö° Mostrar Perguntas R√°pidas", value=False, key="show_quick_questions"):
                    st.subheader("‚ö° Perguntas R√°pidas")

                    # Perguntas populares por categoria
                    quick_actions = {
                        "üéØ Vendas": [
                            "Produto mais vendido",
                            "Top 10 produtos",
                            "Ranking de vendas na une scr"
                        ],
                        "üè¨ UNEs/Lojas": [
                            "Ranking de vendas por UNE",
                            "Top 5 produtos da une 261",
                            "Vendas totais de cada une"
                        ],
                        "üè™ Segmentos": [
                            "Qual segmento mais vendeu?",
                            "Top 10 produtos do segmento TECIDOS",
                            "Ranking dos segmentos"
                        ],
                        "üìà An√°lises": [
                            "Evolu√ß√£o de vendas dos √∫ltimos 12 meses",
                            "Produtos sem movimento",
                            "An√°lise ABC de produtos"
                        ]
                    }

                    for categoria, perguntas in quick_actions.items():
                        with st.expander(categoria, expanded=False):
                            for pergunta in perguntas:
                                if st.button(pergunta, key=f"qa_{pergunta}", use_container_width=True):
                                    # Adicionar pergunta ao session state
                                    st.session_state['pergunta_selecionada'] = pergunta

                    st.caption("üí° Clique para executar")

    # --- Estado da Sess√£o ---

    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
    if 'messages' not in st.session_state:
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": {
                    "type": "text",
                    "content": "Ol√°! Eu sou a Ca√ßulinha, sua assistente de BI. O que vamos analisar hoje?"
                }
            }
        ]

    # --- NOTA: DirectQueryEngine removido - 100% IA ---
    # get_direct_query_engine() foi removido - sistema usa apenas agent_graph
    # Data: 12/10/2025

    # --- Fun√ß√µes de Intera√ß√£o ---
    def query_backend(user_input: str):
        '''Processa a query diretamente usando o backend integrado.'''
        # Log removido - informa√ß√£o confidencial do usu√°rio

        # üìù GARANTIR que a pergunta do usu√°rio seja sempre preservada
        user_message = {"role": "user", "content": {"type": "text", "content": user_input}}
        st.session_state.messages.append(user_message)

        # ‚úÖ PROCESSAMENTO DIRETO (sem spinners - mais r√°pido)
        try:
            # Inicializar agent_response
            agent_response = None
            start_time = datetime.now()

            # üíæ CACHE: Verificar cache antes de processar (com normaliza√ß√£o)
            try:
                from core.business_intelligence.agent_graph_cache import get_agent_graph_cache
                cache = get_agent_graph_cache()

                # ‚úÖ OTIMIZA√á√ÉO: Normalizar query para melhorar cache hit rate
                normalized_query = normalize_query_for_cache(user_input)

                # Tentar com query normalizada primeiro
                cached_result = cache.get(normalized_query)

                # Fallback: tentar com query original se n√£o encontrar
                if not cached_result:
                    cached_result = cache.get(user_input)

                if cached_result:
                    logger.info(f"‚úÖ Cache HIT! Query normalizada: '{normalized_query}'")
                else:
                    logger.info(f"‚ùå Cache MISS. Query normalizada: '{normalized_query}'")

            except Exception as cache_error:
                logger.warning(f"Erro ao acessar cache: {cache_error}")
                cached_result = None

            if cached_result:
                # ‚úÖ CACHE HIT!
                agent_response = cached_result
                agent_response["method"] = "agent_graph_cached"
                agent_response["processing_time"] = (datetime.now() - start_time).total_seconds()

                # Debug para admins
                user_role = st.session_state.get('role', '')
                if user_role == 'admin':
                    with st.expander("üíæ Cache Hit!"):
                        st.success(f"‚úÖ Resposta recuperada do cache")
                        st.write(f"**Fonte:** {cached_result.get('cache_source', 'unknown')}")
            else:
                # ‚ùå CACHE MISS: Processar com agent_graph
                logger.info("Cache miss. Processando com agent_graph...")
                # ‚úÖ CORRE√á√ÉO CONTEXT7: Acessar backend via cache_resource (n√£o session_state)
                backend = initialize_backend()
                if backend and 'agent_graph' in backend:
                    agent_graph = backend['agent_graph']

                    # ‚úÖ CORRE√á√ÉO: Construir o hist√≥rico completo de mensagens
                    from langchain_core.messages import AIMessage
                    HumanMessage = get_backend_module("HumanMessage")
                    
                    langchain_messages = []
                    for msg in st.session_state.get('messages', []):
                        if msg.get("role") == "user":
                            # ‚úÖ CORRE√á√ÉO: Verificar tipo antes de chamar .get()
                            content = msg.get("content", {})
                            if isinstance(content, dict):
                                user_text = content.get("content", "")
                            elif isinstance(content, list):
                                # Se for lista, converter para string
                                user_text = str(content)
                            else:
                                # Se for string ou outro tipo, usar diretamente
                                user_text = str(content)
                            langchain_messages.append(HumanMessage(content=user_text))
                        elif msg.get("role") == "assistant":
                            # Para o assistente, podemos simplificar para o conte√∫do textual por enquanto
                            # j√° que o grafo espera principalmente o texto.
                            assistant_content = msg.get("content", {})
                            if isinstance(assistant_content, dict):
                                text_content = assistant_content.get("content", "")
                                if isinstance(text_content, dict): # Caso de content aninhado
                                    text_content = text_content.get("content", "...")
                                langchain_messages.append(AIMessage(content=str(text_content)))
                            elif isinstance(assistant_content, list):
                                # Se for lista, converter para string
                                langchain_messages.append(AIMessage(content=str(assistant_content)))
                            else:
                                langchain_messages.append(AIMessage(content=str(assistant_content)))

                    # A √∫ltima mensagem (a atual) j√° foi adicionada √† session_state, ent√£o usamos a lista completa
                    
                    # üîí SEGURAN√áA: Mascarar PII no input antes de enviar ao grafo
                    masked_query = mask_pii(user_input)
                    if masked_query != user_input:
                        logger.info(f"üîí PII mascarado no input: {user_input} -> {masked_query}")
                    
                    graph_input = {"messages": langchain_messages, "query": masked_query}

                    # ‚úÖ OTIMIZA√á√ÉO CONTEXT7: Configurar thread_id para checkpointing
                    # Permite recovery autom√°tico e isolamento de sess√µes
                    config = {
                        "configurable": {
                            "thread_id": st.session_state.session_id  # Usa session_id existente
                        }
                    }
                    logger.info(f"üîÑ Checkpointing ativado - thread_id: {st.session_state.session_id}")

                    # ‚úÖ STREAMING IMPLEMENTATION: Executar agent_graph com feedback visual

                    try:
                        # Status de progresso
                        status_container = st.empty()
                        status_container.markdown("üîÑ *Processando sua pergunta...*")

                        # Executar grafo em modo streaming
                        agent_response = None
                        initial_feedback_shown = False

                        for event in agent_graph.stream(graph_input, config=config):
                            # Identificar qual n√≥ foi executado
                            current_node = list(event.keys())[0] if isinstance(event, dict) else "unknown"

                            # Atualizar status baseado no n√≥
                            if current_node == "reasoning":
                                status_container.markdown("üß† *Analisando inten√ß√£o...*")
                            elif current_node == "generate_initial_feedback":
                                # üéØ NOVO: Exibir feedback inicial ao usu√°rio
                                state_update = event.get(current_node, {})
                                feedback_msg = state_update.get("initial_feedback", "")
                                if feedback_msg and not initial_feedback_shown:
                                    # Limpar status e mostrar feedback
                                    status_container.empty()
                                    # Adicionar mensagem de feedback nas mensagens do chat
                                    st.session_state.messages.append({"role": "assistant", "content": feedback_msg})
                                    with st.chat_message("assistant"):
                                        st.markdown(feedback_msg)
                                    initial_feedback_shown = True
                                    # Atualizar status para mostrar que est√° processando
                                    status_container.markdown("‚öôÔ∏è *Processando...*")
                            elif current_node == "conversational_response":
                                status_container.markdown("üí¨ *Gerando resposta conversacional...*")
                            elif current_node == "classify_intent":
                                status_container.markdown("üéØ *Classificando tipo de consulta...*")
                            elif current_node == "generate_parquet_query":
                                status_container.markdown("üîç *Preparando consulta de dados...*")
                            elif current_node == "execute_query":
                                status_container.markdown("üìä *Consultando dados...*")
                            elif current_node == "generate_plotly_spec":
                                status_container.markdown("üìà *Gerando visualiza√ß√£o...*")
                            elif current_node == "format_final_response":
                                status_container.markdown("‚úçÔ∏è *Formatando resposta...*")

                            # Verificar se temos uma resposta final no estado
                            if isinstance(event, dict):
                                state_update = event.get(current_node, {})
                                if "final_response" in state_update:
                                    agent_response = state_update["final_response"]

                        # Limpar status
                        status_container.empty()

                        # Verificar se obtivemos resposta
                        if not agent_response:
                            agent_response = {
                                "type": "error",
                                "content": "N√£o foi poss√≠vel obter uma resposta do agente."
                            }

                        # üîí SEGURAN√áA: Mascarar PII na resposta se for dict com content
                        if isinstance(agent_response, dict) and "content" in agent_response:
                            content = agent_response["content"]
                            if isinstance(content, str):
                                masked_content = mask_pii(content)
                                if masked_content != content:
                                    agent_response["content"] = masked_content
                                    logger.info(f"üîí PII mascarado na resposta")
                                    pii_summary = get_pii_summary()
                                    if pii_summary:
                                        logger.warning(f"üîí Tipos de PII mascarados: {pii_summary}")

                    except Exception as e:
                        logger.error(f"‚ùå Erro no streaming: {e}", exc_info=True)
                        agent_response = {"type": "error", "content": f"Erro ao processar: {str(e)}"}
                else:
                    # üîß DIAGN√ìSTICO: Verificar por que agent_graph n√£o est√° dispon√≠vel
                    error_details = []

                    if not backend:
                        error_details.append("‚ùå Backend n√£o inicializado")
                    elif 'agent_graph' not in backend:
                        error_details.append("‚ùå Agent Graph n√£o encontrado no backend")
                        available_keys = list(backend.keys())
                        error_details.append(f"Componentes dispon√≠veis: {', '.join(available_keys)}")

                    error_msg = "ü§ñ **Sistema de IA Indispon√≠vel**\n\n"
                    error_msg += "O sistema n√£o conseguiu inicializar o agente de IA.\n\n"
                    error_msg += "**üí° Solu√ß√£o:**\n"
                    error_msg += "1. Recarregue a p√°gina (F5)\n"
                    error_msg += "2. Verifique sua conex√£o de internet\n"
                    error_msg += "3. Se o problema persistir, entre em contato com o suporte"

                    # Adicionar detalhes t√©cnicos apenas para admins
                    user_role = st.session_state.get('role', '')
                    if user_role == 'admin' and error_details:
                        error_msg += "\n\n**üîß Detalhes T√©cnicos (Admin):**\n"
                        error_msg += "\n".join(error_details)

                    agent_response = {
                        "type": "error",
                        "content": error_msg,
                        "user_query": user_input,
                        "method": "agent_graph_unavailable"
                    }

            # ‚úÖ GARANTIR estrutura correta da resposta
            if agent_response:
                assistant_message = {"role": "assistant", "content": agent_response}
                st.session_state.messages.append(assistant_message)
            else:
                # Fallback se agent_response n√£o foi definido
                error_message = {
                    "role": "assistant",
                    "content": {
                        "type": "error",
                        "content": "Erro ao processar consulta. Tente novamente.",
                        "user_query": user_input
                    }
                }
                st.session_state.messages.append(error_message)

            # Resposta processada silenciosamente

        except Exception as e:
            # Erro fatal na invoca√ß√£o do agente. Parar a execu√ß√£o e notificar o usu√°rio.
            logger.critical(f"Erro fatal ao invocar o backend: {e}", exc_info=True)
            st.error("üö® Desculpe, ocorreu um erro cr√≠tico no sistema.")
            st.info("A equipe de desenvolvimento foi notificada. Por favor, atualize a p√°gina e tente novamente.")
                
            # Adiciona uma mensagem de erro clara ao chat para o usu√°rio
            error_content = {
                "type": "text",
                "content": "‚ùå **Erro Interno**\n\nOcorreu uma falha inesperada ao processar sua solicita√ß√£o. A equipe de suporte j√° foi notificada."
            }
            st.session_state.messages.append({"role": "assistant", "content": error_content})
            # N√£o fazer st.rerun() aqui para que o erro seja vis√≠vel.

        # Log the query and its outcome
        backend = initialize_backend()
        if backend and backend.get("query_history"):
            query_history = backend["query_history"]
            
            # Default agent_response to an empty dict if it's not a dict
            if not isinstance(agent_response, dict):
                agent_response = {}

            # Safely determine if the main operation was successful
            is_success = agent_response.get("type") != "error"

            # Safely get result count from chart data if it exists
            results_count = 0
            if is_success and isinstance(agent_response.get("result"), dict):
                chart_data = agent_response["result"].get("chart_data", {})
                if isinstance(chart_data, dict):
                    results_count = len(chart_data.get("x", []))
            
            # Safely get error message
            error_message = None
            if not is_success:
                error_message = agent_response.get("content")
            
            # Get processing time from the response if available
            processing_time = agent_response.get("processing_time", 0.0)

            query_history.add_query(
                query=user_input,
                session_id=st.session_state.session_id,
                success=is_success,
                results_count=results_count,
                error=error_message,
                processing_time=processing_time
            )

        st.rerun()

    # --- Fun√ß√µes de Streaming ---
    def stream_text(text: str, speed: float = 0.01):
        """
        Generator para criar efeito de digita√ß√£o (typewriter effect).
        Yields: caracteres um por um com delay entre eles.
        """
        import time
        for char in text:
            yield char
            time.sleep(speed)

    # --- Renderiza√ß√£o da Interface ---
    # üîç DEBUG: Mostrar hist√≥rico de mensagens na sidebar (apenas para admins)
    user_role = st.session_state.get('role', '')
    if user_role == 'admin':
        with st.sidebar:
            st.write(f"**Total de mensagens:** {len(st.session_state.messages)}")
            if st.checkbox("Mostrar hist√≥rico debug"):
                for i, msg in enumerate(st.session_state.messages):
                    st.write(f"**{i+1}. {msg['role'].title()}:**")
                    content_preview = str(msg.get('content', {}))[:100] + "..." if len(str(msg.get('content', {}))) > 100 else str(msg.get('content', {}))
                    st.write(f"{content_preview}")

    # üí¨ RENDERIZAR hist√≥rico de conversas
    for i, msg in enumerate(st.session_state.messages):
        try:
            # üé® CUSTOMIZA√á√ÉO: Usar logo Ca√ßula otimizada para chat (53x80px)
            import os
            logo_chat_path = os.path.join(os.getcwd(), "assets", "images", "cacula_logo_chat.png")

            if msg["role"] == "assistant" and os.path.exists(logo_chat_path):
                # Usar logo Ca√ßula otimizada para assistente (n√£o cortada)
                with st.chat_message(msg["role"], avatar=logo_chat_path):
                    response_data = msg.get("content", {})
            else:
                # Usar avatar padr√£o
                with st.chat_message(msg["role"]):
                    response_data = msg.get("content", {})

            # ‚úÖ Garantir que response_data seja um dicion√°rio
            if not isinstance(response_data, dict):
                response_data = {"type": "text", "content": str(response_data)}

            response_type = response_data.get("type", "text")
            content = response_data.get("content", "Conte√∫do n√£o dispon√≠vel")

            # üîç DEBUG: Log de renderiza√ß√£o (removido print para evitar problemas)
            # if msg["role"] == "user":
            #     print(f"RENDERING USER MSG {i+1}: '{content}'")
            # else:
            #     print(f"RENDERING ASSISTANT MSG {i+1}: Type={response_type}")
            
            # üìà RENDERIZAR GR√ÅFICOS
            if response_type == "chart":
                # ‚ö° Imports sob demanda apenas quando necess√°rio
                import plotly.graph_objects as go

                # üìù Mostrar contexto da pergunta que gerou o gr√°fico
                user_query = response_data.get("user_query")
                if user_query:
                    st.caption(f"üìù Pergunta: {user_query}")

                try:
                    # Verificar se chart_data est√° em result ou no content diretamente
                    if 'result' in response_data and 'chart_data' in response_data['result']:
                        # Nosso formato personalizado
                        chart_data = response_data['result']['chart_data']

                        # Criar gr√°fico melhorado com cores e interatividade
                        chart_type = chart_data.get("type", "bar")
                        x_data = chart_data.get("x", [])
                        y_data = chart_data.get("y", [])
                        colors = chart_data.get("colors", None)

                        # Configura√ß√µes comuns
                        height = chart_data.get("height", 500)
                        margin = chart_data.get("margin", {"l": 60, "r": 60, "t": 80, "b": 100})

                        # Criar figura baseado no tipo
                        fig = go.Figure()

                        if chart_type == "bar" and x_data and y_data:
                            # Gr√°fico de barras
                            fig.add_trace(go.Bar(
                                x=x_data,
                                y=y_data,
                                marker_color=colors if colors else '#1f77b4',
                                text=[f'{int(val):,}' for val in y_data],
                                textposition='outside',
                                name='Vendas',
                                hovertemplate='<b>%{x}</b><br>Vendas: %{y:,.0f}<extra></extra>'
                            ))

                            fig.update_layout(
                                xaxis_title="Categoria",
                                yaxis_title="Valor",
                                xaxis=dict(tickangle=-45),
                                yaxis=dict(gridcolor='rgba(128,128,128,0.2)')
                            )

                        elif chart_type == "pie" and x_data and y_data:
                            # Gr√°fico de pizza
                            fig.add_trace(go.Pie(
                                labels=x_data,
                                values=y_data,
                                textinfo='label+percent',
                                hovertemplate='<b>%{label}</b><br>Vendas: %{value:,.0f}<br>Percentual: %{percent}<extra></extra>'
                            ))
                            height = 600

                        elif chart_type == "line" and x_data and y_data:
                            # Gr√°fico de linha
                            fig.add_trace(go.Scatter(
                                x=x_data,
                                y=y_data,
                                mode='lines+markers',
                                line=dict(color=colors if colors else '#1f77b4', width=2),
                                marker=dict(size=8),
                                name='Tend√™ncia',
                                hovertemplate='<b>%{x}</b><br>Valor: %{y:,.0f}<extra></extra>'
                            ))

                            fig.update_layout(
                                xaxis_title="Per√≠odo",
                                yaxis_title="Valor",
                                yaxis=dict(gridcolor='rgba(128,128,128,0.2)')
                            )

                        elif chart_type == "scatter" and x_data and y_data:
                            # Gr√°fico de dispers√£o
                            fig.add_trace(go.Scatter(
                                x=x_data,
                                y=y_data,
                                mode='markers',
                                marker=dict(
                                    size=10,
                                    color=colors if colors else y_data,
                                    colorscale='Viridis',
                                    showscale=True
                                ),
                                hovertemplate='<b>%{x}</b><br>Valor: %{y:,.0f}<extra></extra>'
                            ))

                            fig.update_layout(
                                xaxis_title="X",
                                yaxis_title="Y"
                            )

                        elif chart_type == "area" and x_data and y_data:
                            # Gr√°fico de √°rea
                            fig.add_trace(go.Scatter(
                                x=x_data,
                                y=y_data,
                                fill='tozeroy',
                                mode='lines',
                                line=dict(color=colors if colors else '#1f77b4'),
                                name='√Årea',
                                hovertemplate='<b>%{x}</b><br>Valor: %{y:,.0f}<extra></extra>'
                            ))

                            fig.update_layout(
                                xaxis_title="Per√≠odo",
                                yaxis_title="Valor",
                                yaxis=dict(gridcolor='rgba(128,128,128,0.2)')
                            )

                        elif chart_type == "histogram" and y_data:
                            # Histograma
                            fig.add_trace(go.Histogram(
                                x=y_data,
                                marker_color=colors if colors else '#1f77b4',
                                name='Distribui√ß√£o'
                            ))

                            fig.update_layout(
                                xaxis_title="Valor",
                                yaxis_title="Frequ√™ncia"
                            )

                        elif chart_type == "box" and y_data:
                            # Box plot
                            fig.add_trace(go.Box(
                                y=y_data,
                                name='Distribui√ß√£o',
                                marker_color=colors if colors else '#1f77b4',
                                boxmean='sd'
                            ))

                            fig.update_layout(
                                yaxis_title="Valor"
                            )

                        elif chart_type == "heatmap" and x_data and y_data:
                            # Heatmap (requer dados em formato matriz)
                            z_data = chart_data.get("z", [[]])
                            fig.add_trace(go.Heatmap(
                                x=x_data,
                                y=y_data,
                                z=z_data,
                                colorscale='Viridis'
                            ))

                            fig.update_layout(
                                xaxis_title="X",
                                yaxis_title="Y"
                            )

                        elif chart_type == "funnel" and x_data and y_data:
                            # Funil
                            fig.add_trace(go.Funnel(
                                x=y_data,
                                y=x_data,
                                textinfo="value+percent total",
                                marker=dict(color=colors if colors else None)
                            ))

                        elif x_data and y_data:
                            # Fallback: tentar renderizar como barra
                            st.warning(f"‚ö†Ô∏è Tipo '{chart_type}' usando renderiza√ß√£o padr√£o (barras)")
                            fig.add_trace(go.Bar(x=x_data, y=y_data))
                        else:
                            st.error("Dados do gr√°fico n√£o dispon√≠veis")
                            continue

                        # Layout comum para todos os gr√°ficos
                        fig.update_layout(
                            title={
                                'text': response_data.get("title", "Gr√°fico"),
                                'x': 0.5,
                                'xanchor': 'center',
                                'font': {'size': 16, 'family': 'Arial Black'}
                            },
                            height=height,
                            margin=margin,
                            showlegend=chart_type in ["line", "area", "scatter"],
                            plot_bgcolor='rgba(0,0,0,0)',
                            paper_bgcolor='rgba(0,0,0,0)',
                            font=dict(family="Arial, sans-serif", size=12, color="#333"),
                            hoverlabel=dict(bgcolor="white", font_size=12, font_family="Arial")
                        )
                    else:
                        # Formato Plotly padr√£o (j√° completo)
                        if isinstance(content, str):
                            import json
                            chart_data = json.loads(content)
                        else:
                            chart_data = content

                        # Usar gr√°fico Plotly diretamente
                        fig = go.Figure(chart_data)

                    # Renderizar gr√°fico com chave √∫nica para evitar conflitos
                    import hashlib
                    import time

                    # Gerar chave √∫nica baseada na query e timestamp
                    user_query = response_data.get("user_query", "")
                    chart_key = hashlib.md5(f"{user_query}_{time.time()}".encode()).hexdigest()[:8]

                    st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': True}, key=f"chart_{chart_key}")

                    # Bot√£o para salvar gr√°fico
                    col1, col2 = st.columns(2)

                    with col1:
                        if st.button("üíæ Salvar no Dashboard", key=f"save_chart_{chart_key}"):
                            if "dashboard_charts" not in st.session_state:
                                st.session_state.dashboard_charts = []

                            chart_data = {
                                "title": response_data.get("title", "Gr√°fico"),
                                "type": "chart",
                                "output": fig,
                                "query": user_query,
                                "timestamp": datetime.now().isoformat()
                            }
                            st.session_state.dashboard_charts.append(chart_data)
                            st.success("‚úÖ Gr√°fico salvo no Dashboard!")

                    with col2:
                        # Salvar gr√°fico em arquivo
                        import os
                        os.makedirs("reports/charts", exist_ok=True)

                        timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
                        title_safe = response_data.get("title", "grafico").replace(" ", "_")[:50]

                        # Salvar como HTML (sempre funciona)
                        filename_html = f"reports/charts/{title_safe}_{timestamp_str}.html"
                        fig.write_html(filename_html)

                        # Tentar salvar como PNG (requer kaleido)
                        filename_png = f"reports/charts/{title_safe}_{timestamp_str}.png"
                        try:
                            fig.write_image(filename_png, width=1200, height=800)
                            st.download_button(
                                label="üì• Download PNG",
                                data=open(filename_png, "rb").read(),
                                file_name=f"{title_safe}.png",
                                mime="image/png",
                                key=f"download_png_{chart_key}"
                            )
                        except Exception as e:
                            # Se falhar PNG, oferecer HTML
                            st.download_button(
                                label="üì• Download HTML",
                                data=open(filename_html, "r", encoding="utf-8").read(),
                                file_name=f"{title_safe}.html",
                                mime="text/html",
                                key=f"download_html_{chart_key}"
                            )
                            if st.session_state.get('role') == 'admin':
                                st.caption(f"‚ÑπÔ∏è PNG n√£o dispon√≠vel: {str(e)[:100]}")

                    # Mostrar informa√ß√µes adicionais
                    result_info = response_data.get("result", {})
                    if "total_unes" in result_info:
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Total de UNEs", result_info.get("total_unes", 0))
                        with col2:
                            st.metric("UNEs Exibidas", result_info.get("unes_exibidas", 0))
                        with col3:
                            st.metric("Total de Vendas", f"{result_info.get('total_vendas', 0):,.0f}")

                    # Interatividade: bot√µes para drill-down por UNE (se aplic√°vel)
                    if "produto_codigo" in result_info and result_info.get("total_unes", 0) > 1:
                        st.write("üîç **An√°lise Detalhada por UNE:**")
                        st.info("üí° **Dica:** Para ver vendas mensais de uma UNE espec√≠fica, pergunte: 'gr√°fico de barras do produto [c√≥digo] na une [n√∫mero]'")

                    st.success("‚úÖ Gr√°fico gerado com sucesso!")
                except Exception as e:
                    st.error(f"Erro ao renderizar gr√°fico: {e}")
                    st.write("Dados do gr√°fico:", content)
            elif response_type == "multiple_charts" and isinstance(content, list):
                # ‚úÖ CORRE√á√ÉO: Renderizar m√∫ltiplos gr√°ficos Plotly
                user_query = response_data.get("user_query")
                if user_query:
                    st.caption(f"üìù Pergunta: {user_query}")

                try:
                    import plotly.io as pio
                    import json

                    st.info(f"üìä {len(content)} gr√°ficos gerados:")

                    for i, chart_json in enumerate(content):
                        # Parse JSON para Figure
                        fig = pio.from_json(chart_json)

                        # Exibir subt√≠tulo para cada gr√°fico
                        chart_title = fig.layout.title.text if fig.layout.title and fig.layout.title.text else f"Gr√°fico {i+1}"
                        st.subheader(chart_title)

                        # Renderizar o gr√°fico
                        st.plotly_chart(fig, use_container_width=True, key=f"chart_{i}_{uuid.uuid4()}")

                    st.success(f"‚úÖ {len(content)} gr√°ficos gerados com sucesso!")
                except Exception as e:
                    st.error(f"Erro ao renderizar m√∫ltiplos gr√°ficos: {e}")
                    st.write("Dados dos gr√°ficos:", content)
            elif response_type == "data" and isinstance(content, list):
                # üìù Mostrar contexto da pergunta que gerou os dados
                user_query = response_data.get("user_query")
                if user_query:
                    st.caption(f"üìù Pergunta: {user_query}")

                if content:
                    # üí∞ FORMATA√á√ÉO BRASILEIRA: Aplicar formata√ß√£o R$ automaticamente
                    try:
                        from core.utils.dataframe_formatter import format_dataframe_for_display, create_download_csv

                        df_original = pd.DataFrame(content)

                        # Debug: Mostrar colunas ANTES da formata√ß√£o (apenas para admin)
                        user_role = st.session_state.get('role', '')


                        df_formatado = format_dataframe_for_display(df_original, auto_detect=True)

                        # Preparar dados para download (necess√°rio antes do DataFrame interativo)
                        csv_data, csv_filename = create_download_csv(df_original, filename_prefix="export")

                        # Debug: Confirmar formata√ß√£o aplicada
                        if user_role == 'admin':
                            st.caption(f"‚úÖ Formata√ß√£o brasileira aplicada (R$, separadores de milhar)")

                        # Exibir DataFrame formatado
                        # ‚úÖ Configura√ß√£o avan√ßada baseada em Context7 (/streamlit/docs)

                        # Configura√ß√£o de colunas com formata√ß√£o personalizada
                        column_config = {}

                        # Detectar e configurar colunas monet√°rias
                        for col in df_formatado.columns:
                            col_lower = str(col).lower()

                            # Colunas de vendas/valores monet√°rios
                            if any(kw in col_lower for kw in ['venda', 'preco', 'liquido', 'valor', 'custo', 'mes_']):
                                column_config[col] = st.column_config.TextColumn(
                                    col,
                                    help=f"Valores em Reais (R$)",
                                    width="medium"
                                )

                            # Colunas de estoque/quantidades
                            elif any(kw in col_lower for kw in ['estoque', 'quantidade', 'qtd']):
                                column_config[col] = st.column_config.TextColumn(
                                    col,
                                    help=f"Quantidade em unidades",
                                    width="small"
                                )

                            # Colunas de texto (produto, categoria, etc)
                            elif any(kw in col_lower for kw in ['nome', 'descricao', 'categoria', 'segmento', 'fabricante']):
                                column_config[col] = st.column_config.TextColumn(
                                    col,
                                    help=f"Informa√ß√£o textual",
                                    width="large"
                                )

                        # Exibir DataFrame com sele√ß√£o interativa
                        event = st.dataframe(
                            df_formatado,
                            use_container_width=True,
                            height=600,  # Altura fixa para scroll completo
                            hide_index=True,  # Ocultar √≠ndice num√©rico (melhor UX)
                            column_config=column_config,  # Formata√ß√£o personalizada por coluna
                            row_height=35,  # Altura compacta para melhor densidade visual
                            on_select="rerun",  # Recarregar app quando linhas forem selecionadas
                            selection_mode="multi-row",  # Permitir sele√ß√£o de m√∫ltiplas linhas
                            key=f"dataframe_main_{i}"  # ‚úÖ FIX: Key √∫nico para evitar erro de ID duplicado
                        )

                        # Mostrar linhas selecionadas (se houver)
                        if event and hasattr(event, 'selection') and event.selection.get('rows'):
                            selected_rows = event.selection['rows']

                            if selected_rows:
                                st.info(f"üîç **{len(selected_rows)} linha(s) selecionada(s)**")

                                # Mostrar dados das linhas selecionadas
                                with st.expander("üìã Ver detalhes das linhas selecionadas", expanded=False):
                                    selected_data = df_formatado.iloc[selected_rows]
                                    st.dataframe(
                                        selected_data,
                                        use_container_width=True,
                                        hide_index=True,
                                        column_config=column_config,
                                        key=f"dataframe_selected_{i}"  # ‚úÖ FIX: Key √∫nico
                                    )

                                    # Bot√£o para exportar apenas selecionados
                                    csv_selected = selected_data.to_csv(index=False, encoding='utf-8-sig')
                                    st.download_button(
                                        label="üì• Baixar linhas selecionadas (CSV)",
                                        data=csv_selected,
                                        file_name=f"selecionados_{csv_filename}",
                                        mime="text/csv",
                                        key=f"download_selected_{uuid.uuid4()}"
                                    )

                        # Bot√£o de download com formata√ß√£o (todos os dados)
                        st.download_button(
                            label="üì• Baixar CSV (formatado)",
                            data=csv_data,
                            file_name=csv_filename,
                            mime="text/csv",
                            key=f"download_csv_{uuid.uuid4()}"
                        )

                        st.info(f"üìä {len(content)} registros encontrados")
                    except Exception as e:
                        logger.warning(f"Erro ao formatar DataFrame: {e}")
                        # Fallback: exibir sem formata√ß√£o (com recursos b√°sicos)
                        st.dataframe(
                            pd.DataFrame(content),
                            use_container_width=True,
                            height=600,
                            hide_index=True,
                            row_height=35,  # Mesma densidade visual
                            on_select="rerun",
                            selection_mode="multi-row",
                            key=f"dataframe_fallback_{i}"  # ‚úÖ FIX: Key √∫nico
                        )
                        st.info(f"üìä {len(content)} registros encontrados")
                else:
                    st.warning("‚ö†Ô∏è Nenhum dado encontrado para a consulta.")
            elif response_type == "clarification":
                st.markdown(content.get("message"))
                choices = content.get("choices", {})
                for choice_category, choice_list in choices.items():
                    for choice in choice_list:
                        if st.button(choice, key=f"btn_{choice}_{uuid.uuid4()}"):
                            query_backend(choice)
            elif response_type == "text_with_data":
                # üÜï TEXTO COM OP√á√ÉO DE DOWNLOAD
                user_query = response_data.get("user_query")
                if user_query and msg["role"] == "assistant":
                    st.caption(f"üìù Pergunta: {user_query}")

                # Renderizar conte√∫do textual
                if isinstance(content, str):
                    st.markdown(content, unsafe_allow_html=True)
                else:
                    st.markdown(str(content), unsafe_allow_html=True)

                # üì• BOT√ïES DE DOWNLOAD
                download_data = response_data.get("download_data", [])
                download_filename = response_data.get("download_filename", "dados_export")

                if download_data and isinstance(download_data, list) and len(download_data) > 0:
                    st.markdown("---")
                    st.markdown("### üì• Exportar Dados")

                    # Converter para DataFrame
                    df_export = pd.DataFrame(download_data)

                    # Layout de colunas para bot√µes
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        # Download CSV
                        csv_data = df_export.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            label="üìÑ Baixar CSV",
                            data=csv_data,
                            file_name=f"{download_filename}.csv",
                            mime="text/csv",
                            key=f"csv_{i}_{download_filename}",
                            help="Exportar dados em formato CSV (compat√≠vel com Excel)"
                        )

                    with col2:
                        # Download Excel
                        from io import BytesIO
                        buffer = BytesIO()
                        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                            df_export.to_excel(writer, index=False, sheet_name='Dados')
                        excel_data = buffer.getvalue()

                        st.download_button(
                            label="üìä Baixar Excel",
                            data=excel_data,
                            file_name=f"{download_filename}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            key=f"excel_{i}_{download_filename}",
                            help="Exportar dados em formato Excel (.xlsx)"
                        )

                    with col3:
                        # Download JSON
                        import json
                        json_data = json.dumps(download_data, indent=2, ensure_ascii=False)
                        st.download_button(
                            label="üîß Baixar JSON",
                            data=json_data,
                            file_name=f"{download_filename}.json",
                            mime="application/json",
                            key=f"json_{i}_{download_filename}",
                            help="Exportar dados em formato JSON (para desenvolvedores)"
                        )

                    # Informa√ß√£o sobre os dados
                    st.caption(f"üìä Total de registros: {len(df_export):,} | Colunas: {', '.join(df_export.columns[:5])}{'...' if len(df_export.columns) > 5 else ''}")

            else:
                # üìù Para respostas de texto, tamb√©m mostrar contexto se dispon√≠vel
                user_query = response_data.get("user_query")
                if user_query and msg["role"] == "assistant":
                    st.caption(f"üìù Pergunta: {user_query}")

                # ‚úÖ STREAMING: Renderizar com efeito de digita√ß√£o para novas mensagens
                is_last_message = (i == len(st.session_state.messages) - 1)

                if isinstance(content, str):
                    # Caso normal: content √© string
                    if is_last_message and msg["role"] == "assistant":
                        # ‚úÖ NOVA MENSAGEM: Streaming (typewriter effect)
                        st.write_stream(stream_text(content, speed=0.005))
                    else:
                        # Mensagem antiga do hist√≥rico: renderizar direto
                        st.markdown(content)
                elif isinstance(content, dict):
                    # Se content for dict, tentar extrair mensagem
                    if "message" in content:
                        if is_last_message and msg["role"] == "assistant":
                            st.write_stream(stream_text(content["message"], speed=0.005))
                        else:
                            st.markdown(content["message"])
                    elif "text" in content:
                        if is_last_message and msg["role"] == "assistant":
                            st.write_stream(stream_text(content["text"], speed=0.005))
                        else:
                            st.markdown(content["text"])
                    else:
                        # √öltimo recurso: mostrar JSON formatado
                        st.warning("‚ö†Ô∏è Resposta em formato n√£o esperado:")
                        st.json(content)
                else:
                    # Converter para string
                    text_content = str(content)
                    if is_last_message and msg["role"] == "assistant":
                        st.write_stream(stream_text(text_content, speed=0.005))
                    else:
                        st.markdown(text_content)

                # ‚úÖ DEBUG PARA ADMINS: Mostrar estrutura da resposta
                if msg["role"] == "assistant" and st.session_state.get('role') == 'admin':
                    with st.expander("üîç Debug (Admin)", expanded=False):
                        st.write("**Response Data Structure:**")
                        st.json(response_data)

                        st.write("**Response Type:**", response_type)
                        st.write("**Content Type:**", type(content).__name__)

                        if isinstance(content, str):
                            st.write("**Content Length:**", len(content))
                        elif isinstance(content, (list, dict)):
                            st.write("**Content Keys/Length:**",
                                    list(content.keys()) if isinstance(content, dict) else len(content))

                # ‚úÖ FEEDBACK REMOVIDO - Interface limpa conforme solicitado

        except Exception as e:
            # ‚ùå Tratamento de erro na renderiza√ß√£o
            st.error(f"Erro ao renderizar mensagem {i+1}: {str(e)}")
            st.write(f"Dados da mensagem: {msg}")

    # Verificar se h√° uma pergunta selecionada da p√°gina de exemplos
    if 'pergunta_selecionada' in st.session_state and st.session_state.pergunta_selecionada:
        pergunta = st.session_state.pergunta_selecionada
        st.session_state.pergunta_selecionada = None  # Limpar para n√£o processar novamente
        query_backend(pergunta)
        st.rerun()

    with st.sidebar:
        st.divider()
        if st.button("Logout"):
            st.session_state.authenticated = False
            st.session_state.username = ""
            st.session_state.role = ""
            # Clear chat history on logout
            st.session_state.messages = [
                {
                    "role": "assistant",
                    "content": {
                        "type": "text",
                        "content": "Voc√™ foi desconectado. Fa√ßa login para continuar."
                    }
                }
            ]
            st.rerun()

    if prompt := st.chat_input("Fa√ßa sua pergunta..."):
        query_backend(prompt)
