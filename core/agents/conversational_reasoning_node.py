"""
MÃ³dulo de RaciocÃ­nio Conversacional - Conversational Reasoning Engine

Este mÃ³dulo implementa uma camada de raciocÃ­nio explÃ­cito que torna o agente
verdadeiramente conversacional, nÃ£o apenas um executor de queries.

Baseado em Extended Thinking patterns do Context7 Anthropic Cookbook.

Author: devAndreJr
Version: 3.0.0 - Conversational AI
"""

import logging
import json
import re
from typing import Dict, Any, Tuple, List, Optional
from core.agent_state import AgentState
from core.llm_base import BaseLLMAdapter

logger = logging.getLogger(__name__)


class ConversationalReasoningEngine:
    """
    ğŸ§  Motor de RaciocÃ­nio Conversacional

    Implementa Extended Thinking para anÃ¡lise profunda da intenÃ§Ã£o do usuÃ¡rio,
    detectando contexto emocional, necessidades implÃ­citas e escolhendo o modo
    de resposta adequado (conversacional vs analÃ­tico).
    """

    def __init__(self, llm_adapter: BaseLLMAdapter):
        """
        Inicializa o motor de raciocÃ­nio.

        Args:
            llm_adapter: Adaptador LLM (Gemini ou DeepSeek)
        """
        self.llm_adapter = llm_adapter
        self.conversation_memory: List[Dict[str, str]] = []

        logger.info("ğŸ§  ConversationalReasoningEngine inicializado")

    def reason_about_user_intent(self, state: AgentState) -> Tuple[str, Dict[str, Any]]:
        """
        ğŸ¯ RACIOCÃNIO PROFUNDO: Analisa a intenÃ§Ã£o do usuÃ¡rio com Extended Thinking

        Este mÃ©todo implementa a primeira camada de processamento, onde o agente:
        1. Analisa o contexto completo da conversa
        2. Detecta o tom emocional do usuÃ¡rio
        3. Identifica necessidades implÃ­citas
        4. Decide o modo de resposta apropriado

        Args:
            state: Estado atual do agente com histÃ³rico de mensagens

        Returns:
            Tupla (mode, reasoning_result):
            - mode: "conversational" ou "analytical"
            - reasoning_result: DicionÃ¡rio com anÃ¡lise detalhada
        """
        messages = state.get("messages", [])
        if not messages:
            logger.warning("âš ï¸ Nenhuma mensagem no estado")
            return "conversational", self._create_fallback_reasoning()

        user_query = self._extract_user_message(messages[-1])
        conversation_history = self._format_conversation_history(messages)

        # ğŸ§  PROMPT DE RACIOCÃNIO PROFUNDO
        reasoning_prompt = self._build_reasoning_prompt(user_query, conversation_history)

        logger.info(f"ğŸ§  Analisando intent: '{user_query[:80]}...'")

        try:
            # ğŸ”¥ CHAMADA COM TEMPERATURA ALTA para raciocÃ­nio criativo
            response = self.llm_adapter.get_completion(
                messages=[{"role": "user", "content": reasoning_prompt}],
                json_mode=True,
                temperature=0.8,  # Alta criatividade no raciocÃ­nio
                max_tokens=2000,
                cache_context={"operation": "conversational_reasoning", "stage": "intent_analysis"}
            )

            reasoning_result = self._parse_reasoning(response.get("content", "{}"))

            # ğŸ“Š LOGGING DETALHADO
            mode = reasoning_result.get("mode", "conversational")
            emotional_tone = reasoning_result.get("emotional_tone", "neutro")
            confidence = reasoning_result.get("confidence", 0.5)

            logger.info(f"ğŸ¯ Mode: {mode} | Emotion: {emotional_tone} | Confidence: {confidence:.2f}")
            logger.info(f"ğŸ’­ Reasoning: {reasoning_result.get('reasoning', 'N/A')[:100]}...")

            return mode, reasoning_result

        except Exception as e:
            logger.error(f"âŒ Erro no raciocÃ­nio: {e}", exc_info=True)
            return "conversational", self._create_fallback_reasoning()

    def generate_conversational_response(
        self,
        reasoning: Dict[str, Any],
        state: AgentState
    ) -> str:
        """
        ğŸ’¬ MODO CONVERSACIONAL: Gera resposta natural e humana

        Este mÃ©todo Ã© acionado quando o usuÃ¡rio:
        - EstÃ¡ conversando casualmente
        - Precisa de clarificaÃ§Ã£o
        - Fez uma saudaÃ§Ã£o/agradecimento
        - EstÃ¡ frustrado e precisa de empatia

        Args:
            reasoning: Resultado da anÃ¡lise de raciocÃ­nio
            state: Estado atual do agente

        Returns:
            Resposta conversacional natural em portuguÃªs
        """
        messages = state.get("messages", [])
        user_query = self._extract_user_message(messages[-1])
        emotional_tone = reasoning.get("emotional_tone", "neutro")
        needs_clarification = reasoning.get("needs_clarification", False)

        # ğŸ¨ PROMPT CONVERSACIONAL com temperatura mÃ¡xima
        conversational_prompt = self._build_conversational_prompt(
            user_query,
            emotional_tone,
            reasoning,
            self._format_conversation_history(messages[-5:])  # Ãšltimas 5 mensagens
        )

        logger.info(f"ğŸ’¬ Gerando resposta conversacional (tom: {emotional_tone})")

        try:
            response = self.llm_adapter.get_completion(
                messages=[{"role": "user", "content": conversational_prompt}],
                temperature=1.0,  # ğŸ”¥ TEMPERATURA MÃXIMA = respostas mais humanas
                max_tokens=800,
                cache_context={"operation": "conversational_response", "tone": emotional_tone}
            )

            response_text = response.get("content", "")

            # Remover possÃ­veis tags JSON se houver
            response_text = self._clean_response(response_text)

            logger.info(f"âœ… Resposta conversacional gerada: {len(response_text)} chars")
            return response_text

        except Exception as e:
            logger.error(f"âŒ Erro ao gerar resposta conversacional: {e}", exc_info=True)
            return self._get_fallback_response(emotional_tone)

    def _build_reasoning_prompt(self, user_query: str, conversation_history: str) -> str:
        """ConstrÃ³i o prompt de raciocÃ­nio profundo"""

        return f"""# ğŸ§  ANÃLISE DE INTENÃ‡ÃƒO CONVERSACIONAL

VocÃª Ã© a Caculinha, uma assistente de BI conversacional. VocÃª NÃƒO Ã© um robÃ´ executor de queries.

## ğŸ“š CONTEXTO DA CONVERSA

HistÃ³rico recente:
{conversation_history}

**Mensagem atual:** "{user_query}"

## ğŸ¤” TAREFA: PENSAR PROFUNDAMENTE

Analise a mensagem e responda estas perguntas em seu raciocÃ­nio:

1. **IntenÃ§Ã£o Real**: O que o usuÃ¡rio REALMENTE quer? (alÃ©m das palavras literais)
2. **Tom Emocional**: Como ele estÃ¡ se sentindo? (frustrado/curioso/casual/urgente/neutro/confuso)
3. **Contexto**: Ã‰ continuaÃ§Ã£o da conversa anterior ou novo tÃ³pico?
4. **Clareza**: Ele tem informaÃ§Ã£o suficiente ou estÃ¡ confuso sobre algo?
5. **Tipo de Resposta**: Preciso conversar ou executar anÃ¡lise tÃ©cnica?

## ğŸ¯ CATEGORIZAÃ‡ÃƒO

**MODO CONVERSACIONAL** - Use quando:
- SaudaÃ§Ãµes/agradecimentos/despedidas
- Perguntas sobre capacidades ("o que vocÃª faz?", "pode me ajudar com...")
- Feedback emocional ("nÃ£o entendi", "estÃ¡ confuso", "muito obrigado")
- InformaÃ§Ã£o INSUFICIENTE (falta UNE, produto, perÃ­odo, etc.)
- Tom frustrado (precisa de empatia)
- Pedidos vagos sem detalhes tÃ©cnicos

**MODO ANALÃTICO** - Use quando:
- Pedido CLARO de dados/anÃ¡lise com todas informaÃ§Ãµes
- Query tÃ©cnica bem definida (ex: "MC do produto 123 na UNE SCR")
- SolicitaÃ§Ã£o de grÃ¡fico/relatÃ³rio com contexto completo

## ğŸ“¤ RESPOSTA (JSON)

```json
{{
  "mode": "conversational" ou "analytical",
  "reasoning": "Seu raciocÃ­nio em 2-3 frases explicando POR QUE escolheu este modo",
  "emotional_tone": "frustrado/curioso/casual/urgente/neutro/confuso",
  "confidence": 0.0-1.0,
  "needs_clarification": true/false,
  "clarification_question": "pergunta natural se needs_clarification=true, senÃ£o null",
  "missing_info": ["lista", "de", "informaÃ§Ãµes", "faltando"] ou null,
  "next_action": {{
    "type": "respond_directly" ou "use_tool" ou "ask_clarification",
    "response_style": "friendly/empathetic/technical/excited/patient"
  }}
}}
```

**IMPORTANTE**:
- Seja genuÃ­no e humano no raciocÃ­nio
- Se FALTAR informaÃ§Ã£o (UNE, produto, etc.), escolha "conversational" e peÃ§a clarificaÃ§Ã£o
- Prefira "conversational" na dÃºvida - melhor conversar do que errar a query
"""

    def _build_conversational_prompt(
        self,
        user_query: str,
        emotional_tone: str,
        reasoning: Dict[str, Any],
        conversation_history: str
    ) -> str:
        """ConstrÃ³i o prompt para resposta conversacional"""

        clarification_question = reasoning.get("clarification_question", "")
        missing_info = reasoning.get("missing_info", [])
        response_style = reasoning.get("next_action", {}).get("response_style", "friendly")

        # ğŸ¨ Exemplos de tom baseados na emoÃ§Ã£o detectada
        tone_examples = {
            "frustrado": '''
**Tom EmpÃ¡tico:**
"Opa, vi que vocÃª tÃ¡ tentando hÃ¡ um tempo e nÃ£o deu certo. ğŸ˜• Deixa eu te ajudar de outro jeito..."
"Poxa, desculpa pela confusÃ£o! Vou te explicar melhor..."
            ''',
            "curioso": '''
**Tom Entusiasmado:**
"Boa pergunta! ğŸ˜Š Vou te mostrar algo interessante sobre isso..."
"Olha sÃ³ que legal! Isso que vocÃª perguntou Ã© super importante porque..."
            ''',
            "casual": '''
**Tom Leve:**
"Claro! Vou dar uma olhada nisso pra vocÃª ğŸ‘€"
"Tranquilo! Deixa comigo..."
            ''',
            "urgente": '''
**Tom Ãgil:**
"Entendi, vou resolver isso rapidinho pra vocÃª! âš¡"
"Pode deixar, jÃ¡ vou te trazer essa informaÃ§Ã£o!"
            ''',
            "confuso": '''
**Tom Paciente:**
"Sem problemas! Deixa eu te explicar melhor... ğŸ˜Š"
"Vou te guiar passo a passo, fica tranquilo!"
            ''',
            "neutro": '''
**Tom Profissional AmigÃ¡vel:**
"Claro! Vou te ajudar com isso."
"Entendi. Deixa eu te mostrar..."
            '''
        }

        tone_example = tone_examples.get(emotional_tone, tone_examples["neutro"])

        # Construir seÃ§Ã£o de informaÃ§Ãµes faltando
        missing_info_section = ""
        if missing_info:
            missing_list = ', '.join(missing_info)
            missing_info_section = f"## â“ INFORMAÃ‡Ã•ES FALTANDO\n{missing_list}\n\n"

        # Construir seÃ§Ã£o de clarificaÃ§Ã£o ou resposta
        if clarification_question:
            task_section = f"## ğŸ¯ CLARIFICAÃ‡ÃƒO NECESSÃRIA\n\n{clarification_question}\n\nResponda de forma natural fazendo esta pergunta, mas reformule com suas palavras!"
        else:
            task_section = "## ğŸ¯ RESPONDA Ã€ MENSAGEM\n\nResponda naturalmente Ã  mensagem do usuÃ¡rio no tom apropriado."

        return f'''# ğŸ’¬ RESPOSTA CONVERSACIONAL DA CACULINHA

VocÃª Ã© a Caculinha. Responda de forma COMPLETAMENTE NATURAL e HUMANA.

## ğŸ­ CONTEXTO EMOCIONAL
UsuÃ¡rio estÃ¡: **{emotional_tone}**
Estilo de resposta: **{response_style}**

## ğŸ“œ CONVERSA RECENTE
{conversation_history}

## ğŸ’¬ MENSAGEM ATUAL
"{user_query}"

## ğŸ§  SEU RACIOCÃNIO
{reasoning.get('reasoning', '')}

{missing_info_section}## ğŸ¨ EXEMPLOS DE TOM APROPRIADO
{tone_example}

## âœï¸ INSTRUÃ‡Ã•ES PARA SUA RESPOSTA

1. **Seja vocÃª mesma**: Fale como uma PESSOA REAL, nÃ£o um assistente formal
2. **Use o tom certo**: Adapte-se ao estado emocional detectado ({emotional_tone})
3. **Seja conversacional**:
   - Use contraÃ§Ãµes naturais (tÃ¡, nÃ©, pra, vou dar uma olhada)
   - Emojis moderados quando apropriado
   - Linguagem do dia-a-dia
4. **Mostre personalidade**: VocÃª Ã© prestativa, curiosa e GOSTA de ajudar

{task_section}

**IMPORTANTE:**
- NÃƒO use linguagem corporativa ("prezado usuÃ¡rio", "conforme solicitado")
- NÃƒO comece com "De acordo com..." ou "Conforme..."
- NÃƒO seja robÃ³tica
- SEJA genuÃ­na e humana
- Se precisar pedir informaÃ§Ã£o, pergunte de forma natural

**RESPONDA APENAS O TEXTO (sem JSON, sem tags):**
'''

    def _extract_user_message(self, message: Any) -> str:
        """Extrai conteÃºdo da mensagem do usuÃ¡rio"""
        if hasattr(message, 'content'):
            return str(message.content)
        elif isinstance(message, dict):
            return str(message.get('content', ''))
        return str(message)

    def _format_conversation_history(self, messages: List) -> str:
        """Formata histÃ³rico de conversa de forma legÃ­vel"""
        if not messages or len(messages) <= 1:
            return "(Primeira mensagem da conversa)"

        history = []
        for msg in messages[:-1]:  # Todas exceto a Ãºltima
            try:
                role = "UsuÃ¡rio" if (hasattr(msg, 'type') and msg.type == 'human') or \
                                    (hasattr(msg, 'role') and msg.role == 'user') else "Caculinha"
                content = self._extract_user_message(msg)
                # Truncar mensagens muito longas
                content_preview = content[:150] + "..." if len(content) > 150 else content
                history.append(f"{role}: {content_preview}")
            except Exception as e:
                logger.warning(f"Erro ao formatar mensagem do histÃ³rico: {e}")
                continue

        return "\n".join(history[-5:]) if history else "(Sem histÃ³rico)"  # Ãšltimas 5

    def _parse_reasoning(self, content: str) -> Dict[str, Any]:
        """Parse do resultado de raciocÃ­nio com validaÃ§Ã£o robusta"""

        # Limpar markdown se presente
        if "```json" in content:
            match = re.search(r"```json\n(.*?)```", content, re.DOTALL)
            if match:
                content = match.group(1).strip()
        elif "```" in content:
            match = re.search(r"```\n(.*?)```", content, re.DOTALL)
            if match:
                content = match.group(1).strip()

        try:
            result = json.loads(content)

            # Validar campos obrigatÃ³rios
            if "mode" not in result:
                result["mode"] = "conversational"  # Default seguro

            if "emotional_tone" not in result:
                result["emotional_tone"] = "neutro"

            if "reasoning" not in result:
                result["reasoning"] = "AnÃ¡lise automÃ¡tica da intenÃ§Ã£o"

            return result

        except json.JSONDecodeError as e:
            logger.warning(f"âš ï¸ Erro ao parsear reasoning JSON: {e}")
            return self._create_fallback_reasoning()

    def _create_fallback_reasoning(self) -> Dict[str, Any]:
        """Cria um reasoning fallback para casos de erro"""
        return {
            "mode": "conversational",
            "reasoning": "NÃ£o foi possÃ­vel analisar completamente a intenÃ§Ã£o. Vou responder de forma conversacional.",
            "emotional_tone": "neutro",
            "confidence": 0.5,
            "needs_clarification": False,
            "next_action": {
                "type": "respond_directly",
                "response_style": "friendly"
            }
        }

    def _clean_response(self, response: str) -> str:
        """Remove tags JSON ou markdown indesejadas da resposta"""

        # Remover blocos JSON
        response = re.sub(r'```json.*?```', '', response, flags=re.DOTALL)
        response = re.sub(r'```.*?```', '', response, flags=re.DOTALL)

        # Remover objetos JSON soltos
        response = re.sub(r'\{["\']content["\']\s*:\s*["\'].*?["\']\}', '', response, flags=re.DOTALL)

        return response.strip()

    def _get_fallback_response(self, emotional_tone: str) -> str:
        """Retorna uma resposta fallback baseada no tom emocional"""

        fallback_responses = {
            "frustrado": "Poxa, desculpa pela dificuldade! ğŸ˜• Pode me explicar de novo o que vocÃª precisa? Vou tentar ajudar de outra forma.",
            "curioso": "Boa pergunta! ğŸ˜Š Deixa eu te ajudar com isso. Pode me dar mais detalhes sobre o que vocÃª quer saber?",
            "casual": "Claro! ğŸ‘ Como posso te ajudar?",
            "urgente": "Entendi! Vou te ajudar rapidinho. Pode me dar mais detalhes?",
            "confuso": "Sem problemas! Vou te explicar melhor. O que vocÃª gostaria de saber?",
            "neutro": "OlÃ¡! Sou a Caculinha, sua assistente de dados. Como posso te ajudar?"
        }

        return fallback_responses.get(emotional_tone, fallback_responses["neutro"])
