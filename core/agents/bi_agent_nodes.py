"""
N√≥s (estados) para o StateGraph da arquitetura avan√ßada do Agent_BI.
Cada fun√ß√£o representa um passo no fluxo de processamento da consulta.
"""

import logging
import json
import re
from typing import Dict, Any
import pandas as pd
import numpy as np

# Importa√ß√µes corrigidas baseadas na estrutura completa do projeto
from core.agent_state import AgentState
from core.llm_base import BaseLLMAdapter
from core.agents.code_gen_agent import CodeGenAgent
from core.tools.data_tools import fetch_data_from_query
from core.connectivity.parquet_adapter import ParquetAdapter


from core.utils.json_utils import _clean_json_values # Import the cleaning function


logger = logging.getLogger(__name__)

def _extract_user_query(state: AgentState) -> str:
    """Extrai a query do usu√°rio do state, lidando com objetos LangChain."""
    last_message = state['messages'][-1]
    return last_message.content if hasattr(last_message, 'content') else last_message.get('content', '')

def classify_intent(state: AgentState, llm_adapter: BaseLLMAdapter) -> Dict[str, Any]:
    """
    Classifica a inten√ß√£o do utilizador para roteamento do fluxo.
    As inten√ß√µes poss√≠veis s√£o:
    - 'python_analysis': Para perguntas complexas que exigem an√°lise, agrega√ß√£o ou ranking (ex: 'top 5', 'mais vendido').
    - 'gerar_grafico': Para pedidos diretos de gr√°ficos sem l√≥gica complexa.
    - 'resposta_simples': Para consultas que podem ser respondidas com filtros simples.
    """
    user_query = _extract_user_query(state)
    logger.info(f"[NODE] classify_intent: Recebida query '{user_query}'")
    
    prompt = f"""
    Analise a consulta do utilizador e classifique a inten√ß√£o principal para guiar o fluxo de an√°lise de dados. Responda APENAS com um objeto JSON.

    **Inten√ß√µes Poss√≠veis:**

    1.  **`une_operation`**: Use para opera√ß√µes UNE (abastecimento, MC, pre√ßos).
        - Palavras-chave: "abastecimento", "abastecer", "reposi√ß√£o", "MC", "m√©dia comum", "pre√ßo final", "calcular pre√ßo", "UNE", "linha verde".
        - **Exemplos:**
            - "quais produtos precisam abastecimento na UNE 2586?" ‚Üí `{{"intent": "une_operation"}}`
            - "qual a MC do produto 704559?" ‚Üí `{{"intent": "une_operation"}}`
            - "calcule o pre√ßo de R$ 800 ranking 0 a vista" ‚Üí `{{"intent": "une_operation"}}`

    2.  **`python_analysis`**: Use para perguntas que exigem **an√°lise, ranking, agrega√ß√£o ou compara√ß√µes**.
        - Palavras-chave: "qual mais", "top", "maior", "menor", "evolu√ß√£o", "comparar", "an√°lise de", "ranking de".
        - **Exemplos:**
            - "qual produto mais vende no segmento tecidos?" ‚Üí `{{"intent": "python_analysis"}}`
            - "top 5 categorias por venda" ‚Üí `{{"intent": "python_analysis"}}`

    3.  **`gerar_grafico`**: Use para pedidos **diretos e simples** de gr√°ficos.
        - **Exemplos:**
            - "gere um gr√°fico de vendas por categoria" ‚Üí `{{"intent": "gerar_grafico"}}`

    4.  **`resposta_simples`**: Use para perguntas com **filtragem direta**.
        - **Exemplos:**
            - "liste os produtos da categoria 'AVIAMENTOS'" ‚Üí `{{"intent": "resposta_simples"}}`
            - "qual o estoque do produto 12345?" ‚Üí `{{"intent": "resposta_simples"}}`

    **REGRAS:**
    - Priorize `une_operation` se mencionar UNE, abastecimento, MC ou c√°lculo de pre√ßo.
    - Responda APENAS com o objeto JSON contendo a chave 'intent'.

    **Consulta do Usu√°rio:**
    "{user_query}"

    **JSON de Sa√≠da:**
    """
    
    # Use json_mode=True para for√ßar a resposta em JSON
    response_dict = llm_adapter.get_completion(messages=[{"role": "user", "content": prompt}], json_mode=True)
    plan_str = response_dict.get("content", "{}")
    
    # Fallback para extrair JSON de blocos de markdown
    if "```json" in plan_str:
        match = re.search(r"```json\n(.*?)```", plan_str, re.DOTALL)
        if match:
            plan_str = match.group(1).strip()

    try:
        plan = json.loads(plan_str)
    except json.JSONDecodeError:
        logger.warning(f"N√£o foi poss√≠vel decodificar o JSON da inten√ß√£o: {plan_str}")
        # Fallback para a inten√ß√£o mais poderosa em caso de erro de parsing
        plan = {"intent": "python_analysis", "entities": {}}

    intent = plan.get('intent', 'python_analysis')
    logger.info(f"[NODE] classify_intent: Inten√ß√£o classificada como '{intent}'")
    
    # Assegura que o plan sempre tenha a chave 'intent'
    if 'intent' not in plan:
        plan['intent'] = intent
        
    return {"plan": plan, "intent": intent}



def generate_parquet_query(state: AgentState, llm_adapter: BaseLLMAdapter, parquet_adapter: ParquetAdapter) -> Dict[str, Any]:
    """
    Gera um dicion√°rio de filtros para consulta Parquet a partir da pergunta do utilizador, usando o schema do arquivo Parquet e descri√ß√µes de colunas.
    """
    user_query = _extract_user_query(state)
    logger.info(f"[NODE] generate_parquet_query: Gerando filtros para '{user_query}'")

    # Importar field_mapper
    from core.utils.field_mapper import get_field_mapper
    
    # Obter o schema do arquivo Parquet para dar contexto ao LLM
    try:
        schema = parquet_adapter.get_schema()
    except Exception as e:
        logger.error(f"Erro ao obter o schema do arquivo Parquet: {e}", exc_info=True)
        return {"parquet_filters": {}, "final_response": {"type": "error", "content": "N√£o foi poss√≠vel aceder ao schema do arquivo Parquet para gerar a consulta."}}

    # Load the focused catalog (catalog_focused.json)
    import os
    base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    catalog_file_path = os.path.join(base_dir, "data", "catalog_focused.json")
    
    try:
        with open(catalog_file_path, 'r', encoding='utf-8') as f:
            catalog_data = json.load(f)
        
        # Find the entry for admatao.parquet
        admatao_catalog = next((entry for entry in catalog_data if entry.get("file_name") == "admatao.parquet"), None)
        
        if admatao_catalog and "column_descriptions" in admatao_catalog:
            column_descriptions = admatao_catalog["column_descriptions"]
            column_descriptions_str = json.dumps(column_descriptions, indent=2, ensure_ascii=False)
        else:
            column_descriptions_str = "Nenhuma descri√ß√£o de coluna dispon√≠vel."
            logger.warning("Descri√ß√µes de coluna para admatao.parquet n√£o encontradas no cat√°logo.")

    except FileNotFoundError:
        column_descriptions_str = "Erro: Arquivo de cat√°logo n√£o encontrado."
        logger.error(f"Arquivo de cat√°logo n√£o encontrado em {catalog_file_path}", exc_info=True)
    except Exception as e:
        column_descriptions_str = f"Erro ao carregar descri√ß√µes de coluna: {e}"
        logger.error(f"Erro ao carregar descri√ß√µes de coluna: {e}", exc_info=True)
    
    # Inicializar field_mapper
    field_mapper = get_field_mapper(catalog_file_path)
    
    # Gerar mapeamento de campos para o prompt
    field_mapping_guide = """
## Mapeamento de Campos (OBRIGAT√ìRIO)

Quando o usu√°rio mencionar:
- "segmento" ‚Üí use: NOMESEGMENTO
- "categoria" ‚Üí use: NomeCategoria
- "grupo" ‚Üí use: NOMEGRUPO
- "subgrupo" ‚Üí use: NomeSUBGRUPO
- "c√≥digo" ou "produto" ‚Üí use: PRODUTO
- "nome" ‚Üí use: NOME
- "estoque" ‚Üí use: ESTOQUE_UNE
- "pre√ßo" ‚Üí use: LIQUIDO_38
- "vendas" ou "vendas 30 dias" ‚Üí use: VENDA_30DD
- "fabricante" ‚Üí use: NomeFabricante

**REGRAS CR√çTICAS:**
1. NUNCA use "SEGMENTO", sempre use "NOMESEGMENTO"
2. NUNCA use "CATEGORIA", sempre use "NomeCategoria"
3. NUNCA use "CODIGO", sempre use "PRODUTO"
4. Para estoque zero: filtre por ESTOQUE_UNE = 0
5. Para campos de texto: use valores em MAI√öSCULAS
"""


    prompt = f"""
    Voc√™ √© um especialista em traduzir perguntas de neg√≥cio em filtros de dados JSON. Sua tarefa √© analisar a **NOVA Pergunta do Usu√°rio** e convert√™-la em um objeto JSON de filtros, usando o schema e as regras de mapeamento fornecidas.

    {field_mapping_guide}

    **Instru√ß√µes Cr√≠ticas:**
    1.  **FOCO TOTAL NA NOVA PERGUNTA:** Sua resposta DEVE ser uma tradu√ß√£o direta da **NOVA Pergunta do Usu√°rio**.
    2.  **EXTRA√á√ÉO DE C√ìDIGOS:** Se a pergunta contiver um n√∫mero que se pare√ßa com um c√≥digo de produto (geralmente com 5 ou mais d√≠gitos), voc√™ DEVE extra√≠-lo como um filtro para a coluna `PRODUTO`.
    3.  **N√ÉO COPIE OS EXEMPLOS:** Os exemplos abaixo s√£o apenas um guia de estilo e formato. N√£o os use como base para a sua resposta.
    4.  **GERE APENAS JSON:** Sua sa√≠da final deve ser um √∫nico e v√°lido objeto JSON, sem nenhum texto ou explica√ß√£o adicional.
    5.  **CONSULTA VAZIA:** Se a pergunta n√£o contiver nenhum filtro (ex: "liste todas as categorias"), retorne um objeto JSON vazio: `{{}}`.

    **Schema do Arquivo Parquet (para refer√™ncia de colunas):**
    ```
    {schema}
    ```

    ---

    **Exemplos de Formato (Use apenas como guia):**

    - **Exemplo 1 (Filtro de C√≥digo de Produto):**
      - Pergunta: "qual o estoque do produto 369947?"
      - Filtros JSON: `{{"PRODUTO": 369947}}`

    - **Exemplo 2 (Filtro Composto):**
      - Pergunta: "quais s√£o as categorias do segmento tecidos com estoque 0?"
      - Filtros JSON: `{{"NOMESEGMENTO": "TECIDO", "ESTOQUE_UNE": 0}}`
    
    - **Exemplo 3 (Filtro de Texto):**
      - Pergunta: "liste produtos da categoria aviamentos"
      - Filtros JSON: `{{"NomeCategoria": "AVIAMENTOS"}}`

    ---

    **NOVA Pergunta do Usu√°rio (TRADUZIR ESTA):**
    "{user_query}"

    **Filtros JSON Resultantes:**
    """

    response_dict = llm_adapter.get_completion(messages=[{"role": "user", "content": prompt}], json_mode=True)
    filters_str = response_dict.get("content", "{}").strip()

    # Fallback para extrair JSON de blocos de markdown
    if "```json" in filters_str:
        match = re.search(r"```json\n(.*?)```", filters_str, re.DOTALL)
        if match:
            filters_str = match.group(1).strip()

    try:
        parquet_filters = json.loads(filters_str)
    except json.JSONDecodeError:
        logger.warning(f"N√£o foi poss√≠vel decodificar o JSON dos filtros Parquet: {filters_str}")
        parquet_filters = {}

    # ‚úÖ MAPEAMENTO DE COLUNAS: LLM usa nomes padronizados, Parquet tem nomes reais
    column_mapping = {
        'PRODUTO': 'codigo',
        'NOME': 'nome_produto',
        'NOMESEGMENTO': 'nomesegmento',
        'NomeCategoria': 'NOMECATEGORIA',
        'NOMEGRUPO': 'nomegrupo',
        'NomeSUBGRUPO': 'NOMESUBGRUPO',
        'VENDA_30DD': 'venda_30_d',
        'ESTOQUE_UNE': 'estoque_atual',
        'LIQUIDO_38': 'preco_38_percent',
        'UNE_NOME': 'une_nome',
        'NomeFabricante': 'NOMEFABRICANTE'
    }

    # Aplicar mapeamento nos filtros
    mapped_filters = {}
    for key, value in parquet_filters.items():
        mapped_key = column_mapping.get(key, key)
        mapped_filters[mapped_key] = value

    logger.info(f"Filtros originais: {parquet_filters}")
    logger.info(f"Filtros mapeados: {mapped_filters}")

    return {"parquet_filters": mapped_filters}


def execute_query(state: AgentState, parquet_adapter: ParquetAdapter) -> Dict[str, Any]:
    """
    Executa os filtros Parquet do estado.
    """
    user_query = _extract_user_query(state)
    parquet_filters = state.get('parquet_filters', {})

    logger.info(f"[NODE] execute_query: Executando com filtros {parquet_filters}")
    logger.info(f"üìä QUERY EXECUTION - User query: '{user_query}'")
    logger.info(f"üìä QUERY EXECUTION - Filters: {parquet_filters}")

    # A l√≥gica de fallback para filtros vazios foi removida, pois era a causa do MemoryError.
    # Agora, a prote√ß√£o no ParquetAdapter ser√° acionada se os filtros estiverem vazios.
    retrieved_data = fetch_data_from_query.invoke({"query_filters": parquet_filters, "parquet_adapter": parquet_adapter})

    # ‚úÖ LOG DETALHADO DOS RESULTADOS
    if isinstance(retrieved_data, list):
        if retrieved_data and "error" in retrieved_data[0]:
            logger.error(f"‚ùå QUERY ERROR: {retrieved_data[0]}")
        else:
            logger.info(f"‚úÖ QUERY SUCCESS: Retrieved {len(retrieved_data)} rows")
            if retrieved_data:
                logger.info(f"üìã SAMPLE DATA COLUMNS: {list(retrieved_data[0].keys()) if retrieved_data else 'No data'}")
    else:
        logger.warning(f"‚ö†Ô∏è UNEXPECTED DATA TYPE: {type(retrieved_data)}")

    return {"retrieved_data": retrieved_data}

def generate_plotly_spec(state: AgentState, llm_adapter: BaseLLMAdapter, code_gen_agent: CodeGenAgent) -> Dict[str, Any]:
    """
    Gera uma especifica√ß√£o JSON para Plotly ou uma resposta textual usando o CodeGenAgent.
    Este n√≥ agora lida com dois cen√°rios:
    1.  **Com `raw_data`**: Gera um gr√°fico a partir de dados pr√©-filtrados.
    2.  **Sem `raw_data` (fluxo `python_analysis`)**: Gera um script Python para fazer a an√°lise completa (filtrar, agregar, etc.).
    """
    logger.info("N√≥: generate_plotly_spec")
    raw_data = state.get("retrieved_data")
    user_query = _extract_user_query(state)
    plan = state.get("plan", {})
    intent = plan.get("intent")

    logger.info(f"üêç Python CodeGen - User query: '{user_query}'")
    logger.info(f"üêç Python CodeGen - Intent: {intent}")
    logger.info(f"üêç Python CodeGen - Data available: {len(raw_data) if raw_data else 'No pre-loaded data'}")

    # Verifica se o estado de erro j√° foi definido por um n√≥ anterior
    if raw_data and isinstance(raw_data, list) and raw_data and "error" in raw_data[0]:
        return {"final_response": {"type": "text", "content": raw_data[0]["error"]}}

    try:
        # Cen√°rio 1: An√°lise complexa, sem dados pr√©-carregados.
        # O CodeGenAgent deve fazer o trabalho completo.
        if not raw_data:
            prompt_for_code_gen = f"""
            **TAREFA:** Voc√™ deve escrever um script Python para responder √† pergunta do usu√°rio.

            **INSTRU√á√ïES OBRIGAT√ìRIAS:**
            1. **CARREGUE OS DADOS:** Inicie seu script com a linha: `df = load_data()`
            2. **RESPONDA √Ä PERGUNTA:** Usando o dataframe `df`, escreva o c√≥digo para responder √† seguinte pergunta: "{user_query}"
            3. **SALVE O RESULTADO NA VARI√ÅVEL `result`:** A √∫ltima linha do seu script DEVE ser a atribui√ß√£o do resultado final √† vari√°vel `result`. Esta √© a √∫nica forma que o sistema tem para ver sua resposta. N√ÉO use `print()`.

            **Exemplo de Script:**
            ```python
            # Passo 1: Carregar dados
            df = load_data()

            # Passo 2: Responder √† pergunta (ex: "ranking de vendas do segmento tecidos")
            tecidos_df = df[df['NOMESEGMENTO'].str.upper() == 'TECIDO']
            ranking = tecidos_df.groupby('NOME')['VENDA_30DD'].sum().sort_values(ascending=False).reset_index()

            # Passo 3: Salvar resultado
            result = ranking
            ```

            **Seu Script Python (Lembre-se, a √∫ltima linha deve ser `result = ...`):**
            """
        # Cen√°rio 2: Gera√ß√£o de gr√°fico a partir de dados pr√©-carregados.
        else:
            prompt_for_code_gen = f"""
            Com base na consulta do usu√°rio e no DataFrame Pandas `df_raw_data` j√° dispon√≠vel, gere um script Python para criar um gr√°fico com Plotly Express.
            O objeto da figura Plotly resultante deve ser armazenado em uma vari√°vel chamada `result`.
            N√£o inclua `fig.show()`.

            **Consulta do Usu√°rio:** "{user_query}"
            **Dados Brutos (amostra):**
            ```json
            {pd.DataFrame(raw_data).head(3).to_json(orient="records", indent=2)}
            ```

            **Seu Script Python:**
            """

        # O CodeGenAgent espera um dicion√°rio com a query e os dados brutos (se existirem)
        code_gen_input = {
            "query": prompt_for_code_gen,
            "raw_data": raw_data  # Passa os dados brutos ou None
        }
        
        logger.info(f"\n--- PROMPT PARA CODEGENAGENT ---\n{prompt_for_code_gen}\n---------------------------------")

        logger.info("üöÄ Calling code_gen_agent.generate_and_execute_code...")
        code_gen_response = code_gen_agent.generate_and_execute_code(code_gen_input)

        # ‚úÖ LOGS DETALHADOS DO RETORNO DO CODEGENAGENT
        logger.info(f"üìã CodeGenAgent response type: {code_gen_response.get('type')}")
        logger.info(f"üìã CodeGenAgent response keys: {list(code_gen_response.keys())}")

        # Logs espec√≠ficos por tipo
        if code_gen_response.get("type") == "dataframe":
            df_result = code_gen_response.get("output")
            if isinstance(df_result, pd.DataFrame):
                logger.info(f"üìä DataFrame result: {len(df_result)} rows, {len(df_result.columns)} cols")
                logger.info(f"üìä DataFrame columns: {list(df_result.columns)}")
                if len(df_result) > 0:
                    logger.info(f"üìä DataFrame sample (first 3 rows): {df_result.head(3).to_dict(orient='records')}")
            else:
                logger.warning(f"‚ö†Ô∏è Expected DataFrame but got {type(df_result)}")
        elif code_gen_response.get("type") == "text":
            text_output = str(code_gen_response.get("output"))
            logger.info(f"üìù Text result length: {len(text_output)} chars")
            logger.info(f"üìù Text result preview: {text_output[:200]}...")

        # Processa a resposta do CodeGenAgent
        if code_gen_response.get("type") == "chart":
            plotly_spec = json.loads(code_gen_response.get("output"))
            logger.info(f"üìà Chart generated successfully")
            return {"plotly_spec": plotly_spec}

        elif code_gen_response.get("type") == "dataframe":
            # ‚úÖ CORRE√á√ÉO: Converter DataFrame para lista de dicion√°rios
            df_result = code_gen_response.get("output")

            # Garantir que seja DataFrame
            if isinstance(df_result, pd.DataFrame):
                data_list = df_result.to_dict(orient='records')
            else:
                data_list = df_result

            logger.info(f"üìä Converted DataFrame to {len(data_list)} records")
            logger.info(f"üìä Sample record keys: {list(data_list[0].keys()) if data_list else 'Empty'}")
            return {"retrieved_data": data_list}

        elif code_gen_response.get("type") == "text":
            # ‚úÖ CORRE√á√ÉO: Garantir que texto seja STRING e preservar user_query
            text_output = str(code_gen_response.get("output"))
            logger.info(f"üìù Text response: {len(text_output)} chars - Returning as final_response")

            return {
                "final_response": {
                    "type": "text",
                    "content": text_output,
                    "user_query": user_query
                }
            }

        elif code_gen_response.get("type") == "error":
            error_msg = str(code_gen_response.get("output", "Erro desconhecido"))
            logger.error(f"‚ùå CodeGenAgent error: {error_msg}")

            return {
                "final_response": {
                    "type": "text",
                    "content": f"‚ùå Erro ao processar: {error_msg}",
                    "user_query": user_query
                }
            }

        else:
            # ‚úÖ FALLBACK: Tipo desconhecido
            logger.warning(f"‚ö†Ô∏è Unknown CodeGenAgent response type: {code_gen_response.get('type')}")

            return {
                "final_response": {
                    "type": "text",
                    "content": f"‚ö†Ô∏è Resposta inesperada do agente: {code_gen_response.get('output')}",
                    "user_query": user_query
                }
            }

    except Exception as e:
        logger.error(f"Erro ao gerar script Python com CodeGenAgent: {e}", exc_info=True)
        return {"final_response": {"type": "text", "content": f"N√£o consegui gerar a an√°lise. Erro interno: {e}"}}


def format_final_response(state: AgentState) -> Dict[str, Any]:
    """
    Formata a resposta final para o utilizador.
    """
    user_query = _extract_user_query(state)
    logger.info(f"[NODE] format_final_response: Formatando resposta para '{user_query}'")

    # üîç LOGS DETALHADOS DO ESTADO
    logger.info(f"üîç STATE KEYS: {list(state.keys())}")
    logger.info(f"üîç clarification_needed: {state.get('clarification_needed')}")
    logger.info(f"üîç plotly_spec exists: {bool(state.get('plotly_spec'))}")
    logger.info(f"üîç retrieved_data exists: {bool(state.get('retrieved_data'))}")
    logger.info(f"üîç final_response exists: {bool(state.get('final_response'))}")

    # Se retrieved_data existir, logar detalhes
    if state.get("retrieved_data"):
        data = state.get("retrieved_data")
        logger.info(f"üìä retrieved_data type: {type(data)}")
        logger.info(f"üìä retrieved_data length: {len(data) if isinstance(data, list) else 'N/A'}")
        if isinstance(data, list) and len(data) > 0:
            logger.info(f"üìä retrieved_data sample keys: {list(data[0].keys())}")

    # üìù Construir resposta baseada no estado
    response = {}

    # ‚úÖ PRIORIDADE 1: Verificar se j√° existe final_response (resposta direta do CodeGenAgent)
    if state.get("final_response"):
        logger.info(f"‚úÖ Using pre-formatted final_response from state")
        response = state.get("final_response")
        # Garantir que user_query esteja presente
        if "user_query" not in response:
            response["user_query"] = user_query

    # ‚úÖ PRIORIDADE 2: Clarifica√ß√£o
    elif state.get("clarification_needed"):
        response = {"type": "clarification", "content": state.get("clarification_options")}
        logger.info(f"üí¨ CLARIFICATION RESPONSE for query: '{user_query}'")

    # ‚úÖ PRIORIDADE 3: Gr√°fico
    elif state.get("plotly_spec"):
        response = {"type": "chart", "content": state.get("plotly_spec")}
        response["user_query"] = user_query
        logger.info(f"üìà CHART RESPONSE for query: '{user_query}'")

    # ‚úÖ PRIORIDADE 4: Dados tabulares
    elif state.get("retrieved_data"):
        data = state.get("retrieved_data")
        response = {"type": "data", "content": _clean_json_values(data)}
        response["user_query"] = user_query
        logger.info(f"üìä DATA RESPONSE for query: '{user_query}' - {len(data)} rows")

    # ‚ùå FALLBACK: Se nenhum dos acima
    else:
        response = {
            "type": "text",
            "content": "‚ùå N√£o consegui processar a sua solicita√ß√£o. Tente reformular a pergunta."
        }
        response["user_query"] = user_query
        logger.warning(f"‚ùì FALLBACK RESPONSE for query: '{user_query}' - No data in state")
        logger.warning(f"‚ùì State keys available: {list(state.keys())}")

    # ‚úÖ GARANTIR que a pergunta do usu√°rio seja preservada no hist√≥rico
    final_messages = state['messages'] + [{"role": "assistant", "content": response}]

    # üîç LOG DO RESULTADO FINAL
    logger.info(f"‚úÖ FINAL RESPONSE - Type: {response.get('type')}, User Query: '{user_query}'")
    logger.info(f"üìã MESSAGE HISTORY - Total messages: {len(final_messages)}")

    return {"messages": final_messages, "final_response": response}


def execute_une_tool(state: AgentState, llm_adapter: BaseLLMAdapter) -> Dict[str, Any]:
    """
    Executa ferramentas UNE baseado na query do usu√°rio.
    Detecta qual ferramenta UNE usar e extrai os par√¢metros necess√°rios.
    """
    user_query = _extract_user_query(state)
    logger.info(f"[NODE] execute_une_tool: Processando query UNE '{user_query}'")

    # Importar ferramentas UNE
    from core.tools.une_tools import (
        calcular_abastecimento_une,
        calcular_mc_produto,
        calcular_preco_final_une
    )

    # Detectar qual ferramenta usar
    tool_detection_prompt = f"""
    Analise a consulta e identifique qual ferramenta UNE usar.

    Ferramentas dispon√≠veis:
    - calcular_abastecimento_une: Para queries sobre abastecimento, reposi√ß√£o, produtos para abastecer
    - calcular_mc_produto: Para queries sobre MC, m√©dia comum, m√©dia de vendas
    - calcular_preco_final_une: Para queries sobre pre√ßo final, calcular pre√ßo, pre√ßo com desconto

    Retorne APENAS um JSON: {{"tool": "nome_da_ferramenta"}}

    Query: "{user_query}"
    """

    tool_response = llm_adapter.get_completion(
        messages=[{"role": "user", "content": tool_detection_prompt}],
        json_mode=True
    )

    tool_str = tool_response.get("content", "{}").strip()
    if "```json" in tool_str:
        match = re.search(r"```json\n(.*?)```", tool_str, re.DOTALL)
        if match:
            tool_str = match.group(1).strip()

    try:
        tool_data = json.loads(tool_str)
        tool_name = tool_data.get("tool", "")
    except json.JSONDecodeError:
        logger.error(f"Erro ao detectar ferramenta UNE: {tool_str}")
        return {"final_response": {"type": "text", "content": "N√£o consegui identificar a opera√ß√£o UNE solicitada."}}

    logger.info(f"Ferramenta UNE detectada: {tool_name}")

    # Executar ferramenta apropriada
    try:
        if "abastecimento" in tool_name:
            # Extrair par√¢metros para abastecimento
            extract_prompt = f"""
            Extraia o ID da UNE e o segmento (opcional) da consulta.
            Retorne JSON: {{"une_id": <n√∫mero>, "segmento": "<nome ou null>"}}

            Query: "{user_query}"
            """
            params_response = llm_adapter.get_completion(
                messages=[{"role": "user", "content": extract_prompt}],
                json_mode=True
            )
            params_str = params_response.get("content", "{}").strip()
            if "```json" in params_str:
                match = re.search(r"```json\n(.*?)```", params_str, re.DOTALL)
                if match:
                    params_str = match.group(1).strip()

            params = json.loads(params_str)
            une_id = int(params.get("une_id"))
            segmento = params.get("segmento")

            args = {"une_id": une_id}
            if segmento:
                args["segmento"] = segmento

            result = calcular_abastecimento_une.invoke(args)

        elif "mc_produto" in tool_name:
            # Extrair par√¢metros para MC
            extract_prompt = f"""
            Extraia o c√≥digo do produto e o ID da UNE da consulta.
            Retorne JSON: {{"produto_id": <n√∫mero>, "une_id": <n√∫mero>}}

            Query: "{user_query}"
            """
            params_response = llm_adapter.get_completion(
                messages=[{"role": "user", "content": extract_prompt}],
                json_mode=True
            )
            params_str = params_response.get("content", "{}").strip()
            if "```json" in params_str:
                match = re.search(r"```json\n(.*?)```", params_str, re.DOTALL)
                if match:
                    params_str = match.group(1).strip()

            params = json.loads(params_str)
            produto_id = int(params.get("produto_id"))
            une_id = int(params.get("une_id"))

            result = calcular_mc_produto.invoke({"produto_id": produto_id, "une_id": une_id})

        elif "preco" in tool_name:
            # Extrair par√¢metros para pre√ßo
            extract_prompt = f"""
            Extraia o valor da compra, ranking e forma de pagamento.
            Retorne JSON: {{"valor_compra": <n√∫mero>, "ranking": <0-4>, "forma_pagamento": "<vista|30d|90d|120d>"}}

            Query: "{user_query}"
            """
            params_response = llm_adapter.get_completion(
                messages=[{"role": "user", "content": extract_prompt}],
                json_mode=True
            )
            params_str = params_response.get("content", "{}").strip()
            if "```json" in params_str:
                match = re.search(r"```json\n(.*?)```", params_str, re.DOTALL)
                if match:
                    params_str = match.group(1).strip()

            params = json.loads(params_str)
            valor_compra = float(params.get("valor_compra"))
            ranking = int(params.get("ranking"))
            forma_pagamento = params.get("forma_pagamento")

            result = calcular_preco_final_une.invoke({
                "valor_compra": valor_compra,
                "ranking": ranking,
                "forma_pagamento": forma_pagamento
            })
        else:
            return {"final_response": {"type": "text", "content": f"Ferramenta UNE '{tool_name}' n√£o reconhecida."}}

        # Verificar se houve erro
        if "error" in result:
            return {"final_response": {"type": "text", "content": f"Erro: {result['error']}"}}

        # Formatar resposta baseado no tipo de ferramenta
        if "produtos" in result:  # Abastecimento
            retrieved_data = result.get("produtos", [])
            return {"retrieved_data": retrieved_data}
        elif "mc_calculada" in result:  # MC - Formatar para usu√°rio
            response_text = f"""**M√©dia Comum (MC) - Produto {result['produto_id']}**

**Produto:** {result['nome']}
**Segmento:** {result['segmento']}
**UNE:** {result['une_id']}

**Indicadores:**
- MC Calculada: {result['mc_calculada']:.2f} unidades/dia
- Estoque Atual: {result['estoque_atual']:.2f} unidades
- Linha Verde: {result['linha_verde']:.2f} unidades
- Percentual da LV: {result['percentual_linha_verde']:.1f}%

**Recomenda√ß√£o:**
{result['recomendacao']}"""
            return {"final_response": {"type": "text", "content": response_text}}
        elif "valor_original" in result:  # Pre√ßo - Formatar para usu√°rio
            response_text = f"""**C√°lculo de Pre√ßo Final UNE**

**Valor Original:** R$ {result['valor_original']:.2f}
**Tipo de Venda:** {result['tipo']}
**Ranking:** {result['ranking']} ({result['desconto_ranking']})
**Forma de Pagamento:** {result['forma_pagamento']} ({result['desconto_pagamento']})

**C√°lculo:**
- Desconto Ranking: {result['desconto_aplicado_ranking']:.1f}%
- Desconto Pagamento: {result['desconto_aplicado_pagamento']:.1f}%
- **Desconto Total:** {result['desconto_total']:.1f}%

**PRE√áO FINAL:** R$ {result['preco_final']:.2f}"""
            return {"final_response": {"type": "text", "content": response_text}}
        else:  # Fallback - JSON formatado
            response_text = json.dumps(result, indent=2, ensure_ascii=False)
            return {"final_response": {"type": "text", "content": response_text}}

    except Exception as e:
        logger.error(f"Erro ao executar ferramenta UNE: {e}", exc_info=True)
        return {"final_response": {"type": "text", "content": f"Erro ao processar opera√ß√£o UNE: {str(e)}"}}