"""
N√≥s (estados) para o StateGraph da arquitetura avan√ßada do Agent_BI.
Cada fun√ß√£o representa um passo no fluxo de processamento da consulta.
"""

import logging
import json
import re
from typing import Dict, Any
import pandas as pd
import numpy as np

# Importa√ß√µes corrigidas baseadas na estrutura completa do projeto
from core.agent_state import AgentState
from core.llm_base import BaseLLMAdapter
from core.agents.code_gen_agent import CodeGenAgent
from core.tools.data_tools import fetch_data_from_query
from core.connectivity.parquet_adapter import ParquetAdapter


from core.utils.json_utils import _clean_json_values # Import the cleaning function


logger = logging.getLogger(__name__)

def _extract_user_query(state: AgentState) -> str:
    """Extrai a query do usu√°rio do state, lidando com objetos LangChain."""
    last_message = state['messages'][-1]
    return last_message.content if hasattr(last_message, 'content') else last_message.get('content', '')

def classify_intent(state: AgentState, llm_adapter: BaseLLMAdapter) -> Dict[str, Any]:
    """
    Classifica a inten√ß√£o do utilizador usando Few-Shot Learning.

    Baseado em: Context7 - Few-Shot Learning + Confidence Scoring

    Inten√ß√µes poss√≠veis:
    - 'une_operation': Opera√ß√µes UNE (abastecimento, MC, pre√ßos)
    - 'python_analysis': An√°lise complexa SEM visualiza√ß√£o
    - 'gerar_grafico': Visualiza√ß√µes e gr√°ficos
    - 'resposta_simples': Consultas simples de filtro
    """
    user_query = _extract_user_query(state)
    logger.info(f"[NODE] classify_intent: Recebida query '{user_query}'")

    # ‚úÖ NOVO: Few-shot examples com scores de confian√ßa
    few_shot_examples = [
        # une_operation
        {
            "query": "quais produtos precisam abastecimento na UNE 2586?",
            "intent": "une_operation",
            "confidence": 0.95,
            "reasoning": "Menciona 'abastecimento' + 'UNE' (opera√ß√£o espec√≠fica)"
        },
        {
            "query": "qual a MC do produto 704559?",
            "intent": "une_operation",
            "confidence": 0.98,
            "reasoning": "Pergunta sobre MC (M√©dia Comum) - m√©trica UNE"
        },
        {
            "query": "calcule o pre√ßo de R$ 800 ranking 0 a vista",
            "intent": "une_operation",
            "confidence": 0.92,
            "reasoning": "C√°lculo de pre√ßo - regra de neg√≥cio UNE"
        },
        # python_analysis
        {
            "query": "qual produto mais vende no segmento tecidos?",
            "intent": "python_analysis",
            "confidence": 0.90,
            "reasoning": "An√°lise + ranking SEM men√ß√£o a visualiza√ß√£o"
        },
        {
            "query": "top 5 categorias por venda",
            "intent": "python_analysis",
            "confidence": 0.92,
            "reasoning": "Ranking num√©rico SEM pedido de gr√°fico"
        },
        {
            "query": "liste os produtos com estoque zerado",
            "intent": "python_analysis",
            "confidence": 0.88,
            "reasoning": "An√°lise de dados com filtro espec√≠fico"
        },
        # gerar_grafico
        {
            "query": "gere um gr√°fico de vendas por categoria",
            "intent": "gerar_grafico",
            "confidence": 0.99,
            "reasoning": "Explicitamente menciona 'gr√°fico'"
        },
        {
            "query": "mostre a evolu√ß√£o de vendas mensais",
            "intent": "gerar_grafico",
            "confidence": 0.95,
            "reasoning": "An√°lise temporal ('evolu√ß√£o') ‚Üí visualiza√ß√£o"
        },
        {
            "query": "distribui√ß√£o por segmento",
            "intent": "gerar_grafico",
            "confidence": 0.88,
            "reasoning": "'Distribui√ß√£o' geralmente implica visualiza√ß√£o"
        },
        {
            "query": "comparar vendas entre UNEs visualmente",
            "intent": "gerar_grafico",
            "confidence": 0.97,
            "reasoning": "Palavra-chave 'visualmente' + compara√ß√£o"
        },
        {
            "query": "tend√™ncia dos √∫ltimos 6 meses",
            "intent": "gerar_grafico",
            "confidence": 0.93,
            "reasoning": "An√°lise temporal de tend√™ncia ‚Üí gr√°fico de linha"
        },
        # resposta_simples
        {
            "query": "liste os produtos da categoria AVIAMENTOS",
            "intent": "resposta_simples",
            "confidence": 0.94,
            "reasoning": "Filtro direto sem an√°lise complexa"
        },
        {
            "query": "qual o estoque do produto 12345?",
            "intent": "resposta_simples",
            "confidence": 0.97,
            "reasoning": "Lookup de valor √∫nico - query simples"
        },
        {
            "query": "quantos produtos tem no segmento TECIDOS?",
            "intent": "resposta_simples",
            "confidence": 0.91,
            "reasoning": "Contagem simples sem an√°lise profunda"
        }
    ]

    # Construir prompt estruturado com few-shot learning
    prompt = f"""# üéØ CLASSIFICA√á√ÉO DE INTEN√á√ÉO (Few-Shot Learning)

Voc√™ √© um classificador de inten√ß√µes para um sistema de an√°lise de dados de varejo.

## üìö EXEMPLOS ROTULADOS (Aprenda com estes exemplos)

{json.dumps(few_shot_examples, indent=2, ensure_ascii=False)}

## üéØ CATEGORIAS DE INTEN√á√ÉO

1. **une_operation**: Opera√ß√µes UNE (abastecimento, MC, pre√ßos, Linha Verde)
2. **python_analysis**: An√°lise/ranking SEM visualiza√ß√£o
3. **gerar_grafico**: Visualiza√ß√µes, gr√°ficos, tend√™ncias, distribui√ß√µes
4. **resposta_simples**: Consultas b√°sicas de filtro/lookup

## ‚ö†Ô∏è REGRAS DE PRIORIZA√á√ÉO

1. Se mencionar UNE + (abastecimento|MC|pre√ßo) ‚Üí `une_operation`
2. Se mencionar (gr√°fico|visualiza√ß√£o|evolu√ß√£o|tend√™ncia|distribui√ß√£o) ‚Üí `gerar_grafico`
3. Se pedir (ranking|an√°lise) SEM visualiza√ß√£o ‚Üí `python_analysis`
4. Se for lookup simples ‚Üí `resposta_simples`

## üéØ TAREFA ATUAL

**Query do Usu√°rio:** "{user_query}"

## üìù INSTRU√á√ïES

Analise a query acima e retorne um JSON com:
- `intent`: uma das 4 categorias
- `confidence`: score de 0.0 a 1.0 (sua confian√ßa na classifica√ß√£o)
- `reasoning`: breve explica√ß√£o (1 frase) de por que escolheu esta categoria

**IMPORTANTE:** Use os exemplos acima como refer√™ncia. Queries similares devem ter a mesma classifica√ß√£o.

## üì§ FORMATO DE SA√çDA (JSON)

```json
{{
  "intent": "categoria_escolhida",
  "confidence": 0.95,
  "reasoning": "Explica√ß√£o breve"
}}
```

**Responda APENAS com o JSON acima. N√£o adicione texto extra.**
"""

    # üîç LOGGING DETALHADO - Diagn√≥stico de classifica√ß√£o
    logger.info(f"[CLASSIFY_INTENT] üìù Query original: '{user_query}'")

    # Use json_mode=True para for√ßar a resposta em JSON
    response_dict = llm_adapter.get_completion(messages=[{"role": "user", "content": prompt}], json_mode=True)
    plan_str = response_dict.get("content", "{}")

    # üîç LOGGING: Resposta raw da LLM
    logger.info(f"[CLASSIFY_INTENT] ü§ñ Resposta LLM raw: {plan_str[:200]}...")

    # Fallback para extrair JSON de blocos de markdown
    if "```json" in plan_str:
        match = re.search(r"```json\n(.*?)```", plan_str, re.DOTALL)
        if match:
            plan_str = match.group(1).strip()

    try:
        plan = json.loads(plan_str)
    except json.JSONDecodeError:
        logger.warning(f"N√£o foi poss√≠vel decodificar o JSON da inten√ß√£o: {plan_str}")
        # Fallback para a inten√ß√£o mais poderosa em caso de erro de parsing
        plan = {"intent": "python_analysis", "entities": {}}

    intent = plan.get('intent', 'python_analysis')
    confidence = plan.get('confidence', 0.5)
    reasoning = plan.get('reasoning', 'N√£o fornecido')

    # ‚úÖ NOVO: Valida√ß√£o de confidence score (Context7 best practice)
    if confidence < 0.7:
        logger.warning(f"[CLASSIFY_INTENT] ‚ö†Ô∏è Baixa confian√ßa na classifica√ß√£o: {confidence:.2f}")
        logger.warning(f"[CLASSIFY_INTENT] Reasoning: {reasoning}")
        # TODO: Futuramente, pode pedir clarifica√ß√£o ao usu√°rio aqui

    # üîç LOGGING DETALHADO - Intent final com confidence
    logger.info(f"[CLASSIFY_INTENT] ‚úÖ Intent: '{intent}' | Confidence: {confidence:.2f} | Reasoning: {reasoning}")

    # üîç LOGGING: Alertar se query pede gr√°fico mas n√£o foi classificada como tal
    keywords_visuais = ['gr√°fico', 'chart', 'visualiza√ß√£o', 'evolu√ß√£o', 'tend√™ncia', 'distribui√ß√£o', 'sazonalidade', 'comparar']
    query_lower = user_query.lower()
    tem_keyword_visual = any(kw in query_lower for kw in keywords_visuais)

    if tem_keyword_visual and intent != 'gerar_grafico':
        logger.warning(f"[CLASSIFY_INTENT] ‚ö†Ô∏è POSS√çVEL ERRO: Query tem palavra visual ({[kw for kw in keywords_visuais if kw in query_lower]}) mas intent='{intent}' (n√£o 'gerar_grafico')")

    logger.info(f"[NODE] classify_intent: Inten√ß√£o classificada como '{intent}'")
    
    # Assegura que o plan sempre tenha a chave 'intent'
    if 'intent' not in plan:
        plan['intent'] = intent
        
    return {"plan": plan, "intent": intent}



def generate_parquet_query(state: AgentState, llm_adapter: BaseLLMAdapter, parquet_adapter: ParquetAdapter) -> Dict[str, Any]:
    """
    Gera um dicion√°rio de filtros para consulta Parquet a partir da pergunta do utilizador, usando o schema do arquivo Parquet e descri√ß√µes de colunas.
    """
    user_query = _extract_user_query(state)
    logger.info(f"[NODE] generate_parquet_query: Gerando filtros para '{user_query}'")

    # Importar field_mapper
    from core.utils.field_mapper import get_field_mapper
    
    # Obter o schema do arquivo Parquet para dar contexto ao LLM
    try:
        schema = parquet_adapter.get_schema()
    except Exception as e:
        logger.error(f"Erro ao obter o schema do arquivo Parquet: {e}", exc_info=True)
        return {"parquet_filters": {}, "final_response": {"type": "error", "content": "N√£o foi poss√≠vel aceder ao schema do arquivo Parquet para gerar a consulta."}}

    # Load the focused catalog (catalog_focused.json)
    import os
    base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    catalog_file_path = os.path.join(base_dir, "data", "catalog_focused.json")
    
    try:
        with open(catalog_file_path, 'r', encoding='utf-8') as f:
            catalog_data = json.load(f)
        
        # Find the entry for admatao.parquet
        admatao_catalog = next((entry for entry in catalog_data if entry.get("file_name") == "admatao.parquet"), None)
        
        if admatao_catalog and "column_descriptions" in admatao_catalog:
            column_descriptions = admatao_catalog["column_descriptions"]
            column_descriptions_str = json.dumps(column_descriptions, indent=2, ensure_ascii=False)
        else:
            column_descriptions_str = "Nenhuma descri√ß√£o de coluna dispon√≠vel."
            logger.warning("Descri√ß√µes de coluna para admatao.parquet n√£o encontradas no cat√°logo.")

    except FileNotFoundError:
        column_descriptions_str = "Erro: Arquivo de cat√°logo n√£o encontrado."
        logger.error(f"Arquivo de cat√°logo n√£o encontrado em {catalog_file_path}", exc_info=True)
    except Exception as e:
        column_descriptions_str = f"Erro ao carregar descri√ß√µes de coluna: {e}"
        logger.error(f"Erro ao carregar descri√ß√µes de coluna: {e}", exc_info=True)
    
    # Inicializar field_mapper
    field_mapper = get_field_mapper(catalog_file_path)
    
    # Gerar mapeamento de campos para o prompt
    field_mapping_guide = """
## Mapeamento de Campos (OBRIGAT√ìRIO)

Quando o usu√°rio mencionar:
- "segmento" ‚Üí use: NOMESEGMENTO
- "categoria" ‚Üí use: NomeCategoria
- "grupo" ‚Üí use: NOMEGRUPO
- "subgrupo" ‚Üí use: NomeSUBGRUPO
- "c√≥digo" ou "produto" ‚Üí use: PRODUTO
- "nome" ‚Üí use: NOME
- "estoque" ‚Üí use: ESTOQUE_UNE
- "pre√ßo" ‚Üí use: LIQUIDO_38
- "vendas" ou "vendas 30 dias" ‚Üí use: VENDA_30DD
- "fabricante" ‚Üí use: NomeFabricante

**REGRAS CR√çTICAS:**
1. NUNCA use "SEGMENTO", sempre use "NOMESEGMENTO"
2. NUNCA use "CATEGORIA", sempre use "NomeCategoria"
3. NUNCA use "CODIGO", sempre use "PRODUTO"
4. Para estoque zero: filtre por ESTOQUE_UNE = 0
5. Para campos de texto: use valores em MAI√öSCULAS
"""


    prompt = f"""
    Voc√™ √© um especialista em traduzir perguntas de neg√≥cio em filtros de dados JSON. Sua tarefa √© analisar a **NOVA Pergunta do Usu√°rio** e convert√™-la em um objeto JSON de filtros, usando o schema e as regras de mapeamento fornecidas.

    {field_mapping_guide}

    **Instru√ß√µes Cr√≠ticas:**
    1.  **FOCO TOTAL NA NOVA PERGUNTA:** Sua resposta DEVE ser uma tradu√ß√£o direta da **NOVA Pergunta do Usu√°rio**.
    2.  **EXTRA√á√ÉO DE C√ìDIGOS:** Se a pergunta contiver um n√∫mero que se pare√ßa com um c√≥digo de produto (geralmente com 5 ou mais d√≠gitos), voc√™ DEVE extra√≠-lo como um filtro para a coluna `PRODUTO`.
    3.  **N√ÉO COPIE OS EXEMPLOS:** Os exemplos abaixo s√£o apenas um guia de estilo e formato. N√£o os use como base para a sua resposta.
    4.  **GERE APENAS JSON:** Sua sa√≠da final deve ser um √∫nico e v√°lido objeto JSON, sem nenhum texto ou explica√ß√£o adicional.
    5.  **CONSULTA VAZIA:** Se a pergunta n√£o contiver nenhum filtro (ex: "liste todas as categorias"), retorne um objeto JSON vazio: `{{}}`.

    **Schema do Arquivo Parquet (para refer√™ncia de colunas):**
    ```
    {schema}
    ```

    ---

    **Exemplos de Formato (Use apenas como guia):**

    - **Exemplo 1 (Filtro de C√≥digo de Produto):**
      - Pergunta: "qual o estoque do produto 369947?"
      - Filtros JSON: `{{"PRODUTO": 369947}}`

    - **Exemplo 2 (Filtro Composto):**
      - Pergunta: "quais s√£o as categorias do segmento tecidos com estoque 0?"
      - Filtros JSON: `{{"NOMESEGMENTO": "TECIDO", "ESTOQUE_UNE": 0}}`
    
    - **Exemplo 3 (Filtro de Texto):**
      - Pergunta: "liste produtos da categoria aviamentos"
      - Filtros JSON: `{{"NomeCategoria": "AVIAMENTOS"}}`

    ---

    **NOVA Pergunta do Usu√°rio (TRADUZIR ESTA):**
    "{user_query}"

    **Filtros JSON Resultantes:**
    """

    response_dict = llm_adapter.get_completion(messages=[{"role": "user", "content": prompt}], json_mode=True)
    filters_str = response_dict.get("content", "{}").strip()

    # Fallback para extrair JSON de blocos de markdown
    if "```json" in filters_str:
        match = re.search(r"```json\n(.*?)```", filters_str, re.DOTALL)
        if match:
            filters_str = match.group(1).strip()

    try:
        parquet_filters = json.loads(filters_str)
    except json.JSONDecodeError:
        logger.warning(f"N√£o foi poss√≠vel decodificar o JSON dos filtros Parquet: {filters_str}")
        parquet_filters = {}

    # ‚úÖ MAPEAMENTO DE COLUNAS: LLM usa nomes padronizados, Parquet tem nomes reais
    column_mapping = {
        'PRODUTO': 'codigo',
        'NOME': 'nome_produto',
        'NOMESEGMENTO': 'nomesegmento',
        'NomeCategoria': 'NOMECATEGORIA',
        'NOMEGRUPO': 'nomegrupo',
        'NomeSUBGRUPO': 'NOMESUBGRUPO',
        'VENDA_30DD': 'venda_30_d',
        'ESTOQUE_UNE': 'estoque_atual',
        'LIQUIDO_38': 'preco_38_percent',
        'UNE_NOME': 'une_nome',
        'NomeFabricante': 'NOMEFABRICANTE'
    }

    # Aplicar mapeamento nos filtros
    mapped_filters = {}
    for key, value in parquet_filters.items():
        mapped_key = column_mapping.get(key, key)
        mapped_filters[mapped_key] = value

    logger.info(f"Filtros originais: {parquet_filters}")
    logger.info(f"Filtros mapeados: {mapped_filters}")

    return {"parquet_filters": mapped_filters}


def execute_query(state: AgentState, parquet_adapter: ParquetAdapter) -> Dict[str, Any]:
    """
    Executa os filtros Parquet do estado.
    """
    user_query = _extract_user_query(state)
    parquet_filters = state.get('parquet_filters', {})

    logger.info(f"[NODE] execute_query: Executando com filtros {parquet_filters}")
    logger.info(f"üìä QUERY EXECUTION - User query: '{user_query}'")
    logger.info(f"üìä QUERY EXECUTION - Filters: {parquet_filters}")

    # A l√≥gica de fallback para filtros vazios foi removida, pois era a causa do MemoryError.
    # Agora, a prote√ß√£o no ParquetAdapter ser√° acionada se os filtros estiverem vazios.
    retrieved_data = fetch_data_from_query.invoke({"query_filters": parquet_filters, "parquet_adapter": parquet_adapter})

    # ‚úÖ LOG DETALHADO DOS RESULTADOS
    if isinstance(retrieved_data, list):
        if retrieved_data and "error" in retrieved_data[0]:
            logger.error(f"‚ùå QUERY ERROR: {retrieved_data[0]}")
        else:
            logger.info(f"‚úÖ QUERY SUCCESS: Retrieved {len(retrieved_data)} rows")
            if retrieved_data:
                logger.info(f"üìã SAMPLE DATA COLUMNS: {list(retrieved_data[0].keys()) if retrieved_data else 'No data'}")
    else:
        logger.warning(f"‚ö†Ô∏è UNEXPECTED DATA TYPE: {type(retrieved_data)}")

    return {"retrieved_data": retrieved_data}

def generate_plotly_spec(state: AgentState, llm_adapter: BaseLLMAdapter, code_gen_agent: CodeGenAgent) -> Dict[str, Any]:
    """
    Gera uma especifica√ß√£o JSON para Plotly ou uma resposta textual usando o CodeGenAgent.
    Este n√≥ agora lida com dois cen√°rios:
    1.  **Com `raw_data`**: Gera um gr√°fico a partir de dados pr√©-filtrados.
    2.  **Sem `raw_data` (fluxo `python_analysis`)**: Gera um script Python para fazer a an√°lise completa (filtrar, agregar, etc.).
    """
    logger.info("N√≥: generate_plotly_spec")
    raw_data = state.get("retrieved_data")
    user_query = _extract_user_query(state)
    plan = state.get("plan", {})
    intent = plan.get("intent")

    logger.info(f"üêç Python CodeGen - User query: '{user_query}'")
    logger.info(f"üêç Python CodeGen - Intent: {intent}")
    logger.info(f"üêç Python CodeGen - Data available: {len(raw_data) if raw_data else 'No pre-loaded data'}")

    # Verifica se o estado de erro j√° foi definido por um n√≥ anterior
    if raw_data and isinstance(raw_data, list) and raw_data and "error" in raw_data[0]:
        return {"final_response": {"type": "text", "content": raw_data[0]["error"]}}

    try:
        # Cen√°rio 1: An√°lise complexa, sem dados pr√©-carregados.
        # O CodeGenAgent deve fazer o trabalho completo.
        if not raw_data:
            prompt_for_code_gen = f"""
            **TAREFA:** Voc√™ deve escrever um script Python para responder √† pergunta do usu√°rio.

            **INSTRU√á√ïES OBRIGAT√ìRIAS:**
            1. **CARREGUE OS DADOS:** Inicie seu script com a linha: `df = load_data()`
            2. **RESPONDA √Ä PERGUNTA:** Usando o dataframe `df`, escreva o c√≥digo para responder √† seguinte pergunta: "{user_query}"
            3. **SALVE O RESULTADO NA VARI√ÅVEL `result`:** A √∫ltima linha do seu script DEVE ser a atribui√ß√£o do resultado final √† vari√°vel `result`. Esta √© a √∫nica forma que o sistema tem para ver sua resposta. N√ÉO use `print()`.

            **REGRAS DE NEG√ìCIO ESPEC√çFICAS:**
            - **Produtos em Excesso:** Para perguntas sobre 'produtos em excesso', filtre o DataFrame para incluir apenas produtos onde a coluna `estoque_atual` √© maior que a coluna `linha_verde`.

            **Exemplo de Script:**
            ```python
            # Passo 1: Carregar dados
            df = load_data()

            # Passo 2: Responder √† pergunta (ex: "ranking de vendas do segmento tecidos")
            tecidos_df = df[df['NOMESEGMENTO'].str.upper() == 'TECIDO']
            ranking = tecidos_df.groupby('NOME')['VENDA_30DD'].sum().sort_values(ascending=False).reset_index()

            # Passo 3: Salvar resultado
            result = ranking
            ```

            **Seu Script Python (Lembre-se, a √∫ltima linha deve ser `result = ...`):**
            """
        # Cen√°rio 2: Gera√ß√£o de gr√°fico a partir de dados pr√©-carregados.
        else:
            prompt_for_code_gen = f"""
            Com base na consulta do usu√°rio e no DataFrame Pandas `df_raw_data` j√° dispon√≠vel, gere um script Python para criar um gr√°fico com Plotly Express.
            O objeto da figura Plotly resultante deve ser armazenado em uma vari√°vel chamada `result`.
            N√£o inclua `fig.show()`.

            **Consulta do Usu√°rio:** "{user_query}"
            **Dados Brutos (amostra):**
            ```json
            {pd.DataFrame(raw_data).head(3).to_json(orient="records", indent=2)}
            ```

            **Seu Script Python:**
            """

        # O CodeGenAgent espera um dicion√°rio com a query e os dados brutos (se existirem)
        code_gen_input = {
            "query": prompt_for_code_gen,
            "raw_data": raw_data  # Passa os dados brutos ou None
        }
        
        logger.info(f"\n--- PROMPT PARA CODEGENAGENT ---\n{prompt_for_code_gen}\n---------------------------------")

        logger.info("üöÄ Calling code_gen_agent.generate_and_execute_code...")
        code_gen_response = code_gen_agent.generate_and_execute_code(code_gen_input)

        # ‚úÖ LOGS DETALHADOS DO RETORNO DO CODEGENAGENT
        logger.info(f"üìã CodeGenAgent response type: {code_gen_response.get('type')}")
        logger.info(f"üìã CodeGenAgent response keys: {list(code_gen_response.keys())}")

        # Logs espec√≠ficos por tipo
        if code_gen_response.get("type") == "dataframe":
            df_result = code_gen_response.get("output")
            if isinstance(df_result, pd.DataFrame):
                logger.info(f"üìä DataFrame result: {len(df_result)} rows, {len(df_result.columns)} cols")
                logger.info(f"üìä DataFrame columns: {list(df_result.columns)}")
                if len(df_result) > 0:
                    logger.info(f"üìä DataFrame sample (first 3 rows): {df_result.head(3).to_dict(orient='records')}")
            else:
                logger.warning(f"‚ö†Ô∏è Expected DataFrame but got {type(df_result)}")
        elif code_gen_response.get("type") == "text":
            text_output = str(code_gen_response.get("output"))
            logger.info(f"üìù Text result length: {len(text_output)} chars")
            logger.info(f"üìù Text result preview: {text_output[:200]}...")

        # Processa a resposta do CodeGenAgent
        if code_gen_response.get("type") == "chart":
            plotly_spec = json.loads(code_gen_response.get("output"))
            logger.info(f"üìà Chart generated successfully")
            return {"plotly_spec": plotly_spec}

        elif code_gen_response.get("type") == "multiple_charts":
            # ‚úÖ CORRE√á√ÉO: M√∫ltiplos gr√°ficos Plotly
            charts_json_list = code_gen_response.get("output")
            logger.info(f"üìà {len(charts_json_list)} charts generated successfully")

            # Retornar como final_response com tipo especial
            return {
                "final_response": {
                    "type": "multiple_charts",
                    "content": charts_json_list,
                    "user_query": user_query
                }
            }

        elif code_gen_response.get("type") == "dataframe":
            # ‚úÖ CORRE√á√ÉO: Converter DataFrame para lista de dicion√°rios
            df_result = code_gen_response.get("output")

            # Garantir que seja DataFrame
            if isinstance(df_result, pd.DataFrame):
                data_list = df_result.to_dict(orient='records')
            else:
                data_list = df_result

            logger.info(f"üìä Converted DataFrame to {len(data_list)} records")
            logger.info(f"üìä Sample record keys: {list(data_list[0].keys()) if data_list else 'Empty'}")
            return {"retrieved_data": data_list}

        elif code_gen_response.get("type") == "text":
            # ‚úÖ CORRE√á√ÉO: Garantir que texto seja STRING e preservar user_query
            text_output = str(code_gen_response.get("output"))
            logger.info(f"üìù Text response: {len(text_output)} chars - Returning as final_response")

            return {
                "final_response": {
                    "type": "text",
                    "content": text_output,
                    "user_query": user_query
                }
            }

        elif code_gen_response.get("type") == "error":
            error_msg = str(code_gen_response.get("output", "Erro desconhecido"))
            logger.error(f"‚ùå CodeGenAgent error: {error_msg}")

            return {
                "final_response": {
                    "type": "text",
                    "content": f"‚ùå Erro ao processar: {error_msg}",
                    "user_query": user_query
                }
            }

        else:
            # ‚úÖ FALLBACK: Tipo desconhecido
            logger.warning(f"‚ö†Ô∏è Unknown CodeGenAgent response type: {code_gen_response.get('type')}")

            return {
                "final_response": {
                    "type": "text",
                    "content": f"‚ö†Ô∏è Resposta inesperada do agente: {code_gen_response.get('output')}",
                    "user_query": user_query
                }
            }

    except Exception as e:
        logger.error(f"Erro ao gerar script Python com CodeGenAgent: {e}", exc_info=True)
        return {"final_response": {"type": "text", "content": f"N√£o consegui gerar a an√°lise. Erro interno: {e}"}}


def format_final_response(state: AgentState) -> Dict[str, Any]:
    """
    Formata a resposta final para o utilizador.
    """
    user_query = _extract_user_query(state)
    logger.info(f"[NODE] format_final_response: Formatando resposta para '{user_query}'")

    # üîç LOGS DETALHADOS DO ESTADO
    logger.info(f"üîç STATE KEYS: {list(state.keys())}")
    logger.info(f"üîç clarification_needed: {state.get('clarification_needed')}")
    logger.info(f"üîç plotly_spec exists: {bool(state.get('plotly_spec'))}")
    logger.info(f"üîç retrieved_data exists: {bool(state.get('retrieved_data'))}")
    logger.info(f"üîç final_response exists: {bool(state.get('final_response'))}")

    # Se retrieved_data existir, logar detalhes
    if state.get("retrieved_data"):
        data = state.get("retrieved_data")
        logger.info(f"üìä retrieved_data type: {type(data)}")
        logger.info(f"üìä retrieved_data length: {len(data) if isinstance(data, list) else 'N/A'}")
        if isinstance(data, list) and len(data) > 0:
            logger.info(f"üìä retrieved_data sample keys: {list(data[0].keys())}")

    # üìù Construir resposta baseada no estado
    response = {}

    # ‚úÖ PRIORIDADE 1: Verificar se j√° existe final_response (resposta direta do CodeGenAgent)
    if state.get("final_response"):
        logger.info(f"‚úÖ Using pre-formatted final_response from state")
        response = state.get("final_response")
        # Garantir que user_query esteja presente
        if "user_query" not in response:
            response["user_query"] = user_query

    # ‚úÖ PRIORIDADE 2: Clarifica√ß√£o
    elif state.get("clarification_needed"):
        response = {"type": "clarification", "content": state.get("clarification_options")}
        logger.info(f"üí¨ CLARIFICATION RESPONSE for query: '{user_query}'")

    # ‚úÖ PRIORIDADE 3: Gr√°fico
    elif state.get("plotly_spec"):
        response = {"type": "chart", "content": state.get("plotly_spec")}
        response["user_query"] = user_query
        logger.info(f"üìà CHART RESPONSE for query: '{user_query}'")

    # ‚úÖ PRIORIDADE 4: Dados tabulares
    elif state.get("retrieved_data"):
        data = state.get("retrieved_data")
        response = {"type": "data", "content": _clean_json_values(data)}
        response["user_query"] = user_query
        logger.info(f"üìä DATA RESPONSE for query: '{user_query}' - {len(data)} rows")

    # ‚ùå FALLBACK: Se nenhum dos acima
    else:
        response = {
            "type": "text",
            "content": "‚ùå N√£o consegui processar a sua solicita√ß√£o. Tente reformular a pergunta."
        }
        response["user_query"] = user_query
        logger.warning(f"‚ùì FALLBACK RESPONSE for query: '{user_query}' - No data in state")
        logger.warning(f"‚ùì State keys available: {list(state.keys())}")

    # ‚úÖ GARANTIR que a pergunta do usu√°rio seja preservada no hist√≥rico
    final_messages = state['messages'] + [{"role": "assistant", "content": response}]

    # üîç LOG DO RESULTADO FINAL
    logger.info(f"‚úÖ FINAL RESPONSE - Type: {response.get('type')}, User Query: '{user_query}'")
    logger.info(f"üìã MESSAGE HISTORY - Total messages: {len(final_messages)}")

    return {"messages": final_messages, "final_response": response}


def execute_une_tool(state: AgentState, llm_adapter: BaseLLMAdapter) -> Dict[str, Any]:
    """
    Executa ferramentas UNE baseado na query do usu√°rio.
    Detecta qual ferramenta UNE usar e extrai os par√¢metros necess√°rios.
    """
    user_query = _extract_user_query(state)
    logger.info(f"[NODE] execute_une_tool: Processando query UNE '{user_query}'")

    # Importar mapeamento de UNE
    from core.config.une_mapping import resolve_une_code, suggest_une, get_une_name

    # Importar ferramentas UNE
    from core.tools.une_tools import (
        calcular_abastecimento_une,
        calcular_mc_produto,
        calcular_preco_final_une
    )

    # Detectar qual ferramenta usar
    tool_detection_prompt = f"""
    Analise a consulta e identifique qual ferramenta UNE usar.

    Ferramentas dispon√≠veis:
    - calcular_abastecimento_une: Para queries sobre abastecimento, reposi√ß√£o, produtos para abastecer
    - calcular_mc_produto: Para queries sobre MC, m√©dia comum, m√©dia de vendas
    - calcular_preco_final_une: Para queries sobre pre√ßo final, calcular pre√ßo, pre√ßo com desconto

    Retorne APENAS um JSON: {{"tool": "nome_da_ferramenta"}}

    Query: "{user_query}"
    """

    tool_response = llm_adapter.get_completion(
        messages=[{"role": "user", "content": tool_detection_prompt}],
        json_mode=True
    )

    tool_str = tool_response.get("content", "{}").strip()
    if "```json" in tool_str:
        match = re.search(r"```json\n(.*?)```", tool_str, re.DOTALL)
        if match:
            tool_str = match.group(1).strip()

    try:
        tool_data = json.loads(tool_str)
        tool_name = tool_data.get("tool", "")
    except json.JSONDecodeError:
        logger.error(f"Erro ao detectar ferramenta UNE: {tool_str}")
        return {"final_response": {"type": "text", "content": "N√£o consegui identificar a opera√ß√£o UNE solicitada."}}

    logger.info(f"Ferramenta UNE detectada: {tool_name}")

    # Executar ferramenta apropriada
    try:
        if "abastecimento" in tool_name:
            # Extrair par√¢metros para abastecimento
            extract_prompt = f"""
            Extraia a UNE (sigla, nome ou c√≥digo) e o segmento (opcional) da consulta.
            Retorne JSON: {{"une_input": "<string da UNE>", "segmento": "<nome ou null>"}}

            Exemplos de une_input: "scr", "mad", "Santa Cruz", "123", "une vix"

            Query: "{user_query}"
            """
            params_response = llm_adapter.get_completion(
                messages=[{"role": "user", "content": extract_prompt}],
                json_mode=True
            )
            params_str = params_response.get("content", "{}").strip()
            if "```json" in params_str:
                match = re.search(r"```json\n(.*?)```", params_str, re.DOTALL)
                if match:
                    params_str = match.group(1).strip()

            params = json.loads(params_str)
            une_input = params.get("une_input", "")
            segmento = params.get("segmento")

            # ‚úÖ VALIDAR E RESOLVER UNE usando mapeamento
            une_code = resolve_une_code(une_input)

            if not une_code:
                # UNE n√£o encontrada - sugerir alternativas
                suggestions = suggest_une(une_input)
                if suggestions:
                    sugg_text = ", ".join([f"{code} ({name})" for code, name in suggestions])
                    error_msg = f"‚ùå UNE '{une_input}' n√£o encontrada.\n\nüí° Voc√™ quis dizer: {sugg_text}?"
                else:
                    error_msg = f"‚ùå UNE '{une_input}' n√£o encontrada.\n\nUNEs dispon√≠veis: SCR (123), MAD (261), UNA (301), VIX (401), JFA (501), BHE (601)"

                logger.warning(f"UNE n√£o encontrada: '{une_input}'")
                return {"final_response": {"type": "text", "content": error_msg, "user_query": user_query}}

            une_id = int(une_code)
            une_name = get_une_name(une_code)
            logger.info(f"‚úÖ UNE resolvida: '{une_input}' ‚Üí {une_code} ({une_name})")

            args = {"une_id": une_id}
            if segmento:
                args["segmento"] = segmento

            result = calcular_abastecimento_une.invoke(args)

        elif "mc_produto" in tool_name:
            # Extrair par√¢metros para MC
            extract_prompt = f"""
            Extraia o c√≥digo do produto e o ID da UNE da consulta.
            Retorne JSON: {{"produto_id": <n√∫mero>, "une_id": <n√∫mero>}}

            Query: "{user_query}"
            """
            params_response = llm_adapter.get_completion(
                messages=[{"role": "user", "content": extract_prompt}],
                json_mode=True
            )
            params_str = params_response.get("content", "{}").strip()
            if "```json" in params_str:
                match = re.search(r"```json\n(.*?)```", params_str, re.DOTALL)
                if match:
                    params_str = match.group(1).strip()

            params = json.loads(params_str)
            produto_id = int(params.get("produto_id"))
            une_id = int(params.get("une_id"))

            result = calcular_mc_produto.invoke({"produto_id": produto_id, "une_id": une_id})

        elif "preco" in tool_name:
            # Extrair par√¢metros para pre√ßo
            extract_prompt = f"""
            Extraia o valor da compra, ranking e forma de pagamento.
            Retorne JSON: {{"valor_compra": <n√∫mero>, "ranking": <0-4>, "forma_pagamento": "<vista|30d|90d|120d>"}}

            Query: "{user_query}"
            """
            params_response = llm_adapter.get_completion(
                messages=[{"role": "user", "content": extract_prompt}],
                json_mode=True
            )
            params_str = params_response.get("content", "{}").strip()
            if "```json" in params_str:
                match = re.search(r"```json\n(.*?)```", params_str, re.DOTALL)
                if match:
                    params_str = match.group(1).strip()

            params = json.loads(params_str)
            valor_compra = float(params.get("valor_compra"))
            ranking = int(params.get("ranking"))
            forma_pagamento = params.get("forma_pagamento")

            result = calcular_preco_final_une.invoke({
                "valor_compra": valor_compra,
                "ranking": ranking,
                "forma_pagamento": forma_pagamento
            })
        else:
            return {"final_response": {"type": "text", "content": f"Ferramenta UNE '{tool_name}' n√£o reconhecida."}}

        # Verificar se houve erro
        if "error" in result:
            return {"final_response": {"type": "text", "content": f"Erro: {result['error']}"}}

        # Formatar resposta baseado no tipo de ferramenta
        if "produtos" in result:  # Abastecimento
            retrieved_data = result.get("produtos", [])
            return {"retrieved_data": retrieved_data}
        elif "mc_calculada" in result:  # MC - Formatar para usu√°rio
            response_text = f"""**M√©dia Comum (MC) - Produto {result['produto_id']}**

**Produto:** {result['nome']}
**Segmento:** {result['segmento']}
**UNE:** {result['une_id']}

**Indicadores:**
- MC Calculada: {result['mc_calculada']:.2f} unidades/dia
- Estoque Atual: {result['estoque_atual']:.2f} unidades
- Linha Verde: {result['linha_verde']:.2f} unidades
- Percentual da LV: {result['percentual_linha_verde']:.1f}%

**Recomenda√ß√£o:**
{result['recomendacao']}"""
            return {"final_response": {"type": "text", "content": response_text}}
        elif "valor_original" in result:  # Pre√ßo - Formatar para usu√°rio
            response_text = f"""**C√°lculo de Pre√ßo Final UNE**

**Valor Original:** R$ {result['valor_original']:.2f}
**Tipo de Venda:** {result['tipo']}
**Ranking:** {result['ranking']} ({result['desconto_ranking']})
**Forma de Pagamento:** {result['forma_pagamento']} ({result['desconto_pagamento']})

**C√°lculo:**
- Desconto Ranking: {result['desconto_aplicado_ranking']:.1f}%
- Desconto Pagamento: {result['desconto_aplicado_pagamento']:.1f}%
- **Desconto Total:** {result['desconto_total']:.1f}%

**PRE√áO FINAL:** R$ {result['preco_final']:.2f}"""
            return {"final_response": {"type": "text", "content": response_text}}
        else:  # Fallback - JSON formatado
            response_text = json.dumps(result, indent=2, ensure_ascii=False)
            return {"final_response": {"type": "text", "content": response_text}}

    except Exception as e:
        logger.error(f"Erro ao executar ferramenta UNE: {e}", exc_info=True)
        return {"final_response": {"type": "text", "content": f"Erro ao processar opera√ß√£o UNE: {str(e)}"}}